# Annex. 1 Figures {.unnumbered}

![Relation between IA-ML-DL](../images/a1_DL-enven.png "Relation between IA-ML-DL"){#fig-DLenv fig-alt="IA engloba a ML y ML engloba a DL"}

::: figure-caption
Taken from: Deep learning with R by @chollet2018deep.
:::

![Classic programming and machine learning](../images/a1_ML-progen.png "Classic programming and machine learning"){#fig-MLprog fig-alt="It shows a scheme that explains in a general way the paradigm of classical programming and the use of machine learning. Showing in the first how rules and data are entered to obtain answers, while in machine learning data and answers are entered to obtain rules"}

::: figure-caption
Taken from: Deep learning with R by @chollet2018deep.
:::

![Basic structure of an artificial neural network](../images/a1_RNA-structen.png "Basic structure of an artificial neural network"){#fig-RNAstruct fig-alt="Shows a schematic schematic of the basic structure of an RNA. It shows how the different inputs are connected to each of the hidden layer nodes and in turn how each of the hidden layer nodes is connected to the output layer nodes. The hidden layer and output layer nodes are also connected to a bias parameter"}

::: figure-caption
Taken from: Topic 14: neural networks of @Larranaga07.
:::

```{r}
#| echo: false
#| warning: false

if(knitr::pandoc_to("html") ||
   knitr::pandoc_to("docx")){
  knitr::asis_output("![How the size of the filter affects the output vector](../images/a1_HJ-ksen.gif){#fig-HJks}")
}else if(knitr::pandoc_to("latex")){
  knitr::asis_output('[![How the size of the filter affects the output vector](../images/a1_HJ-ksen.png){#fig-HJks}](https://gist.github.com/davidrsch/3bfcece719d1b3ba019ed066a4cb1d4d)')
}
```

::: figure-caption
Own elaboration: Elaborated from @hongj20. Shows how the size of the output vector changes according to the size of the filter that is used.
:::

```{r}
#| echo: false
#| warning: false

if(knitr::pandoc_to("html") ||
   knitr::pandoc_to("docx")){
  knitr::asis_output("![How stride affects the output vector](../images/a1_HJ-strideen.gif){#fig-HJstride}")
}else if(knitr::pandoc_to("latex")){
  knitr::asis_output('[![How stride affects the output vector](../images/a1_HJ-strideen.png){#fig-HJstride}](https://gist.github.com/davidrsch/27872825c8e61b9076594051142f01a0)')
}
```

::: figure-caption
Own elaboration: Elaborated from @hongj20. Shows how the stride parameter affects the size of the output vector.
:::

```{r}
#| echo: false
#| warning: false

if(knitr::pandoc_to("html") ||
   knitr::pandoc_to("docx")){
  knitr::asis_output("![How dilation affects the output vector](../images/a1_HJ-dilationen.gif){#fig-HJdilation}")
}else if(knitr::pandoc_to("latex")){
  knitr::asis_output('[![How dilation affects the output vector](../images/a1_HJ-dilationen.png){#fig-HJdilation}](https://gist.github.com/davidrsch/e2bc5520db18bfe1d1159f2a2d830f48)')
}
```

::: figure-caption
Own elaboration: Elaborated from @hongj20. Show how the dilation parameter affects the size of the output vector.
:::

```{r}
#| echo: false
#| warning: false

if(knitr::pandoc_to("html") ||
   knitr::pandoc_to("docx")){
  knitr::asis_output("![How padding affects the output vector](../images/a1_HJ-paddingen.gif){#fig-HJpadding}")
}else if(knitr::pandoc_to("latex")){
  knitr::asis_output('[![How padding affects the output vector](../images/a1_HJ-paddingen.png){#fig-HJpadding}](https://gist.github.com/davidrsch/fa011845f1fef68973e1945879719f48)')
}
```

::: figure-caption
Own elaboration: Elaborated from @hongj20. Show how the padding parameter affects the size of the output vector.
:::

![Deployment of the loop of a standard recurrent neural network](../images/a1_CO-RNRstruct.png "Deployment of the loop of a standard recurrent neural network"){#fig-CORNRstruct width="550"}

::: figure-caption
Taken from: Understanding LSTM networks, @COlah15.
:::

![Nearby relevant information](../images/a1_CO-RInclose.png "Nearby relevant information"){#fig-CORInclose width="550"}

::: figure-caption
Taken from: Understanding LSTM networks, @COlah15.
:::

![Distant relevant information](../images/a1_CO-RInaway.png "Distant relevant information"){#fig-CORInaway width="550"}

::: figure-caption
Taken from: Understanding LSTM networks, @COlah15.
:::

![Difference Between Repeat Modules](../images/a1_CO-Drnrlstm.png "Difference Between Repeat Modules"){#fig-CODrnrlstm width="600"}

::: figure-caption
Taken from: Understanding LSTM networks, @COlah15.
:::

![LSTM functionality: Representation of step 1](../images/a1_CO-LSTMstep1.png "LSTM functionality: Representation of step 1"){#fig-COLSTMstep1 height="200"}

::: figure-caption
Taken from: Understanding LSTM networks, @COlah15.
:::

![LSTM functionality: Representation of step 2](../images/a1_CO-LSTMstep2.png "LSTM functionality: Representation of step 2"){#fig-COLSTMstep2 height="180"}

::: figure-caption
Taken from: Understanding LSTM networks, @COlah15.
:::

![LSTM functionality: Representation of step 3](../images/a1_CO-LSTMstep3.png "LSTM functionality: Representation of step 3"){#fig-COLSTMstep3 height="250"}

::: figure-caption
Taken from: Understanding LSTM networks, @COlah15.
:::

![LSTM functionality: Representation of step 4](../images/a1_CO-LSTMstep4.png "LSTM functionality: Representation of step 4"){#fig-COLSTMstep4 height="235"}

::: figure-caption
Taken from: Understanding LSTM networks, @COlah15.
:::

```{r}
#| echo: false
#| warning: false

if(knitr::pandoc_to("html") ||
   knitr::pandoc_to("docx")){
  knitr::asis_output("![Input and output vector display](../images/a2_muestrasen.gif){#fig-muestras}")
}else if(knitr::pandoc_to("latex")){
  knitr::asis_output('[![Input and output vector display](../images/a2_muestrasen.png){#fig-muestras}](https://gist.github.com/davidrsch/bddcafb7223b0c0366ec78d568646d51)')
}
```

::: figure-caption
Own elaboration: Made from an image in @chollet2018deep. It shows what the three-dimensional input and output vectors for a company's data look like, if three observations are used to create the input vector.
:::

![Different structures depending on the different sizes of input vectors](../images/a2_estructurasen.png){#fig-estructuras}

::: figure-caption
Own elaboration: Elaborated from the different models built using the keras and tensorflow packages in R and were graphed using the @Diagrammer package.
:::

![ReLU and Leaky ReLU domain](../images/a2_dominiosen.png){#fig-dominios}

::: figure-caption
Own elaboration: Elaborated from the images that can be seen in @Rallabandi23.
:::

![Flowchart of the Walk Forward Validation methodology](../images/a2_wfven.png){#fig-wfv}

::: figure-caption
Own elaboration
:::
