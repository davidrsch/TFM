[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Traballo Fin de Máster",
    "section": "",
    "text": "Descrición\nTrátase da web de “Aplicación de redes neuronais artificiais e programación cuadrática na xestión de carteiras”, un Traballo Fin de Máster do Máster Universitario en Banca e Finanzas da Universidade da Coruña. O traballo foi realizado por David Díaz Rodríguez e supervisado por Xosé Manuel Martínez Filgueira. O sitio está construído usando Quarto.\nEste traballo ten un repositorio que contén, ademais do código fonte deste sitio, algúns dos datos resultantes do procedemento descrito ao longo do traballo así como estruturas dos modelos de ARN empregados para obter as predicións.\nO código do procedemento exposto neste traballo, Anexo. 4 Códigos, desenvolveuse utilizando a versión 4.3.1 de R e a versión 2023.06.1-524 do software RStudio. Os paquetes necesarios para a execución do código son os seguintes:\n\n\n\nPaquete\nVersión\n\n\n\n\nabind\n1.4.5\n\n\nDiagrammeR\n1.0.10\n\n\ndplyr\n1.1.2\n\n\nforecast\n8.21\n\n\nggplot2\n3.4.2\n\n\ngridExtra\n2.3\n\n\ngt\n0.9.0\n\n\njsonlite\n1.8.7\n\n\nkableExtra\n1.3.4\n\n\nkeras\n2.11.1\n\n\nknitr\n1.43\n\n\nlubridate\n1.9.2\n\n\nMatrix\n1.6.0\n\n\nMetrics\n0.1.4\n\n\nquadprog\n1.5.8\n\n\nquantmod\n0.4.24\n\n\nreadr\n2.1.4\n\n\nreadxl\n1.4.2\n\n\nsimplermarkdown\n0.0.6\n\n\nstringr\n1.5.0\n\n\ntensorflow\n2.11.0\n\n\ntibble\n3.2.1\n\n\ntidyr\n1.3.0\n\n\nTTR\n0.24.3\n\n\nxml2\n1.3.4\n\n\nxts\n0.13.1\n\n\nzoo\n1.8.12"
  },
  {
    "objectID": "greetings.html",
    "href": "greetings.html",
    "title": "Grazas",
    "section": "",
    "text": "Quero expresar o meu sincero agradecemento a todas as persoas que contribuíron significativamente á realización deste traballo fin de máster. Sen o voso apoio, orientación e ánimo, este logro non sería posible.\nAgradecer á Xunta de Galica que me facilite os recursos para realizar estudos de máster como beneficiario da Bolsa Excelencia Juventud Exterior.\nAgradecer á Universidade da Coruña os coñecementos adquiridos durante os estudos do Máster Universitario en Banca e Finanzas. O seu compromiso coa excelencia académica foi unha fonte constante de inspiración.\nAgradezo profundamente ao meu titor Xosé Manuel Martínez Filgueira a súa experta orientación e as valiosas suxestións ao longo deste proceso. O seu coñecemento e dedicación foron fundamentais para darlle rumbo e calidade a este traballo.\nO meu agradecemento vaise estendido aos meus compañeiros e amigos que proporcionaron un espazo para debates ricos e valiosas contribucións que contribuíron ao desenvolvemento deste traballo.\nTamén quero expresar o meu agradecemento á miña familia polo seu constante apoio emocional e comprensión durante os momentos difíciles deste proceso académico."
  },
  {
    "objectID": "summarygal.html",
    "href": "summarygal.html",
    "title": "Resumo",
    "section": "",
    "text": "No contexto do mundo financeiro en constante cambio e complexidade, este traballo trata sobre a aplicación das redes neuronais artificiais e da programación cuadrática na xestión de carteiras financeiras. Destaca a importancia de caracterizar adecuadamente as series temporales financeiras para unha previsión máis precisa e examínase o potencial de combinar redes neuronais convolucionais e LSTM para mellorar a previsión de series temporais. No proceso de composición da carteira aplícase a programación cuadrática como técnica eficiente para conseguir unha distribución óptima dos activos financeiros. En conclusión, o enfoque de combinar redes neuronais artificiais e programación cuadrática resulta prometedor na xestión de carteiras financeiras, pero é necesario un estudo máis profundo e exhaustivo para determinar a súa eficiencia óptima. Este traballo senta as bases para futuras investigacións, destacando a importancia de utilizar datos actualizados e de configurar adecuadamente os modelos para lograr unha xestión de carteira máis informada e eficaz nun entorno financeiro en constante evolución.\nPalabras clave: xestión de carteiras, carteiras, redes neuronais artificiais, programación cuadrática, series temporales financeiras, predición de prezos, composición da carteira."
  },
  {
    "objectID": "summaryes.html",
    "href": "summaryes.html",
    "title": "Resumen",
    "section": "",
    "text": "En el contexto del mundo financiero en constante cambio y complejidad, este trabajo aborda la aplicación de redes neuronales artificiales y programación cuadrática en la gestión de carteras financieras. Se destaca la importancia de caracterizar adecuadamente las series temporales financieras para realizar pronósticos más precisos y se examina el potencial de la combinación de las redes neuronales convolucionales y LSTM para mejorar la previsión de series de tiempo. En el proceso de composición de carteras, se aplica la programación cuadrática como una técnica eficiente para lograr una distribución óptima de activos financieros. En conclusión, el enfoque de combinar redes neuronales artificiales y programación cuadrática muestra promesa en la gestión de carteras financieras, pero es necesario un estudio más profundo y exhaustivo para determinar su eficiencia óptima. Este trabajo sienta las bases para futuras investigaciones, destacando la importancia de utilizar datos actualizados y configurar adecuadamente los modelos para lograr una gestión de carteras más informada y efectiva en un entorno financiero en constante evolución.\nPalabras clave: gestión de carteras, carteras, redes neuronales artificiales, programación cuadrática, series temporales financieras, predicción de precios, composición de carteras.\nNúmero de palabras: 14174"
  },
  {
    "objectID": "summaryen.html",
    "href": "summaryen.html",
    "title": "Abstract",
    "section": "",
    "text": "In the context of the financial world in constant change and complexity, this work deals with the application of artificial neural networks and quadratic programming in the management of financial portfolios. The importance of properly characterizing financial time series for more accurate forecasting is highlighted, and the potential of combining convolutional neural networks and LSTM to improve time series forecasting is examined. In the portfolio composition process, quadratic programming is applied as an efficient technique to achieve an optimal distribution of financial assets. In conclusion, the approach of combining artificial neural networks and quadratic programming shows promise in the management of financial portfolios, but a deeper and more exhaustive study is necessary to determine its optimal efficiency. This paper lays the groundwork for future research, highlighting the importance of using up-to-date data and properly configuring models to achieve more informed and effective portfolio management in an ever-evolving financial environment.\nKeywords: portfolio management, portfolios, artificial neural networks, quadratic programming, financial time series, price prediction, portfolio composition"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1 Introdución",
    "section": "",
    "text": "No ámbito financeiro, a xestión eficiente da carteira é unha tarefa crucial para investidores e xestores de activos, xa que busca maximizar os rendementos e minimizar os riscos asociados aos investimentos. Nos últimos anos, o campo da intelixencia artificial e a aprendizaxe automática experimentou un avance notable, o que permitiu a aplicación de técnicas innovadoras para mellorar o proceso de toma de decisións financeiras.\nEste traballo céntrase na integración de dúas potentes ferramentas: redes neuronais artificiais e programación cuadrática, para abordar o reto da xestión de carteiras. A combinación destas técnicas ofrece un enfoque robusto e prometedor para a previsión de series temporais financeiras e a composición da carteira nun ambiente financeiro altamente dinámico e complexo.\nO desenvolvemento do traballo estrutúrase en varios apartados fundamentais para abordar de forma integral o tema. En primeiro lugar, realízase unha caracterización detallada da serie temporal financeira, examinando as súas características e propiedades esenciais para comprender mellor o comportamento dos prezos dos activos.\nA continuación, explorase o potencial das redes neuronais artificiais na previsión de series temporais. Preséntanse antecedentes sobre o uso destas redes neste contexto e destacan dúas arquitecturas moi utilizadas: redes neuronais convolucionais e redes de memoria a longo prazo (LSTM), ambas con capacidade para capturar patróns complexos en datos financeiros.\nA sección sobre composición da carteira aborda o problema e presenta diversas técnicas aplicadas na xestión de activos. É aquí onde se introduce a programación cuadrática como unha ferramenta relevante e eficiente para a construción óptima de carteiras de investimento.\nA obtención de datos precisos e relevantes é fundamental para calquera análise financeira e para traballar con algoritmos de Machine Learning. Descríbese a metodoloxía aplicada para obter datos e como se computaron algúns dos indicadores máis comúns empregados en finanzas para utilizar como variables descritivas do problema en conxunto cos datos históricos. Tamén se expón como se estruturan os vectores que se empregarán na modelización e adestramento de redes neuronais.\nNos últimos apartados abórdase o proceso de modelización e adestramento, que implica a correcta configuración das redes neuronais e a implantación de programación cuadrática para obter resultados óptimos. Finalmente, preséntanse os resultados obtidos, incluíndo as predicións xeradas polas redes neuronais e a composición de carteiras recomendadas, demostrando así a eficacia da metodoloxía proposta na xestión de carteiras financeiras.\nEn conxunto, este traballo busca ofrecer unha visión completa e actualizada do uso das redes neuronais artificiais e da programación cuadrática na xestión de carteiras, destacando o seu potencial como opción para mellorar a toma de decisións financeiras e proporcionar aos investidores unha valiosa ferramenta para Optimizar o seu investimento. estratexias nun entorno cambiante e competitivo."
  },
  {
    "objectID": "body.html",
    "href": "body.html",
    "title": "2 Desenvolvemento do traballo",
    "section": "",
    "text": "O presente traballo afonda no campo da aprendizaxe automática e da intelixencia artificial, concretamente no uso combinado de redes neuronais artificiais e programación cuadrática. Esta poderosa sinerxía busca ofrecer unha solución eficaz e sofisticada para a previsión de series temporais financeiras e a composición óptima das carteiras de investimento. Mediante a aplicación destas técnicas, preténdese mellorar a toma de decisións financeiras e maximizar os rendementos, minimizando os riscos asociados aos investimentos. Nos seguintes apartados exploraranse en detalle as diferentes etapas do proceso, dende a caracterización de series temporais e o funcionamento das redes neuronais, ata a implantación da programación cuadrática na construción de carteiras eficientes."
  },
  {
    "objectID": "FSandP.html#series-temporais-e-as-súas-características",
    "href": "FSandP.html#series-temporais-e-as-súas-características",
    "title": "2.1 Caracterización de series temporais financeiras",
    "section": "2.1.1 Series temporais e as súas características",
    "text": "2.1.1 Series temporais e as súas características\nAs series temporais son un tipo de proceso estocástico que se caracteriza por ordenar variables aleatorias segundo o tempo. Isto significa que cada momento está asociado a un valor da variable que depende do azar e que pode cambiar co paso do tempo. Segundo Ruiz (2011), un proceso estocástico é “unha colección ou familia de variables aleatorias, ordenadas segundo un subíndice que adoita ser o tempo” (p.01). A análise das series temporais pode ter diferentes finalidades, como describir o comportamento das variables ou prever ou prever os seus valores futuros, o que resulta especialmente relevante para as series financeiras.\nA análise de series temporais é unha ferramenta estatística que permite estudar o comportamento dunha variable ao longo do tempo. Non obstante, non existe un consenso único sobre os compoñentes que se deben considerar neste tipo de análises. Algúns autores, como Kocenda and Cerný (2017) e Anderson et al. (2017), propoñen que as series temporais poden descompoñerse en tres compoñentes: tendencia, estacionalidade e ruído. Outros autores, como Dodge (2008) e Espallargas and Solís (2012), suxiren que habería que engadir un cuarto compoñente: o ciclo. Por último, hai autores que suxiren que as series temporais poden ter ata cinco compoñentes, son os casos de IBM (2021) e Chirinos (2018).\nTendencia: é o patrón de cambio a longo prazo que se observa nunha serie de datos. Pódese definir como a dirección xeral e persistente das variacións da serie ao longo do tempo. Pódese clasificar como positivo (Figura 1), negativo (Figura 2) ou nulo (Figura 3), dependendo de se a serie aumenta, diminúe ou permanece constante a longo prazo. A tendencia pódese identificar mediante análise gráfica ou por métodos estatísticos. Este compoñente é importante para comprender o comportamento histórico e proxectar o futuro dunha serie de datos, é habitual nos distintos criterios mencionados.\nEstacionalidade: Tamén chamada variación cíclica regular: Refírese á variación correspondente aos movementos da serie que se producen cada determinado período de tempo, Figura 4. Este compoñente é, como a tendencia, habitual nos criterios mencionados. Diferenciando en que aqueles autores que expoñen catro e cinco compoñentes denominan estacionalidade ás variacións periódicas correspondentes a períodos inferiores ou iguais a un ano (como periodicidade diaria, semanal, mensual ou anual), mentres que as variacións periódicas correspondentes a períodos máis longos contemplan. un compoñente chamado variacións cíclicas. Polo tanto, para determinar a estacionalidade dunha serie temporal, é necesario analizalas nun período non inferior a dous anos.\nUn compoñente que non se pode explicar polos outros elementos da serie temporal é a variación irregular ou o erro. Este compoñente tamén se coñece como variación aleatoria, ruído ou residual, e móstrase en Figura 4. A variación irregular é común nos tres criterios mencionados anteriormente. Algúns autores distinguen entre a variación irregular, que é ocasional e aleatoria, e a variación atípica, que se produce por eventos illados que alteran o comportamento da serie. A variación atípica pódese clasificar en varios tipos: aditiva, innovación, cambio de nivel, transitoria, estacionalidade aditiva e tendencia local.\nUnha forma de categorizar as series temporais é segundo o grao de variabilidade que presentan ao longo do tempo Segundo o exposto en Villagarcía (2006), é posible distinguir entre series homoscedásticas e heteroscedásticas. As series homoscedásticas son aquelas que manteñen un rango constante de variación, como se mostra en Figura 3. Pola contra, as series heteroscedásticas son as que cambian o rango de variación, aumentando ou diminuíndo a súa amplitude, como se ilustra nos Figura 1 e Figura 2.\nUn concepto clave na análise de series temporais é o da estacionariedade. Unha serie temporal é estacionaria cando as súas propiedades estatísticas, como a media, a varianza e a covarianza, non cambian co tempo. Isto implica que a serie non presenta tendencia, ciclos ou estacionalidade. Como sinalan Castillo and Varela (2010), Villavicencio (2010) e Ruiz (2011), a estacionariedade é unha condición necesaria para poder predicir o comportamento futuro dunha serie temporal mediante técnicas estatísticas. Un exemplo dunha serie temporal estacionaria móstrase en Figura 3.\nAs series temporais financeiras presentan heteroscedasticidade, é dicir, varianzas que cambian co tempo. Isto implica que non están estacionarios e que o seu comportamento depende de factores externos. Para verificar a estacionariedade dunha serie temporal pódense empregar diferentes métodos, como o correlograma, que mostra as funcións de autocorrelación e autocorrelación parcial da serie, ou probas de raíces unitarias, como as de Dickey Fuller ou Phillips Perron, que proban o nulo. hipótese de que a serie ten unha raíz unitaria. Estes métodos explícanse con máis detalle en Castillo and Varela (2010), Villavicencio (2010) e Ruiz (2011). O Figura 5 ilustra un exemplo de correlograma para unha serie temporal financeira."
  },
  {
    "objectID": "FSandP.html#características-de-prezos",
    "href": "FSandP.html#características-de-prezos",
    "title": "2.1 Caracterización de series temporais financeiras",
    "section": "2.1.2 Características de prezos",
    "text": "2.1.2 Características de prezos\nInvestir en accións ou en calquera outro activo cotizado na bolsa é unha tarefa complexa e desafiante, que require unha comprensión completa das tendencias e flutuacións do mercado. O núcleo desta comprensión é a capacidade de analizar e interpretar os datos dos prezos do mercado de accións, proporcionando información clave sobre o comportamento dos participantes no mercado e os factores que impulsan os movementos do mercado. A finalidade desta subsección é ofrecer unha visión xeral do entorno de prezos das accións e da súa representación habitual, sinalando os aspectos máis importantes para a aplicación das técnicas que se explorarán nos seguintes apartados.\nComo se explica en CNMV (n.d.b), os mercados de accións son mercados organizados onde se negocian accións e outros valores, como renda fixa, warrants, certificados e fondos cotizados en bolsa. En BME (n.d.) recóllese que, en España, existen catro bolsas de valores tradicionais (Madrid, Barcelona, ​​​​Bilbao e Valencia) que forman parte do holding BME (Bolsas e Mercados Españoles), que tamén integra outros segmentos e negociación, valores dos sistemas de compensación e liquidación. Sendo, segundo explican en CNMV (n.d.c), o Sistema de Interconexión Bolsa Española (SIBE) é a plataforma que permite a negociación continua e electrónica de todos os valores admitidos a negociación nas catro bolsas españolas.\nComo expón CNMV (n.d.a), as accións son valores mobiliarios que representan unha parte proporcional do capital social dunha sociedade anónima, e os seus titulares son socios propietarios da mesma. As accións poden negociarse en bolsas de valores ou noutros mercados secundarios autorizados.\nDo exposto en Mitchell (2020), Pinset (2021) e C. Team (2023) pódese concluír que, para explicar o prezo das accións dunha empresa, pódense considerar os seguintes factores:\n\nA oferta e a demanda de accións no mercado: se hai máis compradores que vendedores, o prezo subirá e viceversa. Isto depende das expectativas e da confianza dos investidores no futuro da empresa.\nCambios na xestión ou produción da empresa: se a empresa mellora a súa eficiencia, a súa rendibilidade ou a súa innovación, o prezo das súas accións poderá aumentar. Pola contra, se a empresa ten problemas internos, perde competitividade ou se ve afectada por crises externas, o prezo pode baixar.\nA reputación da empresa: se a empresa ten unha boa imaxe pública, está asociada a éxitos ou logros ou recibe boas valoracións dos analistas, o prezo das súas accións pode subir. Pola contra, se a empresa está envolta en escándalos, demandas ou polémicas, ou recibe malas valoracións dos analistas, o prezo pode baixar.\n\nNos textos Pinset (2021), T. I. Team (2022) e C. Team (2023) tamén sinalan a importancia de diferenciar o prezo dunha empresa ou a súa participación do seu valor intrínseco. Poder resumir tendo en conta o que se indica nestes textos e o que se indicou anteriormente que o prezo dunha empresa ou acción é o que compradores e vendedores están dispostos a pagar por ela nun momento determinado, mentres que o valor intrínseco dunha empresa. ou actuación depende en gran medida da metodoloxía empregada para valorar as empresas e dos obxectivos do avaliador.\nUnha vez contextualizado de forma xeral o entorno no que se atopan os prezos das accións e explicados algúns dos factores que poden afectalos, a continuación explícase a estrutura na que adoitan aparecer estes datos. Xeralmente, os prezos das accións rexístranse periodicamente (diariamente, semanalmente, mensualmente, anualmente, etc.). rexistrando para cada período o prezo de apertura, o prezo máis alto, o máis baixo, o prezo de peche, o volume e o prezo de peche axustado, consulte Táboa 1.\nPolo exposto en Barone (2022), Chen (2022), Downey (2022), Hayes (2021) e Ganti (2020) pódese entender que:\n\nO prezo de apertura é o primeiro prezo ao que se negocia un activo financeiro nunha sesión de negociación. Este prezo pode ser diferente ao prezo de peche da sesión anterior, xa que poden producirse cambios na oferta e na demanda durante o período de peche do mercado. O prezo de apertura adoita indicar o ton ou tendencia do mercado para ese día.\nO prezo máis alto é o prezo máis alto ao que se negocia un activo financeiro nunha sesión de negociación. Este prezo reflicte o nivel máis alto de interese do comprador para ese activo nese día. O prezo máis alto pode ser un indicador da fortaleza ou debilidade dun activo, así como da súa volatilidade.\nO prezo máis baixo é o prezo máis baixo ao que se negocia un activo financeiro nunha sesión de negociación. Este prezo reflicte o nivel mínimo de interese dos vendedores por ese activo nese día. O prezo máis baixo pode ser un indicador da presión ou resistencia dun activo, así como da súa volatilidade.\nO prezo de peche é o último prezo ao que se negocia un activo financeiro nunha sesión de negociación. Este prezo é o que se utiliza para calcular o valor de mercado dese activo ao final do día. O prezo de peche adoita ser o máis importante para os investidores, xa que resume o resultado das operacións do día e mostra a dirección do mercado.\nO volume é o número de unidades dun activo financeiro negociado nunha sesión de negociación. O volume mostra o nivel de actividade ou liquidez dun mercado ou dun activo. O volume adoita acompañar os movementos de prezos, xa que indica o grao de consenso ou diverxencia entre os participantes no mercado.\nO prezo de peche axustado é o prezo de peche dun activo financeiro que se modifica para ter en conta eventos como dividendos, escisións, fusións ou adquisicións que afectan ao valor do activo. O prezo de peche axustado permítelle comparar o rendemento histórico dun activo con maior precisión e coherencia.\n\nPolo exposto en Hayes (2021) e Ganti (2020), enténdese que a diferenza entre o prezo de peche e o prezo de peche axustado é de grande importancia, xa que o primeiro pode dar unha imaxe distorsionada da evolución dunha acción ao longo do ano. mentres que o segundo reflicte o valor real do stock despois de axustarse polos factores que o alteran.\n\nadministración dunha empresa pode decidir dividir as accións da empresa 3 por 1. Así, as accións en circulación da empresa aumentan por un múltiplo de tres, mentres que o prezo das súas accións divídese por tres. Digamos que unha acción pechou a $ 300 o día antes da súa división. Neste caso, o prezo de peche axústase a $ 100 ($ 300 dividido por 3) por acción para manter un estándar de comparación consistente. Do mesmo xeito, todos os demais prezos de peche anteriores para esa empresa dividiríanse por tres para obter os prezos de peche axustados. Ganti (2020)\n\nDebido a isto, o prezo de peche axustado é mellor para a aplicación de técnicas de análise de series temporais, xa que permite comparar o comportamento dunha acción ao longo do tempo sen as distorsións provocadas polos eventos corporativos. A serie temporal máis utilizada nos estudos de análise de prezos de mercado é a formada por rendementos calculados a partir do prezo de peche axustado.\n\n\n\n\nAnderson, D. R., D. J. Sweeney, T. A. Williams, D. J. Camm, and J. J Cochran. 2017. Statistics for Business & Economics. Boston: Cengage Learning.\n\n\nBarone, A. 2022. “Opening Price: Definition, Example, Trading Strategies.” 2022. https://www.investopedia.com/terms/o/openingprice.asp.\n\n\nBME. n.d. “¿Qué Es BME?” Accessed April 24, 2023. https://www.bolsasymercados.es/esp/Sobre-BME/Que-es.\n\n\nCastillo, R. A., and R. Varela. 2010. ECONOMETRÍA PRÁCTICA: Fundamentos de Series de Tiempo. México: Universidad Autónoma de Baja California.\n\n\nChen, J. 2022. “Today’s High.” 2022. https://www.investopedia.com/terms/t/todayshigh.asp.\n\n\nChirinos, S. 2018. “Series Cronológicas.” https://www.slideshare.net/SuedimarChirinos/series-cronologicas-119058959. 2018.\n\n\nCNMV. n.d.a. “Glosario Financiero: Acción.” Accessed April 24, 2023. https://cnmv.es/Portal/Inversor/Glosario.aspx?id=0&letra=A&idlng=1.\n\n\n———. n.d.b. “Glosario Financiero: Bolsa de Valores.” Accessed April 24, 2023. https://cnmv.es/Portal/Inversor/Glosario.aspx?id=0&letra=B&idlng=1.\n\n\n———. n.d.c. “Glosario Financiero: Servicio de Interconexión Bursátil Español, SIBE.” Accessed April 24, 2023. https://cnmv.es/Portal/Inversor/Glosario.aspx?id=0&letra=S&idlng=1.\n\n\nDodge, Y. 2008. “Time Series.” In The Concise Encyclopedia of Statistics, 536–39. New York, NY: Springer New York. https://doi.org/10.1007/978-0-387-32833-1_401.\n\n\nDowney, L. 2022. “Today’s Low.” 2022. https://www.investopedia.com/terms/t/todayslow.asp.\n\n\nEspallargas, S. D., and M. V. Solís. 2012. Econometría y Series Temporales: Aplicaciones. La Habana: Editorial Félix Varela.\n\n\nGanti, A. 2020. “Adjusted Closing Price.” 2020. https://www.investopedia.com/terms/a/adjusted_closing_price.asp.\n\n\nHayes, A. 2021. “What Is Closing Price? Definition, How It’s Used, and Example.” 2021. https://www.investopedia.com/terms/c/closingprice.asp.\n\n\nIBM. 2021. “Characteristics of Time Series.” https://www.ibm.com/docs/en/spss-modeler/saas?topic=data-characteristics-time-series. 2021.\n\n\nKocenda, E., and A. Cerný. 2017. Elements of Time Series Econometrics: An Applied Approach. Prague: Karolinum Press.\n\n\nMitchell, C. 2020. “Market Price: Definition, Meaning, How to Determine, and Example.” 2020. https://www.investopedia.com/terms/m/market-price.asp.\n\n\nPinset, W. 2021. “Understanding Stock Prices and Values.” 2021. https://www.investopedia.com/articles/stocks/08/stock-prices-fool.asp.\n\n\nRuiz, M. C. 2011. “Tema 5: Procesos Estocásticos.” http://www.dmae.upct.es/~mcruiz/Telem06/Teoria/apuntes_procesos.pdf; Departamento de Matemática y Estadística. Universidad Politécnica de Cartagena. 2011.\n\n\nTeam, CFI. 2023. “What Is Stock Price?” 2023. https://corporatefinanceinstitute.com/resources/capital-markets/stock-price/.\n\n\nTeam, The Investopedia. 2022. “Intrinsic Value Defined and How It’s Determined in Investing and Business.” 2022. https://www.investopedia.com/terms/i/intrinsicvalue.asp.\n\n\nVillagarcía, T. 2006. “Series Temporales.” https://halweb.uc3m.es/fjnm/estind/doc_grupo1/archivos/Apuntes%20de%20series.pdf. 2006.\n\n\nVillavicencio, J. 2010. “Introducción a Las Series de Tiempo.” http://www.estadisticas.gobierno.pr/iepr/LinkClick.aspx; Instituto de estadística de Puerto Rico. 2010."
  },
  {
    "objectID": "ANNinTSF.html#antecedentes-sobre-o-uso-de-redes-neuronais-artificiais-na-predición-de-series-temporais",
    "href": "ANNinTSF.html#antecedentes-sobre-o-uso-de-redes-neuronais-artificiais-na-predición-de-series-temporais",
    "title": "2.2 Redes neuronais artificiais na previsión de series temporais",
    "section": "2.2.1 Antecedentes sobre o uso de redes neuronais artificiais na predición de series temporais",
    "text": "2.2.1 Antecedentes sobre o uso de redes neuronais artificiais na predición de series temporais\nEn Chollet and Allaire (2018) indícase que o entorno ANN está formado por intelixencia artificial (en diante IA), aprendizaxe automática ou aprendizaxe automática (en diante ML) e aprendizaxe profunda ou aprendizaxe profunda (en diante DL), (fig?) -DLenv. Por iso, é de vital importancia coñecer os aspectos destes campos que están intimamente relacionados coa RNA e que se explican brevemente a continuación.\n“Facer que unha máquina se comporte de tal forma que un humano sería chamado intelixente” (McCarthy et al. (2006), p.11) é a primeira definición que se dá ao problema da IA. Co obxectivo de resolver este problema xurdiu a primeira IA, a chamada IA ​​simbólica.\nComo explicaron Haykin (1998), Banda (2014) e Chollet and Allaire (2018), estas primeiras IAs implicaban regras codificadas creadas polos programadores. Co obxectivo de conseguir que estas regras fosen aprendidas automaticamente polas máquinas ao observar os datos, xurdiu unha nova etapa no desenvolvemento da IA, a denominada ML. Esta nova etapa dá lugar á aparición dunha nova forma de programación, diferenciada da clásica, na medida en que, nesta, os programadores introducen os datos e as respostas esperadas a eles, e os ordenadores son capaces de xerar as regras, Figura 2.\nPolo tanto, enténdese que os modelos de ML intentan atopar representacións axeitadas para os seus datos de entrada: transformacións dos datos que o fan máis apto para a tarefa en cuestión. En DL, que é un subcampo específico de ML, estas representacións de datos modelízanse mediante arquitecturas compostas por capas sucesivas, que se denominan ARN Chollet and Allaire (2018).\nDespois de estudar o que se expuxo en Haykin (1998), Larrañaga (2007), Banda (2014) e Chollet and Allaire (2018) sobre ANN, pódese afirmar que están inspirados no funcionamento do cerebro humano, estes textos confirman e coinciden en que se poden distinguir tres tipos de ANN capas. : entrada, saída e oculta. Unha capa de entrada está composta por neuronas que reciben os vectores de entrada. Unha capa de saída está formada por neuronas que, durante o adestramento, reciben os vectores de saída e despois xeran a resposta. Unha capa oculta está conectada ao ambiente a través das capas de entrada e saída, este tipo de capa oculta procesa a entrada recibida para obter a saída correspondente, Figura 3.\nUnha das aplicacións da ANN é a previsión de series temporais. cuxo obxectivo é predicir os valores futuros das variables en función das súas observacións pasadas. Como se comentou anteriormente, as series temporales financeiras adoitan ser non lineais, ruidosas, caóticas e non estacionarias, o que dificulta a súa modelización e previsión. As ANN teñen a vantaxe de poder captar relacións non lineais complexas e adaptarse ás condicións cambiantes sen esixir presupostos previos sobre a distribución ou estrutura dos datos.\nA historia das ANN na previsión de series temporais financeiras remóntase a finais dos 80 e principios dos 90, cando os investigadores comezaron a explorar o potencial das ANN como alternativa aos métodos estatísticos tradicionais, como o modelo de media móbil autorregresiva integrada, máis coñecido como ARIMA. Autoregresivo Integrado Moving Average) e modelos autorregresivos xeneralizados con heterocedasticidade condicional, máis coñecidos como GARCH (Heterocedasticidade Condicional Autorregresiva Xeneralizada). Demostrouse que as ANN teñen varias vantaxes sobre estes métodos, como a capacidade de capturar relacións non lineais e dinámicas, manexar datos ruidosos e incompletos e adaptarse ás condicións cambiantes do mercado (B. Eddy Patuwo & Michael Y. Hu (1998)).\nNon obstante, as ANN tamén se enfrontan a algunhas limitacións e desafíos na previsión de series temporais financeiras, como a dificultade de escoller unha arquitectura de rede adecuada, un algoritmo de adestramento, a función de activación e as variables de entrada; o risco de problemas de sobreadaptación e xeneralización; a falta de interpretabilidade e transparencia; e o alto custo e tempo computacional (Tealab (2018)).\nPara superar estas limitacións e desafíos, os investigadores propuxeron varias melloras e ampliacións de ANN para a previsión de series temporais financeiras nas últimas décadas. Algúns dos principais desenvolvementos inclúen:\n\nO uso de modelos híbridos que combinan ANN con outras técnicas como a lóxica difusa, algoritmos xenéticos, análise de wavelets, máquinas vectoriais de soporte e aprendizaxe profunda para mellorar o rendemento e a robustez da ANN (Wong and Guo (2010)).\nO uso de redes neuronais recorrentes (en diante RNR) ou bidireccionais, que son un tipo especial de ANN que poden procesar datos secuenciais e capturar dependencias temporais. Demostrouse que os RNR superan as redes neuronais unidireccionais en series temporales complexas e non lineais (Guresen, Kayakutlu, and Daim (2011)).\nO uso de modelos de ARN máis complexos mediante a combinación de diferentes capas, como redes neuronais convolucionais (en diante, CNN), memoria a longo prazo (en diante, LSTM), unidades recorrentes gated (en diante GRU) aplicouse á previsión de series temporais financeiras con resultados prometedores (Sezer, Gudelek, and Ozbayoglu (2020)).\n\nA historia das ANN na previsión de series temporais financeiras mostra que as ANN evolucionaron e melloraron co paso do tempo para facer fronte á complexidade e incerteza dos mercados financeiros. Non obstante, aínda persisten algúns dos desafíos e limitacións mencionados anteriormente, como o sobreajuste, a xeneralización, a interpretabilidade, a robustez e o custo computacional."
  },
  {
    "objectID": "ANNinTSF.html#redes-neuronais-convolucionais",
    "href": "ANNinTSF.html#redes-neuronais-convolucionais",
    "title": "2.2 Redes neuronais artificiais na previsión de series temporais",
    "section": "2.2.2 Redes neuronais convolucionais",
    "text": "2.2.2 Redes neuronais convolucionais\nO modelo de ARN empregado neste traballo está composto por varias capas, sendo a máis importante a capa Conv1D, un tipo específico de CNN, e a capa LSTM, ambas as mencionadas no subapartado anterior cando as estruturas ANN que máis se utilizan na actualidade. Esta subsección céntrase na Capa Conv1D, polo que se exploran os conceptos fundamentais para comprender o seu funcionamento, explicando a convolución, as redes neuronais convolucionais e Conv1D e o seu uso para a análise de series temporais. Ofrécese unha visión xeral da convolución e como se pode aplicar aos datos de series temporais. Despois, fálase das CNN e da súa arquitectura, que lles permite aprender automaticamente funcións a partir de datos de series temporais. Finalmente, explícase Conv1D, un tipo específico de capa de rede neuronal convolucional que é particularmente eficaz para procesar datos de series temporais.\nComo se comenta en Siddiqui (2023), a convolución é unha operación matemática que se usa habitualmente no procesamento de sinal e análise de imaxes. Implica tomar dúas funcións e producir unha terceira función que representa como unha das funcións orixinais modifica a outra. No contexto dos datos de series temporais, a convolución pódese usar para extraer características dos datos aplicando un filtro á serie temporal.\nAdemais de extraer funcións dos datos de series temporais, a convolución tamén se pode usar para outras tarefas como a redución de ruído, a detección de anomalías e a predición. Por exemplo, unha CNN pódese adestrar para predecir os valores futuros dunha serie temporal aprendendo os patróns subxacentes nos datos. En xeral, a convolución é unha poderosa ferramenta para analizar datos de series temporais e as súas aplicacións son numerosas Siddiqui (2023).\nAs CNN introducíronse por primeira vez en Lecun et al. (1998) e son un tipo de modelo de aprendizaxe profunda que se usa habitualmente para a análise de imaxes. Non obstante, como se mencionou anteriormente, tamén se poden usar para a análise de series temporais, xa que son moi axeitados para aprender características a partir de datos que teñen unha estrutura espacial ou temporal.\nA arquitectura dunha CNN consta dunha ou máis capas convolucionais, que aplican filtros aos datos de entrada para extraer características. Cada filtro é un conxunto de pesos que se aprenden durante o proceso de adestramento. Ao desprazar o filtro sobre os datos de entrada, a capa convolucional calcula un produto puntual en cada posición, producindo un novo mapa de características Lecun et al. (1998).\nNun contexto de series temporais, unha CNN pode aprender a extraer automaticamente características dos datos a diferentes escalas e intervalos de tempo, o que o converte nunha poderosa ferramenta para a análise de series temporais. Unha vantaxe fundamental de usar unha CNN para a análise de series temporais é que reduce a necesidade de enxeñería manual de funcións. En lugar de deseñar filtros a man, CNN aprende a extraer automaticamente funcións dos datos, facéndoos máis flexibles e adaptables a diferentes tipos de datos de series temporais.\nEn xeral, a arquitectura dunha CNN permítelle aprender automaticamente características dos datos de series temporais, o que o converte nunha poderosa ferramenta para a análise de series temporais, sendo Conv1D unha das estruturas de CNN máis utilizadas para esta tarefa.\nComo se explica en Jing (2020), Conv1D é un tipo específico de capa CNN que está deseñada para procesar datos unidimensionales, como datos de series temporais. Mentres que as CNN tradicionais están deseñadas para procesar datos bidimensionais, Conv1D está optimizado especificamente para datos unidimensionais, o que o fai máis eficiente e eficaz para a análise de series temporais.\nA arquitectura dunha capa Conv1D é similar á dunha CNN tradicional, pero con algunhas diferenzas clave. En lugar de usar filtros bidimensionais, Conv1D usa filtros unidimensionais, que se aplican á serie temporal de entrada para extraer características. As características que se extraen da cadea dependerán das diferentes configuracións utilizadas para a configuración do filtro e do número de filtros empregados, sendo a seguinte fórmula para calcular a cantidade de característica que extrae cada filtro: Ecuación 1 (Jing (2020)):\n\\[\n\\begin{aligned}\nL_{out} &= \\frac{L_{in} + 2*padding - dilation*(kerenel\\_size - 1)-1}{stride} + 1 \\\\\n\\end{aligned}\n\\tag{1}\\]\nOnde:\n\nLout: é a lonxitude da saída do proceso de filtrado ou o número de funcións.\n\n\nLin: a lonxitude do vector de entrada, correspondente na análise de series temporais ao número de observacións que conteñen as mostras da serie temporal que se pasan ao filtro.\n\n\nkernel_size: é o tamaño do filtro, que define cantas observacións do vector de entrada se pasan ao filtro cada vez. Figura 4 representa como o tamaño do filtro pode afectar a lonxitude do vector de saída.\n\n\nstride: representa o número de pasos ou observacións polos que se move a selección de observacións pasadas ao filtro. Figura 5 representa como o parámetro stride pode afectar a lonxitude do vector de saída.\n\n\ndilation: é a distancia das observacións que pasan polo filtro. Figura 6 representa como o parámetro de dilatación pode afectar a lonxitude do vector de saída.\n\n\npadding: representa o número de ceros a engadir a cada extremo do vector. Figura 7 representa como o parámetro de recheo pode afectar a lonxitude do vector de saída.\n\nEn xeral, Conv1D é unha poderosa ferramenta para procesar datos de series temporais e as súas vantaxes inclúen a eficiencia computacional e a capacidade de capturar dependencias de tempo nos datos. Os seus casos de uso son numerosos e abarcan diferentes campos, polo que é unha ferramenta valiosa para a análise de series temporais."
  },
  {
    "objectID": "ANNinTSF.html#long-short-term-memory",
    "href": "ANNinTSF.html#long-short-term-memory",
    "title": "2.2 Redes neuronais artificiais na previsión de series temporais",
    "section": "2.2.3 Long short-term memory",
    "text": "2.2.3 Long short-term memory\nEsta subsección explica por que os LSTM son unha das estruturas ANN máis utilizadas na predición de series temporais, baseándose nunha breve explicación dos RNR e por que son útiles para resolver problemas de predición de series. as RNN, e o funcionamento de cada unha das capas que conforman a estrutura dunha capa LSTM.\nOlah (2015) explica que unha RNN pode considerarse como varias copias da mesma rede, Figura 8, afirma que este aspecto revela que os RNR están íntimamente relacionados con secuencias e listas, o que fai que este tipo de ARN sexa o que naturalmente se utiliza para traballar con series temporais.\nOs RNR convencionais presentan un problema en relación coa capacidade de reter información, como explica Olah (2015), os RNN estándar só funcionan con gran capacidade se a información relevante para a situación actual é recente, é dicir, onde a brecha entre a información relevante e onde se é necesario é pequeno, Figura 9; ademais expón que a medida que a brecha crece, os RNN estándar non poden acceder á información relevante, Figura 10.\nComo se mencionou anteriormente, os LSTM son un tipo de RNR que pode aprender dependencias a longo prazo dos datos secuenciais. Estes foron propostos en Hochreiter (1997) e foron moi utilizados para varias tarefas como modelado de linguaxe, recoñecemento de voz, tradución automática, descrición de imaxes e previsión de series temporais.\nA idea principal de LSTM é introducir unha célula de memoria que poida almacenar e actualizar información en pasos longos. A cela de memoria está controlada por tres portas: unha porta de entrada, unha porta de esquecemento e unha porta de saída. Estas portas son redes neuronais que aprenden a regular o fluxo de información dentro e fóra da célula Figura 11.\nA porta de entrada decide canto da nova entrada engadir ao estado da cela. A porta de esquecemento decide que parte do estado da cela anterior manter ou eliminar. A porta de saída decide que parte do estado da cela actual se enviará á seguinte capa. Olah (2015) baseándose no exposto en Hochreiter (1997), describe o funcionamento das portas en catro pasos:\n\nDecidindo que información do estado da cela se esquece a través da porta, esquece a capa de porta \\(f_t\\). Esta porta mira \\(h_{t-1}\\), estado oculto do período de tempo anterior, e \\(x_{t}\\), entrada do instante de tempo actual, e mostra un número entre 0 (desfacer) e 1 (mantener) . para cada número no estado da cela \\(C_{t-1}\\), Figura 12, Ecuación 2.\n\n\\[\n\\begin{aligned}\nf_t &= \\sigma(W_f [h_{t-1}, x_t] + b_f) \\\\\n\\end{aligned}\n\\tag{2}\\]\n\nDecida que información nova se almacena no estado da cela. Para isto primeiro, a capa de porta de entrada decide que valores actualizar e despois unha capa tanh (tanxente hiperbólica) crea un vector de novos valores candidatos (\\(\\tilde{C}_t\\)) que se poden engadir ao estado, Figura 13, Ecuación 3 y Ecuación 4.\n\n\\[\n\\begin{aligned}\ni_t &= \\sigma(W_i [h_{t-1}, x_t] + b_i) \\\\\n\\end{aligned}\n\\tag{3}\\]\n\\[\n\\begin{aligned}\n\\tilde{C}_t &= tanh(W_c [h_{t-1}, x_t] + b_c) \\\\\n\\end{aligned}\n\\tag{4}\\]\n\nO estado da cela antiga, \\(C_{t-1}\\), actualízase ao novo estado da cela \\(C_{t}\\). Multiplica o estado anterior por \\(f_{t}\\), esquecendo o que é necesario, despois engade \\(i_{t} * \\tilde{C}_{t}\\). Estes son os novos valores candidatos, escalados pola cantidade de cada valor de estado que se debe actualizar, Figura 14, Ecuación 5.\n\n\\[\n\\begin{aligned}\nC_t &= f_t * C_{t-1} + i_t * \\tilde{C}_t  \\\\\n\\end{aligned}\n\\tag{5}\\]\n\nXérase unha saída en función do estado da cela. Executar primeiro unha capa sigmoide que decide que partes do estado da célula é a saída; entón o estado da cela pásase a través dunha función tanh (escalando os valores entre -1 e 1) e multiplícase pola saída da porta, porta de saída, Figura 15, Ecuación 6 y Ecuación 7.\n\n\\[\n\\begin{aligned}\no_t &= \\sigma(W_o [h_{t-1}, x_t] + b_o) \\\\\n\\end{aligned}\n\\tag{6}\\] \\[\n\\begin{aligned}\nh_t &= o_t * tanh(C_t) \\\\\n\\end{aligned}\n\\tag{7}\\]\nOs LSTM poden aprender a capturar dependencias a longo prazo axustando os valores de porta a través da propagación posterior. Por exemplo, se unha determinada entrada é relevante para unha saída posterior, a porta de entrada aprenderá a deixala entrar e a porta esquecida aprenderá a mantela no estado da cela ata que sexa necesaria. Pola contra, se unha entrada é irrelevante ou obsoleta, a pasarela aprenderá a ignorala e a porta esquecida aprenderá a eliminala do estado da cela.\n\n\n\n\nB. Eddy Patuwo & Michael Y. Hu, Guoqiang Zhang &. 1998. “Forecasting with Artificial Neural Networks:: The State of the Art.” International Journal of Forecasting 14 (1): 35–62. https://doi.org/https://doi.org/10.1016/S0169-2070(97)00044-7.\n\n\nBanda, Hugo. 2014. Inteligencia Artificial: Principios y Aplicaciones. Quito, Ecuador: Escuela Politécnica Nacional.\n\n\nChollet, F., and J. J. Allaire. 2018. Deep Learning with r. Manning Publications. https://books.google.es/books?id=xnIRtAEACAAJ.\n\n\nGuresen, Erkam, Gulgun Kayakutlu, and Tugrul U. Daim. 2011. “Using Artificial Neural Network Models in Stock Market Index Prediction.” Expert Systems with Applications 38 (8): 10389–97. https://doi.org/https://doi.org/10.1016/j.eswa.2011.02.068.\n\n\nHaykin, Simon. 1998. Neural Networks: A Comprehensive Foundation. Prentice Hall PTR.\n\n\nHochreiter, Jürgen, Sepp & Schmidhuber. 1997. “Long Short-Term Memory.” Neural Computation 9 (8): 1735–80. https://doi.org/10.1162/neco.1997.9.8.1735.\n\n\nJing, Hong. 2020. “How Convolutional Layers Work in Deep Learning Neural Networks?” Jingles, Github Blog. 2020. https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/.\n\n\nLarrañaga, Iñaki & Moujahid, Pedro & Inza. 2007. “Tema 14. Redes Neuronales.” Departamento de Ciencias de la Computaci´on e Inteligencia Artificial, Universidad del Pa´ıs Vasco–Euskal Herriko Unibertsitatea. 2007. http://www.sc.ehu.es/ccwbayes/docencia/mmcc/docs/t14-neuronales.pdf.\n\n\nLecun, Y., L. Bottou, Y. Bengio, and P. Haffner. 1998. “Gradient-Based Learning Applied to Document Recognition.” Proceedings of the IEEE 86 (11): 2278–2324. https://doi.org/10.1109/5.726791.\n\n\nMcCarthy, John, Marvin L. Minsky, Nathaniel Rochester, and Claude E. Shannon. 2006. “A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence, August 31, 1955.” AI Magazine 27 (4): 12. https://doi.org/10.1609/aimag.v27i4.1904.\n\n\nOlah, Christopher. 2015. “Understanding LSTM Networks.” Colah’s blog. 2015. https://colah.github.io/posts/2015-08-Understanding-LSTMs/.\n\n\nSezer, Omer Berat, Mehmet Ugur Gudelek, and Ahmet Murat Ozbayoglu. 2020. “Financial Time Series Forecasting with Deep Learning : A Systematic Literature Review: 2005–2019.” Applied Soft Computing 90: 106181. https://doi.org/https://doi.org/10.1016/j.asoc.2020.106181.\n\n\nSiddiqui, J. Rafid. 2023. “Why Convolve? Understanding Convolution and Feature Extraction in Deep Networks.” Medium, Towards Data Science. 2023. https://towardsdatascience.com/why-convolve-understanding-convolution-and-feature-extraction-in-deep-networks-ee45d1fdd17c.\n\n\nTealab, Ahmed. 2018. “Time Series Forecasting Using Artificial Neural Networks Methodologies: A Systematic Review.” Future Computing and Informatics Journal 3 (2): 334–40. https://doi.org/https://doi.org/10.1016/j.fcij.2018.10.003.\n\n\nWong, W. K., and Z. X. Guo. 2010. “A hybrid intelligent model for medium-term sales forecasting in fashion retail supply chains using extreme learning machine and harmony search algorithm.” International Journal of Production Economics 128 (2): 614–24. https://ideas.repec.org/a/eee/proeco/v128y2010i2p614-624.html."
  },
  {
    "objectID": "PC.html#problema-e-técnicas",
    "href": "PC.html#problema-e-técnicas",
    "title": "2.3 Composición de carteiras",
    "section": "2.3.1 Problema e técnicas",
    "text": "2.3.1 Problema e técnicas\nComo explica Gunjan (2023), a optimización da carteira é o proceso de selección da mellor combinación de activos para manter nunha carteira en función de obxectivos predefinidos. Os obxectivos poden ser a maximización do retorno ou a minimización do risco, ou ambos. A optimización da carteira implica atopar os pesos óptimos para cada activo da carteira para que a carteira global cumpra os obxectivos desexados. Este pode ser un problema desafiante debido á gran cantidade de activos para escoller e ás complexas relacións entre eles.\nA optimización da carteira é un proceso importante para os investimentos, xa que lles axuda a minimizar o risco e maximizar o retorno dos seus investimentos. Ao seleccionar coidadosamente os activos para manter na súa carteira, os investimentos poden acadar o nivel de risco e rendemento desexados ao tempo que diversifican os seus investimentos para reducir o risco global. A optimización da carteira é un mecanismo crucial utilizado para reducir o risco de investimento.\nExisten varias técnicas que se poden utilizar para resolver o problema de optimización da carteira. En Gunjan (2023) estas técnicas clasifícanse en dúas categorías: enfoques clásicos e enfoques intelixentes. A continuación móstrase unha explicación xeral dalgunhas das técnicas pertencentes a cada enfoque.\nEnfoques clásicos:\n\nMedia-varianza: esta técnica, proposta en Markowitz and Markowitz (1967), baséase na idea de minimizar a varianza para un rendemento esperado determinado ou maximizar o retorno esperado para unha varianza determinada. É unha técnica de programación cuadrática paramétrica (en diante PQP) que se pode utilizar para resolver problemas de optimización cuadrática que xorden na optimización de carteiras (Aijun Zhang & Chun-hung Li & Agus Sudjianto (2008)). O enfoque da varianza media asume que os investimentos son reacios ao risco e prefiren carteiras con menor varianza. A técnica consiste en construír unha fronteira de carteira que represente o conxunto de carteiras que ofrecen o maior rendemento esperado para un determinado nivel de risco. A continuación, selecciónase a carteira óptima desta fronteira en función das preferencias de risco do investidor.\nVarianza sesgada: esta técnica amplía o enfoque da varianza media ao contabilizar a distribución sesgada. Propúxose en Samuelson (1970) e pódese usar cando a función de distribución non é de natureza cuadrática. A asimetría mide a asimetría dunha distribución e pode proporcionar información adicional sobre os riscos potenciais e os rendementos dunha carteira. Ao incorporar a asimetría ao proceso de optimización da carteira, os investidores poden comprender mellor os posibles riscos negativos e tomar decisións máis informadas.\nValor en risco (VaR): este enfoque estatístico mide a potencial perda de valor dunha carteira durante un período definido para un determinado intervalo de confianza. Introduciuse na primeira edición de Jorion (2007) en 1997 e require a determinación de tres parámetros: período de tempo, nivel de confianza e unidade de valor en risco. O VaR proporciona unha medida da perda potencial máxima que podería ocorrer cunha probabilidade determinada nun horizonte temporal especificado. É habitualmente utilizado polas entidades financeiras para xestionar a súa exposición ao risco e cumprir cos requisitos regulamentarios.\nValor en risco condicional (CVaR): este enfoque amplía o VaR tendo en conta a perda esperada que supera o VaR. Introduciuse en Rockafellar and Uryasev (2002) e pode xestionar perdas extremas mediante o uso de pesos dinámicos derivados de datos históricos. O CVaR proporciona unha medida da perda esperada que podería ocorrer máis aló do limiar de VaR. Tamén se coñece como Expected Shortfall (ES) ou Tail Value-at-Risk (TVaR) e considérase unha medida de risco máis consistente que o VaR.\nDesviación media absoluta (MAD): esta técnica pódese usar para problemas de selección de carteiras a gran escala e moi diversificados. Introduciuse en Konno and Yamazaki (1991) e penaliza as desviacións tanto positivas como negativas. MAD proporciona unha medida da desviación absoluta media dos rendementos da carteira do seu valor medio. Considérase máis robusta que as medidas baseadas na varianza, xa que é menos sensible aos valores atípicos.\nMinimax: esta técnica utiliza o rendemento mínimo como medida de risco. Introduciuse en Cai et al. (2004) e ten certas vantaxes cando os rendementos non se distribúen normalmente. Minimax ofrece unha medida no peor dos casos para unha carteira minimizando a máxima perda potencial que podería ocorrer. Pode ser útil para os investimentos que están especialmente preocupados polos riscos á baixa.\n\nEnfoques intelixentes:\n\nRedes bayesianas: estes modelos gráficos probabilísticos pódense usar para modelar o risco e o rendemento. Presentáronse en Shenoy and Shenoy (2000) e pódense usar para visualizar a relación entre diferentes variables nun modelo. As redes bayesianas proporcionan unha forma de representar dependencias complexas entre variables mediante gráficos acíclicos dirixidos (DAG). Pódense usar para modelar relacións incertas entre variables e para facer predicións probabilísticas sobre eventos futuros. No contexto da xestión de carteiras, as redes bayesianas poden usarse para modelar as relacións entre diferentes activos e facer predicións sobre os seus retornos futuros en base a datos históricos e outra información relevante.\nRegresión vectorial de soporte (SVR): esta técnica de aprendizaxe automática pódese usar para determinar a cantidade a mercar e vender. Foi introducido por Drucker et al. (1996) e ten certas vantaxes sobre as técnicas baseadas en estatísticas, como a súa capacidade para aprender a partir de datos históricos. SVR implica construír un hiperplano que separa os puntos de datos con diferentes etiquetas ao tempo que maximiza a marxe entre eles. Pódese usar para tarefas de regresión onde o obxectivo é predicir valores continuos en lugar de etiquetas discretas. No contexto da xestión de carteiras, o SVR pódese usar para predecir os prezos futuros dos activos baseándose en datos históricos e outra información relevante.\nRedes neuronais artificiais: como se explicou anteriormente, estes modelos computacionais pódense utilizar para resolver problemas complexos de cómputo e aprendizaxe. No contexto da xestión de carteiras, as redes neuronais pódense usar para predecir os prezos futuros dos activos ou os rendementos en función de datos históricos e outra información relevante, que é para o que se utilizan neste documento.\nAprendizaxe por reforzo: este tipo de aprendizaxe automática implica que un axente ou modelo interactúa co seu entorno para aprender das súas accións. Presentouse en Sutton and Barto (2018) e traballa para maximizar a recompensa dos axentes. A aprendizaxe por reforzo implica a aprendizaxe mediante interaccións de proba e erro cun ambiente. O axente realiza accións en función do seu estado actual e recibe recompensas ou penalizacións en función dos resultados desas accións. Co tempo, o axente aprende a tomar accións que maximizan a súa recompensa acumulada. No contexto da xestión de carteiras, a aprendizaxe de reforzo pódese utilizar para desenvolver estratexias comerciais que maximicen os rendementos ao mesmo tempo que xestionan o risco."
  },
  {
    "objectID": "PC.html#programación-cuadrática",
    "href": "PC.html#programación-cuadrática",
    "title": "2.3 Composición de carteiras",
    "section": "2.3.1 Programación cuadrática",
    "text": "2.3.1 Programación cuadrática\nEste subtítulo explica o que é a programación cuadrática. Cales son algunhas das técnicas que existen dentro desta disciplina de optimización matemática. Tamén se expón como se pode describir o problema de optimización da carteira como un problema de programación cuadrática e explícase brevemente como funciona unha das técnicas máis empregadas nesta disciplina, concretamente o denominado Método de conxunto activo dual, que se emprega nos capítulos posteriores.\nA programación cuadrática pódese escoller entre as técnicas enumeradas no subtítulo anterior por varias razóns. En primeiro lugar, é unha técnica ben establecida que foi amplamente utilizada na optimización da carteira. Pode xestionar problemas de optimización complexos con múltiples restricións e pode proporcionar unha forma eficiente e eficaz de resolver o problema de optimización da carteira. Isto convérteo nunha ferramenta útil para os investimentos que buscan minimizar o risco ao acadar o nivel de retorno desexado. Finalmente, a programación cuadrática ten unha sólida base teórica e foi amplamente estudada na literatura. Isto fai que sexa unha técnica fiable e ben entendida que se pode usar con confianza na optimización da carteira.\nExisten varias técnicas de programación cuadrática, entre as máis utilizadas están:\n\nPunto interior: Este é un método de programación lineal ou non lineal que consegue a optimización pasando polo centro do sólido definido polo problema en lugar de arredor da súa superficie. Karmarkar (1984) atopou un algoritmo de programación lineal tempo polinómico usando un método de punto interior.\nConxunto activo: este é un algoritmo usado para identificar as restricións activas nun conxunto de restricións de desigualdade. As restricións activas exprésanse entón como restricións de igualdade, transformando así un problema restrinxido de desigualdade nun subproblema máis simple de restricións de igualdade. O método de conxunto activo foi introducido por primeira vez nun artigo de Beale (1959) e desenvolvido por Fletcher (1971) e Bunch and Kaufman (1977).\nConxunto activo dual: o método, tal e como se expón Goldfarb and Idnani (1982) e Goldfarb and Idnani (1983), é un algoritmo dual eficiente e numéricamente estable para a programación cuadrática definida positiva que aproveita o feito de que o mínimo non restrinxido da función obxectivo pode ser usado como un punto de saída.\nLagrangiano aumentado: introduciuse de forma independente en Magnus R. Hestenes (1969) e Powell (1969). Utilízase para resolver problemas de optimización restrinxida engadindo un termo de penalización á función obxectivo que penaliza calquera violación das restricións. O termo de penalización adoita ser un múltiplo dunha medida de infracción de restricións, como a suma de infraccións de restricións ao cadrado.\nGradiente conxugado: este é un método iterativo para resolver sistemas de ecuacións lineais cunha matriz definida positiva simétrica. Tamén se pode usar para resolver problemas de optimización sen restricións atopando o mínimo dunha función cuadrática. O método xera unha secuencia de enderezos de busca que se conxugan con respecto á matriz que define o sistema de ecuacións ou función cuadrática. O método de gradiente conxugado foi introducido orixinalmente nun artigo de Magnus R. Hestenes and Stiefel (1952).\nProxección de gradientes: o método de proxección de gradientes introduciuse en J. B. Rosen (1960) e J. Rosen (1961). Este é un método iterativo para resolver problemas de optimización restrinxida proxectando o gradiente na rexión factible en cada iteración. O gradiente proxectado utilízase entón como dirección de busca e realízase unha busca de liña ao longo desta dirección para atopar unha nova iteración que satisfaga as restricións e reduza a función obxectivo.\n\nEntre as técnicas mencionadas anteriormente, seleccionouse o algoritmo Dual Active Set Method (en diante, DASM) que, como se mencionou anteriormente, foi introducido en Goldfarb and Idnani (1982) e Goldfarb and Idnani (1983), é un algoritmo de optimización para resolver problemas de programación cuadrática. O algoritmo predice o conxunto activo de restricións que se satisfacen igualmente na solución do problema. Calcula unha secuencia de solucións óptimas de problemas QP que implican algunhas das restricións do problema orixinal, chamada secuencia de puntos factibles duais.\nA continuación móstrase un exemplo xeral de como o algoritmo DASM podería funcionar usando os valores que ocorren para un problema de optimización de carteira de 2 activos, o exemplo foi construído a partir de Goswami, Mondal, and Paruya (2012) e Walker (2014):\nBaixo o suposto de que se trata de atopar a mellor composición dunha carteira na que, por simplicidade, teñamos 2 activos, o problema cuadrático exporíase do seguinte xeito Ecuación 1:\n\\[\n\\begin{aligned}\nmin~~Q(\\vec{w}) &= \\vec{w}^TC\\vec{w}\\\\\nsujeto~a:\\\\\nw_{1}+w_{2}=1\\\\\n0\\leq{w_{i}}\\leq{1}\\\\\nw_{1}\\mathbb{E} + w_{2}\\mathbb{E} \\geq{0.005}\n\\end{aligned}\n\\tag{1}\\]\nAsumindo que teñen rendementos mensuais medios \\(r=\\begin{bmatrix} 0,02 & 0,03 \\end{bmatrix}\\) e unha matriz de covarianza \\(C=\\begin{bmatrix} 0,001 & 0,0008 \\\\ 0,0008 & 0,002 \\end{bmatrix}\\) Os vectores e matrices necesarios para o algoritmo DASM pódense construír do seguinte xeito:\n\nO vector de retorno mensual medio sería \\(r=\\begin{bmatrix} 0.02 & 0.03 \\end{bmatrix}\\).\nA matriz de covarianza C utilizaríase como matriz D en DASM.\nA restrición \\(w_{1}+w_{2}=1\\) pódese escribir en forma de matriz como $\n\\[\\begin{bmatrix} 1 & 1 \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix}\\]\n= $1. Esta sería a primeira fila da matriz \\(A\\) en DASM.\nO requisito mínimo de retorno \\(w_{1}\\mathbb{E} + w_{2}\\mathbb{E} \\geq{0,005}\\) pódese escribir en forma de matriz como \\(\\begin{bmatrix} 0,02 & 0,03 \\end{ bmatrix } \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} \\geq{0,005}\\). Esta sería outra fila da matriz \\(A\\) en DASM.\nAs restricións \\(0\\leq{w_i}\\leq{1}\\) pódense escribir en forma de matriz como \\(\\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} \\geq{0}\\) e \\(\\begin{bmatrix} 0 & 1 \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} \\geq{0}\\) para os límites inferiores e \\(\\begin{bmatrix } -1 & 0 \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} \\geq{-1}\\) e \\(\\begin{bmatrix} 0 & -1 \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} \\geq{-1}\\) para os límites superiores.\nA matriz \\(A\\) sería así: \\(A=\\begin{bmatrix} 1 & 1 \\\\ 0.02 & 0.03 \\\\ 1 & 0 \\\\ 0 & 1 \\\\ -1 & 0 \\\\ 0 & -1 \\end{bmatrix}\\)\n\nO vector correspondente \\(b\\) sería \\(\\begin{bmatrix} 1 & 0,005 & 0 & 0 & -1 & -1\\end{bmatrix}\\). Despois podemos usar o algoritmo DASM para resolver este problema de programación cuadrática e determinar a asignación óptima de activos na nosa carteira.\nPaso 0: atopar o mínimo sen restricións resolvendo o problema de programación cuadrática sen restricións. Establece o número de elementos do conxunto activo A (conxunto baleiro) en cero.\nPaso 1: Escolla unha restrición violada, se a houbera. Neste caso, supoña que se infrinxe a restrición \\(w_{1}+w_{2}=1\\).\nPaso 2: Calcula as direccións do paso primario e dobre e a lonxitude do paso \\(t=min(t_{1},t_{2})\\). Supoña \\(t=t_{2}\\).\nPaso 3: intensifica e actualiza o conxunto activo A e a solución (\\(S\\)) para o par (x, A). Dado que \\(t=t_{2}\\) , engadimos a restrición pth (neste caso \\(w_1+w_2=1\\)) a \\(\\bar{N}\\) e actualizamos \\(H\\) e \\(N^{*}\\) en Ecuación 2.\n\\[\n\\begin{aligned}\nN^{*}=(\\bar{N}^{T}Q^{-1}\\bar{N})\\bar{N}^{T}Q^{-1}\\\\\nH=Q^{-1}(I-\\bar{N}N^{*})\n\\end{aligned}\n\\tag{2}\\]\nOnde:\n\n\\(N^{*}\\) é a inversa pseudo-inversa ou xeralizada de Moore-Penrose \\(\\bar{N}\\).\n\n\n\\(\\bar{N}\\) é a matriz dos vectores normais das restricións no conxunto activo \\(A\\).\n\n\n\\(H\\) é o operador de Hessian inverso reducido de \\(Q\\).\n\nEstes pasos repítense de forma iterativa ata que se cumpran todas as restricións e se determine a asignación óptima de activos.\n\n\n\n\nAijun Zhang & Chun-hung Li & Agus Sudjianto, Zhi-li Wu &. 2008. “Trace Solution Paths for SVMs via Parametric Quadratic Programming.” Researchgate. 2008. https://www.researchgate.net/publication/228577955_Trace_solution_paths_for_SVMs_via_parametric_quadratic_programming.\n\n\nBeale, EML. 1959. “On Quadratic Proramming.” Naval Research Logistics Quarterly 6 (3): 227–43.\n\n\nBunch, James R, and Linda Kaufman. 1977. “Some Stable Methods for Calculating Inertia and Solving Symmetric Linear Systems.” Mathematics of Computation 31 (137): 163–79.\n\n\nCai, Xiaoqiang, Kok Lay Teo, XQ Yang, and Xun Yu Zhou. 2004. “Minimax Portfolio Optimization: Empirical Numerical Study.” Journal of the Operational Research Society 55 (1): 65–72.\n\n\nDrucker, Harris, Christopher Burges, Linda Kaufman, Alex Smola, and Vladimir Vapnik. 1996. “Linear Support Vector Regression Machines.” Advances in Neural Information Processing Systems 9 (9): 155–61.\n\n\nFletcher, Roger. 1971. “A General Quadratic Programming Algorithm.” IMA Journal of Applied Mathematics 7 (1): 76–91.\n\n\nGoldfarb, Donald, and Ashok U. Idnani. 1982. “Dual and Primal-Dual Methods for Solving Strictly Convex Quadratic Programs.” In Numerical Analysis, edited by J. P. Hennart, 226–39. Berlin, Heidelberg: Springer Berlin Heidelberg.\n\n\n———. 1983. “A Numerically Stable Dual Method for Solving Strictly Convex Quadratic Programs.” Mathematical Programming 27: 1–33.\n\n\nGoswami, Nababithi, Supriyo K. Mondal, and Swapan Paruya. 2012. “A Comparative Study of Dual Active-Set and Primal-Dual Interior-Point Method.” IFAC Proceedings Volumes 45 (15): 620–25. https://doi.org/https://doi.org/10.3182/20120710-4-SG-2026.00029.\n\n\nGunjan, Siddhartha, Abhishek & Bhattacharyya. 2023. “A brief review of portfolio optimization techniques.” Artificial Intelligence Review 56 (5): 3847–86. https://doi.org/10.1007/s10462-022-10273-7.\n\n\nHestenes, Magnus R. 1969. “Multiplier and Gradient Methods.” Journal of Optimization Theory and Applications 4 (5): 303–20.\n\n\nHestenes, Magnus R., and Eduard Stiefel. 1952. “Methods of Conjugate Gradients for Solving Linear Systems.” Journal of Research of the National Bureau of Standards 49: 409–35.\n\n\nJorion, Philippe. 2007. Value at Risk: The New Benchmark for Managing Financial Risk. The McGraw-Hill Companies, Inc.\n\n\nKarmarkar, Narendra. 1984. “A New Polynomial-Time Algorithm for Linear Programming.” In Proceedings of the Sixteenth Annual ACM Symposium on Theory of Computing, 302–11.\n\n\nKonno, Hiroshi, and Hiroaki Yamazaki. 1991. “Mean-Absolute Deviation Portfolio Optimization Model and Its Applications to Tokyo Stock Market.” Management Science 37 (5): 519–31.\n\n\nMarkowitz, Harry M, and Harry M Markowitz. 1967. Portfolio Selection: Efficient Diversification of Investments. J. Wiley.\n\n\nPowell, Michael JD. 1969. “A Method for Nonlinear Constraints in Minimization Problems.” Optimization, 283–98.\n\n\nRockafellar, R Tyrrell, and Stanislav Uryasev. 2002. “Conditional Value-at-Risk for General Loss Distributions.” Journal of Banking & Finance 26 (7): 1443–71.\n\n\nRosen, JB. 1961. “The Gradient Projection Method for Nonlinear Programming. Part II. Nonlinear Constraints.” Journal of the Society for Industrial and Applied Mathematics 9 (4): 514–32.\n\n\nRosen, Jo Bo. 1960. “The Gradient Projection Method for Nonlinear Programming. Part i. Linear Constraints.” Journal of the Society for Industrial and Applied Mathematics 8 (1): 181–217.\n\n\nSamuelson, Paul A. 1970. “The Fundamental Approximation Theorem of Portfolio Analysis in Terms of Means, Variances and Higher Moments.” The Review of Economic Studies 37 (4): 537–42.\n\n\nShenoy, Catherine, and Prakash P Shenoy. 2000. “Bayesian Network Models of Portfolio Risk and Return.” In. The MIT Press.\n\n\nSutton, Richard S, and Andrew G Barto. 2018. Reinforcement Learning: An Introduction. MIT press.\n\n\nWalker, Ryan. 2014. “Solving Quadratic Progams with r’s Quadprog Package.” rwalk. 2014. https://rwalk.xyz/solving-quadratic-progams-with-rs-quadprog-package/."
  },
  {
    "objectID": "Data.html#sec-obtdat",
    "href": "Data.html#sec-obtdat",
    "title": "2.4 Datos",
    "section": "2.4.1 Recollida de datos",
    "text": "2.4.1 Recollida de datos\nUnha explicación máis detallada sobre o código empregado para realizar o procedemento descrito neste subtítulo pódese atopar en Sección 1.1.\nCo fin de exemplificar como as redes neuronais artificiais e a programación cuadrática poden utilizarse nunha estratexia de xestión de carteiras, decidiuse neste traballo utilizar datos do mercado español. Por iso, decidiuse traballar coa información correspondente ás empresas que figuran na lista de sociedades cotizadas que se expón en “Empresas Cotizadas” (n.d.) e que se pode ver en Táboa 2.\nO Táboa 2 recolle os datos das empresas r nrow(empresas). Os datos recollidos son o nome, ticker, sector e subsector, mercado, índice de cada unha das empresas e se foron seleccionadas ou non para realizar o resto do trámite unha vez realizados os trámites indicados neste subepígrafe.\nPara obter os datos das empresas e analizalos para seleccionar aquelas coas que traballamos no resto do procedemento utilizouse como fonte  (n.d.a). A continuación, explícase o proceso realizado para obter e seleccionar os datos.\nDecidiuse descargar os datos mensuais de cada unha das empresas recollidos en Táboa 2. Obtención de todos os datos comprendidos entre o 31 de xaneiro de 2000 e o 28 de febreiro de 2023 de cada unha das entidades.\nDespois da obtención dos datos, avaliouse a calidade dos datos. A avaliación comezou cunha análise exploratoria visual dos prezos axustados xa que, como se explicou no capítulo anterior, estes son os idóneos para utilizar en calquera metodoloxía de análise histórica.\nDurante a citada análise visual exploratoria detectouse que había irregularidades nos prezos axustados dalgunhas das series. As irregularidades detectadas consistiron no rexistro incorrecto dos prezos axustados, así como erros no seu cálculo. Estes erros detectáronse facilmente observando os gráficos de valores de prezos de peche axustados de tendencia constante durante longos períodos de tempo, como se ve en Figura 6, o que indica un rexistro incorrecto dos cambios de prezos; así como cambios bruscos de ata máis do 100% nos mesmos nun único período de tempo, que poden indicar un erro de cálculo no prezo axustado, como se observa en Figura 7, neste último caso comprobouse con outras fontes como  (n.d.b), para verificar que os prezos se calcularon mal.\nDado o tempo dispoñible para realizar o estudo descrito no procedemento e o amplo tempo que requiriría realizar a investigación para substituír os valores erróneos da serie, optouse por eliminar estas irregularidades utilizando só o valores posteriores a xaneiro de 2005, que xa non presentaban inconsistencias no cálculo do prezo axustado, posteriormente elimináronse aquelas series que aínda contiñan valores ausentes e que presentaban irregularidades no rexistro das variacións, para estes últimos, aquelas series en que as variacións dos prezos non rexistrados están en máis de 10 observacións.\nQuedando despois dos axustes realizados ás empresas r length(returns_emps3), tal e como se ve na columna seleccionada do Táboa 2, algunhas destas empresas teñen un número diferente de observacións, porque non todas existían nin saíran ao mercado. mercado antes de xaneiro de 2005.\nUnha vez seleccionadas as empresas coas que traballamos, calculáronse os seus rendementos a partir dos prezos axustados. Ademais das rendibilidades correspondentes ás empresas seleccionadas, utilizáronse as rendibilidades do prezo de peche axustado do IBEX 35, así como outras variables que serven de indicadores do comportamento das rendibilidades, e da súa relación coas do índice. neste caso as do IBEX 35. Estas variables inclúen as volatilidades das empresas e do índice, a correlación entre os valores da serie e o IBEX, e a beta das empresas en relación co IBEX."
  },
  {
    "objectID": "Data.html#indicadores",
    "href": "Data.html#indicadores",
    "title": "2.4 Datos",
    "section": "2.4.2 Indicadores",
    "text": "2.4.2 Indicadores\nEste subepígrafe presenta unha breve explicación das variables calculadas a utilizar como variables de entrada en conxunto cos valores históricos dos rendementos das empresas. Unha explicación máis detallada sobre o código empregado para realizar o procedemento descrito neste subtítulo pódese atopar en Sección 1.2.\n\n2.4.2.1 Volatilidade\nPartindo de Hargrave (2023) e Hayes (2023), a desviación estándar e a volatilidade son dous conceptos relacionados que miden o que flutúa o prezo dunha acción ou doutro activo ao longo do tempo. A desviación estándar é un termo estatístico que cuantifica a dispersión dun conxunto de puntos de datos arredor do seu valor medio. A volatilidade é un termo financeiro que describe o grao de variación dos rendementos dun activo durante un período de tempo determinado.\nA desviación estándar e a volatilidade son importantes na análise do mercado de accións porque indican o risco e a incerteza asociada ao investimento nun activo determinado. Unha alta desviación estándar ou volatilidade significa que o prezo do activo pode cambiar significativamente en calquera dirección, o que implica un maior potencial de ganancias ou perdas. Unha baixa desviación estándar ou volatilidade significa que o prezo do activo é relativamente estable e previsible, o que significa menos potencial de ganancias ou perdas Hayes (2023).\nPara calcular a volatilidade dunha acción ou índice, calcúlase a desviación estándar dos rendementos. Polo tanto, os cálculos necesarios son os que se indican a continuación no Ecuación 1.\n\\[R_i = \\frac{P_i - P_{i-1}}{P_{i-1}}\\]\n\\[\\sigma = \\sqrt{\\frac{\\sum_{i=1}^N (R_i - \\bar{R})^2}{N} } \\tag{1}\\]\nonde:\n\n\\(R_i\\) é o retorno das accións no período \\(i\\)\n\\(P_i\\) y \\(P_{i-1}\\) son os prezos dunha acción nos períodos de tempo \\(i\\) e \\(i-1\\), respectivamente.\n\\(\\sigma\\) esa desviación estándar - \\(N\\) é o número de observacións\n\\(\\bar{R}\\) é o rendemento medio das accións.\n\nA desviación estándar e a volatilidade son ferramentas útiles para que investidores e analistas avalien o equilibrio risco-recompensa de diferentes activos e carteiras. Tamén poden axudar a comparar o rendemento de diferentes activos e carteiras ao longo do tempo e en diferentes condicións de mercado.\n\n\n2.4.2.2 Correlación\nComo explica Edwards (2022), a correlación é unha medida estatística que determina como se moven dúas variables entre si. Na análise do mercado de valores, a correlación pode axudar a comprender o comportamento das diferentes accións ou indicadores do mercado ao longo do tempo. Tomando como exemplo os datos empregados neste traballo, se os prezos dunha das empresas seleccionadas tenden a subir e baixar xunto co IBEX 35, estes prezos teñen unha correlación positiva. Se, pola contra, os prezos da empresa tenden a subir ao caer o indicador IBEX 35, teñen unha correlación negativa. Un coeficiente de correlación cero significa que non existe unha relación lineal entre as variables, sendo neste caso os valores do IBEX 35 e os prezos dunha das empresas determinadas.\nComo expuxo Ross (2022), a correlación entre dúas variables calcúlase mediante a seguinte ecuación: Ecuación 2:\n\\[\\rho_{xy} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2}\\sqrt{\\sum_{i=1}^n (y_i - \\bar{y})^2}} \\tag{2}\\]\nonde:\n\n\\(\\rho_{xy}\\) é o coeficiente de correlación\n\\(n\\) é o número de observacións\n\\(x_i\\) y \\(y_i\\) son os valores das dúas variables para a observación \\(i\\)\n\\(\\bar{x}\\) y \\(\\bar{y}\\) son as medias das dúas variables.\n\nComo tamén explica Edwards (2022), o coeficiente de correlación varía de -1 a 1, onde -1 indica correlación negativa perfecta, 1 indica correlación positiva perfecta e 0 indica ningunha correlación. Podendo comprender que canto máis próximo estea o coeficiente de correlación tanto a -1 como a 1, máis forte é a relación lineal entre as variables analizadas.\nComo se explicou anteriormente, o coeficiente de correlación, neste traballo, pode utilizarse para analizar como se moven os rendementos dunha empresa en comparación cos do IBEX 35. A correlación tamén se pode utilizar para diversificar unha carteira escollendo accións que teñan un ou correlación negativa entre si, como explica Boyte-White (2022). Isto pode axudar a reducir o risco global da carteira, xa que as perdas dunha acción poden compensarse coas ganancias doutra. Non obstante, a correlación non é constante e pode cambiar co tempo debido a diversos factores, como as condicións do mercado, os acontecementos económicos ou as noticias da empresa. Polo tanto, é importante supervisar a correlación de accións regularmente e axustar a carteira en consecuencia Boyte-White (2022).\nA correlación é unha ferramenta valiosa na análise do mercado de valores, pero non implica causalidade. Ter unha correlación alta ou baixa entre dúas variables non implica que unha variable provoque cambios na outra. A correlación mide simplemente a forza e a dirección da relación lineal entre dúas variables, sen ter en conta outros factores que poidan influír nelas.\nComo tamén se expuxo en Edwards (2022), a correlación está moi relacionada coa volatilidade do mercado e das accións, podendo constatar que, en períodos de maior volatilidade, como a crise financeira de 2008, as accións poden ter unha tendencia a estar máis correlacionados, aínda que sexan de sectores diferentes. Os mercados internacionais tamén poden estar moi correlacionados en tempos de inestabilidade. Os investimentos poden querer incluír activos nas súas carteiras que teñan unha baixa correlación de mercado cos mercados de accións para axudar a xestionar o seu risco.\n\n\n2.4.2.3 Beta\nSegundo explica Kenton (2022), a beta é unha medida da sensibilidade dos rendementos dunha acción aos cambios nos rendementos do mercado. Calcúlase como a pendente da recta de regresión que se axusta aos rendementos históricos das accións e do mercado. Unha beta de 1 significa que as accións se moven sincronizadas co mercado, unha beta superior a 1 significa que as accións son máis volátiles que o mercado e unha beta inferior a 1 significa que as accións son menos volátiles que o mercado.\nA beta é importante na análise do mercado de accións porque, como explica Kenton (2022), axuda aos investimentos a avaliar o risco e o rendemento dunha carteira. Ao coñecer a beta de cada acción dunha carteira, os investimentos poden estimar canto flutuará a carteira cos movementos do mercado e axustar a súa distribución de activos en consecuencia. Por exemplo, se un investidor quere reducir o risco na súa carteira, pode escoller accións con valores beta baixos ou negativos que tenden a moverse na dirección oposta do mercado.\nSegundo explica Monaghan (2019), a beta está relacionada coa cartografía, pero non son o mesmo. Como se explicou anteriormente, a correlación é unha medida de como están linealmente relacionadas dúas variables, Beta, por outra banda, é unha medida do forte que están relacionadas dúas variables, que indica canto cambia unha variable cando outra variable cambia nunha unidade. A beta pódese calcular a partir da correlación mediante a seguinte ecuación, Ecuación 3:\n\\[\\beta = \\frac{\\rho_{xy} \\sigma_x}{\\sigma_y} \\tag{3}\\]\nonde:\n\n\\(\\rho_{xy}\\) é o coeficiente de correlación entre \\(x\\) y \\(y\\)\n\\(\\sigma_x\\) é a volatilidade de x\n\\(\\sigma_y\\) é a volatilidade de y"
  },
  {
    "objectID": "Data.html#vectores",
    "href": "Data.html#vectores",
    "title": "2.4 Datos",
    "section": "2.4.3 Vectores",
    "text": "2.4.3 Vectores\nNeste subapartado explícase o procedemento realizado para crear os vectores de entrada e saída a partir dos datos resultantes do procedemento descrito no subapartado anterior. Unha explicación máis detallada sobre o código empregado para realizar o procedemento descrito neste subtítulo pódese atopar en Sección 1.3.\nA estrutura do conxunto de vectores de entrada e saída é de vital importancia no modelado de técnicas de ML, tendo un impacto significativo na súa eficacia. O conxunto de vectores debe crearse dun xeito representativo do problema que se vai resolver, polo que os pasos que se describen a continuación explican detalladamente os aspectos do problema que se vai responder neste traballo e como darlle forma ao conxunto de vectores de entrada e saída.\nComo se mencionou anteriormente, o obxectivo deste traballo é presentar un procedemento para o uso de modelos de ARN e programación cuadrática nunha estratexia de investimento. A modelización aborda a necesidade de obter as predicións o máis precisas posibles para posteriormente, a partir das predicións e dos datos históricos, atopar a composición ideal da carteira. Polo tanto, o problema a representar cos conxuntos de vectores de entrada e saída é como explicar o comportamento da rendibilidade dunha empresa nun instante de tempo \\(i+1\\) cos valores de varias variables no instante de tempo. \\(i\\).\nPara representar este problema creáronse vectores tridimensionais, seguindo o exposto en Chollet and Allaire (2018). As dimensións destes vectores explícanse do seguinte xeito:\n\nA primeira dimensión está composta polo número de mostras obtidas ao seccionar as observacións das diferentes series en vectores bidimensionais consecutivos.\nA segunda dimensión está composta polo número de observacións, das distintas series, recollidas en cada vector bidimensional.\nA terceira dimensión é o número de series en cada vector bidimensional.\n\nPolo tanto, para obter correctamente estas mostras, é necesario definir primeiro que serie se utilizará para os vectores de entrada e saída. No apartado anterior definíronse as series utilizadas nos vectores de entrada, sendo as seguintes: os rendementos históricos da empresa e o IBEX, as volatilidades históricas da empresa e o IBEX, a correlación histórica da empresa e o IBEX e o histórico. beta da empresa e do IBEX. A serie utilizada para os vectores de saída é a rendibilidade histórica da empresa.\nPosteriormente definiuse o horizonte temporal a prever, aspecto fundamental na creación dos conxuntos de entradas e saídas. O número de observacións definido como horizonte temporal determina as observacións dos vectores de saída, no presente traballo determinouse unha observación como horizonte temporal posto que se desexa prever a rendibilidade do próximo mes das distintas empresas seleccionadas.\nE o último aspecto a definir é cantas observacións debe observar o modelo para inferir a saída desexada. Isto define o número de observacións que se tomarán de cada serie temporal para formar os vectores de entrada. Para determinar este aspecto débese levar a cabo un proceso iterativo, probando diferentes cantidades e valorando os resultados obtidos polos modelos que se adestran con elas. Para simplificar o proceso, no presente traballo determinouse probar diferentes tamaños de entrada, sendo estes 1, 2 e 3 observacións. Así, probando de certo xeito como o tamaño das entradas afecta á predición obtida.\nSe temos unha matriz para os vectores de entrada que contén algunhas observacións r dim(returns_indc[[1]])[1], podemos calcular o número de mostras obtidas desta matriz seguindo a seguinte ecuación Ecuación 4:\n\\[\nm = n - (i-1+o)\n\\tag{4}\\]\nonde:\n\n\\(m\\) o número de mostras\n\\(n\\) o número de observacións da serie\n\\(i\\) y \\(o\\) o número de observacións nos vecotres de entrada e saída respectivamente.\n\nA Táboa 3 mostra o número de mostras obtidas para os diferentes tamaños de vectores de entrada propostos, para os que se tiveron en conta os diferentes números de observacións da r length(returns_indc) seleccionada. A Figura 16 mostra como son os vectores de entrada e saída, no caso de que o vector de entrada teña 3 observacións.\n\n\n\n\nn.d.a. Yahoo Finance. https://finance.yahoo.com/.\n\n\n———. n.d.b. Investing. https://www.investing.com/.\n\n\nBoyte-White, C. 2022. “How Does Correlation Affect the Stock Market?” 2022. https://www.investopedia.com/ask/answers/021716/how-does-correlation-affect-stock-market.asp.\n\n\nChollet, F., and J. J. Allaire. 2018. Deep Learning with r. Manning Publications. https://books.google.es/books?id=xnIRtAEACAAJ.\n\n\nEdwards, J. 2022. “Why Market Correlation Matters?” 2022. https://www.investopedia.com/articles/financial-advisors/022516/4-reasons-why-market-correlation-matters.asp.\n\n\n“Empresas Cotizadas.” n.d. BME Exchange. Accessed May 21, 2023. https://www.bolsasymercados.es/bme-exchange/es/Mercados-y-Cotizaciones/Acciones/Mercado-Continuo/Empresas-Cotizadas.\n\n\nHargrave, M. 2023. “Standard Deviation Formula and Uses Vs. Variance.” 2023. https://www.investopedia.com/terms/s/standarddeviation.asp.\n\n\nHayes, A. 2023. “Volatility: Meaning in Finance and How It Works with Stocks.” 2023. https://www.investopedia.com/terms/v/volatility.asp.\n\n\nKenton, W. 2022. “Beta: Definition, Calculation, and Explanation for Investors.” 2022. https://www.investopedia.com/terms/b/beta.asp.\n\n\nMonaghan, B. 2019. “Correlation Vs. Beta: What Is the Difference and Why Does It Matter?” 2019. https://www.mackenzieinvestments.com/content/dam/final/corporate/mackenzie/docs/investment-teams/multi-asset-team/en/Correlation%20vs.%20Beta_%20What%20is%20The%20Difference%20and%20Why%20Does%20It%20Matter_%20_%20Mackenzie%20Investments.pdf.\n\n\nRoss, S. 2022. “How Do i Calculate Correlation Between Market Indicators and Specific Stocks?” 2022. https://www.investopedia.com/ask/answers/032315/how-do-i-calculate-correlation-between-market-indicators-and-specific-stocks.asp."
  },
  {
    "objectID": "MandT.html#sec-modelado",
    "href": "MandT.html#sec-modelado",
    "title": "2.5 Modelado e formación",
    "section": "2.5.1 Modelado",
    "text": "2.5.1 Modelado\nEn ?sec-A-models pódese atopar unha explicación máis detallada do código utilizado durante o procedemento descrito nesta subsección.\nComo se explicou anteriormente, os principais elementos dos modelos de redes neuronais artificiais utilizados son unha capa CNN e unha capa LSTM. Ademais disto, utilizouse unha capa de entrada e outra de saída, que se encargan de subministrar aos modelos a información dos vectores constituídos previamente. En ?sec-A-models pódese atopar unha explicación máis detallada sobre o código utilizado para realizar o procedemento descrito neste subtítulo.\nDado que se definiron tres tamaños de observacións diferentes a ter en conta para facer unha predición, foi necesario construír tres estruturas modelo diferentes que se adaptasen ás dimensións dos diferentes vectores de entrada, as diferentes estruturas pódense observar nas ?fig-structures. .\nA primeira diferenza notable entre as estruturas son as saídas das capas de entrada, esta diferenza débese aos tamaños da mostra se optou por utilizar 1, 2 ou 3 observacións para construír o modelo. Como se pode ver, o tamaño da saída da capa de entrada modifica, polo tanto, o tamaño das entradas e saídas da capa CNN.\nComo se mencionou anteriormente, as variacións na segunda dimensión nas saídas da capa CNN poden explicarse polos diferentes tamaños dos vectores de entrada. Pero como se pode ver, o tamaño da terceira dimensión da saída desta capa é o mesmo en todas as estruturas, 64, o que indica o número de filtros elixidos para utilizar, un dos principais parámetros a ter en conta á hora de configurar estes. capas. Isto último significa que as observacións correspondentes ás 6 variables utilizadas foron divididas en 64 variables que permiten ao modelo unha mellor comprensión da relación entre as variables.\nOutro aspecto que se modificou na capa CNN das estruturas foi a función de activación que por defecto se chama ReLU (polas súas siglas en inglés, Rectified Linear Unit) cambiouse a Leaky ReLU porque como se explica en OmG (2021) , ReLU é unha activación non lineal. función que xera cero para entradas negativas, o que pode provocar que algunhas neuronas deixen de aprender se moitas das súas entradas son negativas, xa que os seus gradientes serán cero.\nTendo en conta o exposto anteriormente e que algunhas das variables utilizadas nos valores de entrada presentan un elevado número de observacións negativas, como é o caso dos rendementos ou a correlación dalgunhas das series en determinados períodos de tempo, a utilización do A función de activación de ReLU non parecía unha boa opción. Polo tanto, decidiuse utilizar Leaky Relu como función de activación, que como se explica en OmG (2021), trátase dunha variante que permite un pequeno gradiente constante, distinto de cero, para entradas negativas. Isto significa que esta función de activación permite que algunhas neuronas sigan aprendendo a partir de entradas negativas.\nNos dominios ?fig-obsérvase o dominio da función ReLU e Leaky ReLU, o que lle permitirá comprender mellor o que se expuxo anteriormente.\nA capa CNN en todas as estruturas está ligada a unha capa LSTM, que en todos os casos tiña 64 neuronas. A saída desta capa ligouse á capa de saída que devolve un único valor.\nPara concluír coa construción dos modelos, determinouse utilizar o erro cadrado medio (en diante MSE, polas súas siglas en inglés, Mean Squared Error) como función empregada para avaliar unha solución candidata, os resultados do modelo e o SGD. optimizador (polos seus acrónimos en inglés, Stochastic Gradient Descent) cun alfa de 0,0005."
  },
  {
    "objectID": "MandT.html#sec-entrenamiento",
    "href": "MandT.html#sec-entrenamiento",
    "title": "2.5 Modelado e formación",
    "section": "2.5.2 Formación",
    "text": "2.5.2 Formación\nEn ?sec-A-training pódese atopar unha explicación máis detallada do código utilizado durante o procedemento descrito nesta subsección.\nO adestramento de algoritmos de Machine Learning na previsión de series temporais ten as súas peculiaridades en como se adestran os modelos co obxectivo de resolver outro tipo de problemas. Polo tanto, neste subapartado cóbrase brevemente a metodoloxía de formación empregada, que é a denominada validación de andaina ou validación avanzada.\nComo xa se mencionou, a validación feedforward é un método usado para avaliar modelos de aprendizaxe automática en datos de series temporais. Isto débese a que, como explica Brownlee (2019), ofrece a avaliación máis realista dos modelos de aprendizaxe automática sobre datos de series temporais. Os métodos tradicionais de avaliación de modelos procedentes da aprendizaxe automática, como a validación cruzada k-fold ou a división en datos de adestramento e validación, non funcionan para os datos de series temporais porque ignoran os compoñentes de tempo inherentes ao problema. A validación avanzada ten en conta estes compoñentes temporais e ofrece unha avaliación máis realista de como funcionará o modelo cando se use operativamente.\nAo avaliar un modelo, interésanos saber como funciona o modelo en datos que non se utilizaron para adestralo. Na aprendizaxe automática, isto denomínase datos non vistos ou fóra da mostra. Normalmente, para a resolución doutros problemas, os datos divídense en diferentes subconxuntos: adestramento, proba e validación, cuxo obxectivo é adestrar e validar o modelo. Coa metodoloxía de validación walk forward, os datos divídense por períodos de tempo e o modelo adestrase e validase consecutivamente, o que permite avaliar como o modelo entende a dependencia temporal dos datos.\nAo dividir os datos por períodos de tempo, permítenos avaliar o funcionamento real do modelo se fora aplicado desde o primeiro período, así como analizar o seu comportamento ao longo de todos os períodos, observando se o seu rendemento mellora ou non.\nPolo exposto neste subapartado, enténdese que os modelos foron adestrados utilizando os conxuntos de mostras correspondentes, pasando todas as mostras dispoñibles nun período de tempo determinado antes de continuar co período seguinte. Obtendo como consecuencia do anterior unha predición correspondente a cada período de tempo contemplado, a excepción dos dous primeiros que se utilizarían para adestrar o modelo por primeira vez, tal e como se ve no seguinte esquema do Figura 19.\n\n\n\n\nBrownlee, J. 2019. “How to Backtest Machine Learning Models for Time Series Forecasting.” 2019. https://machinelearningmastery.com/backtest-machine-learning-models-time-series-forecasting/.\n\n\nOmG. 2021. “Difference Between ReLU, ELU and Leaky ReLU. Their Pros and Cons Majorly.” 2021. https://datascience.stackexchange.com/a/102485."
  },
  {
    "objectID": "Results.html#sec-predicciones",
    "href": "Results.html#sec-predicciones",
    "title": "2.6 Resultado",
    "section": "2.6.1 Predicións",
    "text": "2.6.1 Predicións\nEn ?sec-A-predictions pódese atopar unha explicación máis detallada do código utilizado durante o procedemento descrito nesta subsección.\nComo se explicou anteriormente, mentres se adestraba o modelo, obtivéronse as predicións. Como se fixo cos modelos de redes neuronais artificiais, as predicións calculáronse para as diferentes observacións utilizando a media aritmética das observacións. Utilizouse a media aritmética porque é unha das medidas máis utilizadas como indicador de posibles comportamentos futuros no estudo das series temporais financeiras.\nAs predicións avaliaranse calculando o MSE e os valores reais e os \\(R^2\\) dos resultados obtidos polos modelos de redes neuronais artificiais e as medias aritméticas.\nSegundo explica Glen (2023), o MSE indícalle o preto que está unha recta de regresión dun conxunto de puntos. Faino tomando as distancias dos puntos á recta de regresión (estas distancias son os “erros”) e cuadrándoas. O cadrado é necesario para eliminar calquera signo negativo. Tamén dá máis peso ás diferenzas maiores. Chámase erro cadrado medio xa que estás atopando a media dun conxunto de erros. Canto menor sexa o MSE, mellor será a previsión, mostrada por Ecuación 1 tal e como se calculou.\n\\[\n\\begin{aligned}\nMSE &= \\frac{1}{n} * \\sum_{i=1}^{n}{(Y_i-\\hat{Y_i})^2} \\\\\n\\end{aligned}\n\\tag{1}\\]\nOnde:\n\n\\(n\\): número de observacións\n\n\n\\(Y_i\\): valor real\n\n\n\\(\\hat{Y_i}\\): valor esperado\n\nComo explica Nandakumar (2020) \\(R^2\\) úsase habitualmente para explicar o bo rendemento dun modelo en comparación coa media global das observacións, Ecuación 2:\n\\[\n\\begin{aligned}\nR^2 &= 1-\\frac{SSR}{SST}\\\\\nR^2 &= 1-\\frac{\\sum_{i=1}^{n}{(Y_i-\\hat{Y_i})^2}}{\\sum_{i=1}^{n}{(Y_i-\\tilde{Y})^2}}\\\\\n\\end{aligned}\n\\tag{2}\\]\nOnde:\n\n\\(\\tilde{Y}\\): media aritmética de todas as observacións\n\nPero este pode ser un indicador inxusto do rendemento dun modelo de regresión xa que se supón que se coñecen todas as observacións sobre as que se calcula unha media, e como se mencionou anteriormente, este non é o caso dos modelos de redes neuronais. metodoloxía de validación avanzada. Debido a isto, modificouse o cálculo de \\(R^2\\), como se fixo noutras investigacións como Gu, Kelly, and Xiu (2018), de xeito que o modelo co que se comparan os resultados obtidos polas ANN utilizadas é o que comprenden as medias aritméticas de as observacións anteriores á prevista.\nA continuación, describiranse brevemente os diferentes resultados obtidos polos distintos modelos construídos. Cómpre sinalar que, aínda que se propuxeron 3 modelos diferentes de cada un deles, construíronse 10, co obxectivo de estandarizar os resultados obtidos, xa que o proceso de construción e adestramento de redes neuronais contén un factor aleatorio. Polo tanto, os resultados que se describen a continuación son os resultados medios obtidos polos distintos modelos construídos.\n\n2.6.1.1 Unha observación\nOs resultados obtidos por aqueles modelos que foron adestrados con vectores de entrada que tiñan unha observación de cada serie mostraron, como se ve en Figura 8, que nos primeiros períodos os modelos presentaban mellores predicións que as obtidas pola media aritmética. . Pódese observar que a eficacia dos modelos en comparación coas medias decae a medida que o modelo avanza no tempo e aprende das novas observacións. Tamén se ve claramente que na maioría dos períodos o \\(R^2\\) deste modelo é negativo. Ademais, obsérvase un pico no MSE do modelo a principios de 2020, que se entende como unha perda de efectividade do modelo, esta perda de efectividade do modelo podería estar relacionada con movementos bruscos do mercado derivados dos efectos económicos. do Covid-19.\nA análise previa do comportamento dos indicadores destes modelos por períodos ofrécenos unha visión xeral do desempeño destes modelos, pero dado que os resultados obtidos nas empresas son fundamentais para a composición da carteira, analizaremos agora o comportamento observado en os resultados obtidos polas 20 empresas que presentaron os mellores e peores resultados, a partir dos \\(R^2\\) obtidos como criterio.\nObservando os resultados dos indicadores expostos nos Táboa 4, aquelas empresas que presentaron un peor \\(R^2\\) presentan tamén un baixo MSE, o que indica que é menos probable que a composición da carteira se vexa alterada polos resultados. obtidos por estas empresas.empresas. Por outra banda, entre as empresas que obtiveron un mellor \\(R^2\\) hai algunhas que obtiveron un MSE elevado acompañado dun \\(R^2\\) superior ao 5%. Isto indica que se poderían xerar diferenzas entre as composicións das carteiras debido ás diferenzas nas previsións e que se trata de empresas que non teñen unha boa MSE.\nOs resultados descritos no parágrafo anterior son similares para os casos dos modelos construídos con dúas e tres observacións, respectivamente.\n\n\n2.6.1.2 Dúas observacións\nOs resultados obtidos por aqueles modelos que foron adestrados con vectores de entrada que tiñan dúas observacións de cada serie, comprobouse, como se ve en Figura 9, que nos primeiros períodos os modelos presentaban mellores predicións que as obtidas pola media. . Pódese ver que a eficacia dos modelos en comparación coas medias decae a medida que o modelo avanza no tempo, pero decaen a un ritmo máis lento que aqueles modelos adestrados con vectores de entrada cunha observación. Tamén se ve claramente que o \\(R^2\\) destes modelos ten menos variación que o \\(R^2\\) dos modelos analizados anteriormente, xa que para estes modelos o \\(R^2\\) é positivo na maioría dos períodos. Ademais, como no caso dos modelos analizados anteriormente, tamén se observa un pico no MSE do modelo a principios de 2020.\n\n\n2.6.1.3 Tres observacións\nOs resultados obtidos por aqueles modelos que foron adestrados con vectores de entrada que tiñan tres observacións de cada serie, comprobouse, como se ve en Figura 10, que nos primeiros períodos os modelos presentaban mellores predicións que as obtidas pola media. . Pódese ver que a eficacia dos modelos en comparación coas medias decae a medida que o modelo avanza no tempo, pero decaen a un ritmo máis lento que aqueles modelos adestrados con vectores de entrada cunha observación. Obsérvase claramente que o R2 destes modelos presenta unha maior variación que o R2 dos modelos analizados anteriormente, observando como esta variación diminúe para aquelas predicións posteriores a 2015. Estes modelos, como os primeiros, presentaron un R2 negativo na maioría deles. . dos períodos. Ademais, como nos casos anteriores, tamén se observa un pico no MSE do modelo a principios de 2020."
  },
  {
    "objectID": "Results.html#sec-cc",
    "href": "Results.html#sec-cc",
    "title": "2.6 Resultado",
    "section": "2.6.2 Composición de carteiras",
    "text": "2.6.2 Composición de carteiras\nPódese atopar unha explicación máis detallada do código utilizado durante o procedemento descrito nesta subsección en Sección 3.2.\nNeste subepígrafe descríbense os resultados obtidos tras aplicar a programación cuadrática para determinar a composición da carteira. Esta, así como as previsións, fíxose período a período co obxectivo de emular unha situación real na que as técnicas se aplicasen no seu conxunto. Polo tanto, a presente análise céntrase no comportamento observado ao utilizar os distintos modelos e na comparación destes resultados cos obtidos co uso de medias.\nComo se pode ver en Figura 11, as carteiras feitas a partir das predicións obtidas polos modelos de redes neuronais que tiñan unha observación xeralmente obtiveron mellores resultados que as carteiras feitas a partir das predicións usando a media. Obsérvase que ambos grupos de carteiras presentaron unha rendibilidade inferior á do índice, IBEX, no período comprendido entre 2009 e 2016.\nAo realizar a análise do comportamento dos rendementos obtidos polos modelos con dúas observacións de entrada, Figura 12, obsérvase: o comportamento dos rendementos obtidos polos distintos modelos varía menos que os analizados anteriormente; Neste caso e contrariamente ao caso anterior, os rendementos seguen sendo similares no período comprendido entre 2009 e 2016; e aínda que o resultado final dista moito do resultado obtido polas medias, é inferior ao obtido polos modelos anteriores, sendo este último debido a que a avaliación dos modelos neste caso comeza nun período anterior aos de modelos analizados anteriormente.\nObservando os resultados obtidos polos últimos modelos, Figura 13, obsérvase: unha distribución de rendementos superior aos adestrados con dúas observacións pero inferior aos adestrados cunha observación; obsérvase que os rendementos comezan a superar os do índice despois de 2013 en lugar de 2016 como en anos anteriores; e tamén se observa que os rendementos dos modelos de ARN son superiores aos das medias e tamén constitúen os máximos rendementos obtidos entre as distintas estruturas dos modelos de ARN.\n\n\n\n\nGlen, S. 2023. “Mean Squared Error: Definition and Example.” 2023. https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/mean-squared-error/.\n\n\nGu, Shihao, Bryan Kelly, and Dacheng Xiu. 2018. “Empirical Asset Pricing via Machine Learning.” Working Paper 25398. Working Paper Series. National Bureau of Economic Research. https://doi.org/10.3386/w25398.\n\n\nNandakumar, S. 2020. “How Can r-Squared Be Negative When the Correlation Between Prediction and Truth Is Positive?” 2020. https://stackoverflow.com/a/63311778/12660035."
  },
  {
    "objectID": "conclusions.html",
    "href": "conclusions.html",
    "title": "3 Conclusións",
    "section": "",
    "text": "Durante o desenvolvemento deste traballo abordouse a aplicación das redes neuronais artificiais e da programación cuadrática na xestión de carteiras financeiras. A través dunha coidada caracterización das series temporais financeiras, foi posible comprender a importancia de analizar as súas características e patróns para facer previsións máis precisas.\nProbáronse diferentes configuracións de modelos de redes neuronais artificiais, compostos pola combinación de capas convolucionais e LSTM, que diferían no número de observacións históricas que utilizarían como entradas antes de facer unha predición. Comparáronse as predicións obtidas a partir dos citados modelos coas predicións obtidas mediante a media aritmética, que é un dos indicadores máis utilizados. Como resultado da citada comparación, obtívose que os modelos en función do número de observacións que utilizaban como entradas: 1, 2 ou 3; obtiveron un R2 de: -0,00287, 0,0611 e 0,0179 respectivamente.\nAs predicións obtidas, tanto cos modelos de ARN como coas medias aritméticas xunto cos comportamentos históricos foron empregadas para, mediante a programación cuadrática, buscar a composición de carteiras de menor risco. Despois de realizar unha simulación de xestión de carteiras, conseguiuse que as carteiras constituídas a partir das predicións dos modelos ANN obtidas ao final do período estudado, fronte ás compostas polas predicións mediante a media aritmética, producen un rendemento: un 5,63% superior. , para modelos que utilizaron 1 observación como entrada; un 35,67% maior para os que utilizaron 2; e un 25,51% para os que utilizaron 3. Ademais, observouse que as carteiras integradas polos modelos de ARN obtiveron rendementos superiores ao índice, IBEX, nun 40,86%, 39,78% e 60,54%, para os modelos que utilizaron 1, 2 e 3 observacións como entradas respectivamente.\nOs resultados mencionados mostran que o uso combinado destas ferramentas, ANN e programación cuadrática, pode ofrecer ás empresas e organizacións unha importante vantaxe competitiva na xestión dos seus activos financeiros, permitindo unha toma de decisións máis eficaz, optimizando a composición das carteiras e maximizando os rendementos.\nNon obstante, é importante destacar que os resultados que se presentan neste traballo precisan dun estudo máis profundo para analizar, entre outros aspectos, o peso que teñen na composición das carteiras os resultados das predicións das distintas empresas. Por este motivo, este traballo considérase o inicio dunha investigación máis exhaustiva na que: hai que obter datos de maior calidade e contrastar o uso de diversas técnicas, tanto para obter predicións como para atopar axeitada a composición da carteira."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Bibliografía",
    "section": "",
    "text": "n.d.b. Yahoo Finance. https://finance.yahoo.com/.\n\n\n———. n.d.a. Investing. https://www.investing.com/.\n\n\nAijun Zhang & Chun-hung Li & Agus Sudjianto, Zhi-li Wu &.\n2008. “Trace Solution Paths for SVMs via Parametric Quadratic\nProgramming.” Researchgate. 2008. https://www.researchgate.net/publication/228577955_Trace_solution_paths_for_SVMs_via_parametric_quadratic_programming.\n\n\nAnderson, D. R., D. J. Sweeney, T. A. Williams, D. J. Camm, and J. J\nCochran. 2017. Statistics for Business & Economics. Boston:\nCengage Learning.\n\n\nB. Eddy Patuwo & Michael Y. Hu, Guoqiang Zhang &. 1998.\n“Forecasting with Artificial Neural Networks:: The State of the\nArt.” International Journal of Forecasting 14 (1):\n35–62. https://doi.org/https://doi.org/10.1016/S0169-2070(97)00044-7.\n\n\nBanda, Hugo. 2014. Inteligencia Artificial: Principios y\nAplicaciones. Quito, Ecuador: Escuela Politécnica Nacional.\n\n\nBarone, A. 2022. “Opening Price: Definition, Example, Trading\nStrategies.” 2022. https://www.investopedia.com/terms/o/openingprice.asp.\n\n\nBeale, EML. 1959. “On Quadratic Proramming.” Naval\nResearch Logistics Quarterly 6 (3): 227–43.\n\n\nBerwin A. Turlach R port by Andreas Weingessel\n&lt;Andreas.Weingessel@ci.tuwien.ac.at&gt; Fortran contributions from\nCleve Moler dpodi/LINPACK), S original by. 2019. Quadprog: Functions\nto Solve Quadratic Programming Problems. https://CRAN.R-project.org/package=quadprog.\n\n\nBME. n.d. “¿Qué Es BME?” Accessed April 24, 2023. https://www.bolsasymercados.es/esp/Sobre-BME/Que-es.\n\n\nBoyte-White, C. 2022. “How Does Correlation Affect the Stock\nMarket?” 2022. https://www.investopedia.com/ask/answers/021716/how-does-correlation-affect-stock-market.asp.\n\n\nBrownlee, J. 2019. “How to Backtest Machine Learning Models for\nTime Series Forecasting.” 2019. https://machinelearningmastery.com/backtest-machine-learning-models-time-series-forecasting/.\n\n\nBunch, James R, and Linda Kaufman. 1977. “Some Stable Methods for\nCalculating Inertia and Solving Symmetric Linear Systems.”\nMathematics of Computation 31 (137): 163–79.\n\n\nCai, Xiaoqiang, Kok Lay Teo, XQ Yang, and Xun Yu Zhou. 2004.\n“Minimax Portfolio Optimization: Empirical Numerical\nStudy.” Journal of the Operational Research Society 55\n(1): 65–72.\n\n\nCastillo, R. A., and R. Varela. 2010. ECONOMETRÍA PRÁCTICA:\nFundamentos de Series de Tiempo. México: Universidad Autónoma de\nBaja California.\n\n\nChen, J. 2022. “Today’s High.” 2022. https://www.investopedia.com/terms/t/todayshigh.asp.\n\n\nChirinos, S. 2018. “Series Cronológicas.” https://www.slideshare.net/SuedimarChirinos/series-cronologicas-119058959.\n2018.\n\n\nChollet, F., and J. J. Allaire. 2018. Deep Learning with r.\nManning Publications. https://books.google.es/books?id=xnIRtAEACAAJ.\n\n\nCNMV. n.d.a. “Glosario Financiero: Acción.” Accessed April\n24, 2023. https://cnmv.es/Portal/Inversor/Glosario.aspx?id=0&letra=A&idlng=1.\n\n\n———. n.d.b. “Glosario Financiero: Bolsa de Valores.”\nAccessed April 24, 2023. https://cnmv.es/Portal/Inversor/Glosario.aspx?id=0&letra=B&idlng=1.\n\n\n———. n.d.c. “Glosario Financiero: Servicio de Interconexión\nBursátil Español, SIBE.” Accessed April 24, 2023. https://cnmv.es/Portal/Inversor/Glosario.aspx?id=0&letra=S&idlng=1.\n\n\nDodge, Y. 2008. “Time Series.” In The Concise\nEncyclopedia of Statistics, 536–39. New York, NY: Springer New\nYork. https://doi.org/10.1007/978-0-387-32833-1_401.\n\n\nDowney, L. 2022. “Today’s Low.” 2022. https://www.investopedia.com/terms/t/todayslow.asp.\n\n\nDrucker, Harris, Christopher Burges, Linda Kaufman, Alex Smola, and\nVladimir Vapnik. 1996. “Linear Support Vector Regression\nMachines.” Advances in Neural Information Processing\nSystems 9 (9): 155–61.\n\n\nEdwards, J. 2022. “Why Market Correlation Matters?” 2022.\nhttps://www.investopedia.com/articles/financial-advisors/022516/4-reasons-why-market-correlation-matters.asp.\n\n\n“Empresas Cotizadas.” n.d. BME Exchange. Accessed May 21,\n2023. https://www.bolsasymercados.es/bme-exchange/es/Mercados-y-Cotizaciones/Acciones/Mercado-Continuo/Empresas-Cotizadas.\n\n\nEspallargas, S. D., and M. V. Solís. 2012. Econometría y Series\nTemporales: Aplicaciones. La Habana: Editorial Félix Varela.\n\n\nFletcher, Roger. 1971. “A General Quadratic Programming\nAlgorithm.” IMA Journal of Applied Mathematics 7 (1):\n76–91.\n\n\nGanti, A. 2020. “Adjusted Closing Price.” 2020. https://www.investopedia.com/terms/a/adjusted_closing_price.asp.\n\n\nGlen, S. 2023. “Mean Squared Error: Definition and\nExample.” 2023. https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/mean-squared-error/.\n\n\nGoldfarb, Donald, and Ashok U. Idnani. 1982. “Dual and Primal-Dual\nMethods for Solving Strictly Convex Quadratic Programs.” In\nNumerical Analysis, edited by J. P. Hennart, 226–39. Berlin,\nHeidelberg: Springer Berlin Heidelberg.\n\n\n———. 1983. “A Numerically Stable Dual Method for Solving Strictly\nConvex Quadratic Programs.” Mathematical Programming 27:\n1–33.\n\n\nGoswami, Nababithi, Supriyo K. Mondal, and Swapan Paruya. 2012. “A\nComparative Study of Dual Active-Set and Primal-Dual Interior-Point\nMethod.” IFAC Proceedings Volumes 45 (15): 620–25.\nhttps://doi.org/https://doi.org/10.3182/20120710-4-SG-2026.00029.\n\n\nGu, Shihao, Bryan Kelly, and Dacheng Xiu. 2018. “Empirical Asset\nPricing via Machine Learning.” Working Paper 25398. Working Paper\nSeries. National Bureau of Economic Research. https://doi.org/10.3386/w25398.\n\n\nGunjan, Siddhartha, Abhishek & Bhattacharyya. 2023. “A brief review of portfolio optimization\ntechniques.” Artificial Intelligence Review 56\n(5): 3847–86. https://doi.org/10.1007/s10462-022-10273-7.\n\n\nGuresen, Erkam, Gulgun Kayakutlu, and Tugrul U. Daim. 2011. “Using\nArtificial Neural Network Models in Stock Market Index\nPrediction.” Expert Systems with Applications 38 (8):\n10389–97. https://doi.org/https://doi.org/10.1016/j.eswa.2011.02.068.\n\n\nHargrave, M. 2023. “Standard Deviation Formula and Uses Vs.\nVariance.” 2023. https://www.investopedia.com/terms/s/standarddeviation.asp.\n\n\nHayes, A. 2021. “What Is Closing Price? Definition, How It’s Used,\nand Example.” 2021. https://www.investopedia.com/terms/c/closingprice.asp.\n\n\n———. 2023. “Volatility: Meaning in Finance and How It Works with\nStocks.” 2023. https://www.investopedia.com/terms/v/volatility.asp.\n\n\nHaykin, Simon. 1998. Neural Networks: A Comprehensive\nFoundation. Prentice Hall PTR.\n\n\nHestenes, Magnus R. 1969. “Multiplier and Gradient\nMethods.” Journal of Optimization Theory and\nApplications 4 (5): 303–20.\n\n\nHestenes, Magnus R., and Eduard Stiefel. 1952. “Methods of\nConjugate Gradients for Solving Linear Systems.” Journal of\nResearch of the National Bureau of Standards 49: 409–35.\n\n\nHochreiter, Jürgen, Sepp & Schmidhuber. 1997. “Long\nShort-Term Memory.” Neural Computation 9 (8):\n1735–80. https://doi.org/10.1162/neco.1997.9.8.1735.\n\n\nIannone, Richard. 2023. DiagrammeR: Graph/Network\nVisualization. https://CRAN.R-project.org/package=DiagrammeR.\n\n\nIBM. 2021. “Characteristics of Time Series.” https://www.ibm.com/docs/en/spss-modeler/saas?topic=data-characteristics-time-series.\n2021.\n\n\nJing, Hong. 2020. “How Convolutional Layers Work in Deep Learning\nNeural Networks?” Jingles, Github Blog. 2020. https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/.\n\n\nJorion, Philippe. 2007. Value at Risk: The New Benchmark for\nManaging Financial Risk. The McGraw-Hill Companies, Inc.\n\n\nKarmarkar, Narendra. 1984. “A New Polynomial-Time Algorithm for\nLinear Programming.” In Proceedings of the Sixteenth Annual\nACM Symposium on Theory of Computing, 302–11.\n\n\nKenton, W. 2022. “Beta: Definition, Calculation, and Explanation\nfor Investors.” 2022. https://www.investopedia.com/terms/b/beta.asp.\n\n\nKocenda, E., and A. Cerný. 2017. Elements of Time Series\nEconometrics: An Applied Approach. Prague: Karolinum Press.\n\n\nKonno, Hiroshi, and Hiroaki Yamazaki. 1991. “Mean-Absolute\nDeviation Portfolio Optimization Model and Its Applications to Tokyo\nStock Market.” Management Science 37 (5): 519–31.\n\n\nLarrañaga, Iñaki & Moujahid, Pedro & Inza. 2007. “Tema 14.\nRedes Neuronales.” Departamento de Ciencias de la Computaci´on e\nInteligencia Artificial, Universidad del Pa´ıs Vasco–Euskal Herriko\nUnibertsitatea. 2007. http://www.sc.ehu.es/ccwbayes/docencia/mmcc/docs/t14-neuronales.pdf.\n\n\nLecun, Y., L. Bottou, Y. Bengio, and P. Haffner. 1998.\n“Gradient-Based Learning Applied to Document Recognition.”\nProceedings of the IEEE 86 (11): 2278–2324. https://doi.org/10.1109/5.726791.\n\n\nMarkowitz, Harry M, and Harry M Markowitz. 1967. Portfolio\nSelection: Efficient Diversification of Investments. J. Wiley.\n\n\nMcCarthy, John, Marvin L. Minsky, Nathaniel Rochester, and Claude E.\nShannon. 2006. “A Proposal for the Dartmouth Summer Research\nProject on Artificial Intelligence, August 31, 1955.” AI\nMagazine 27 (4): 12. https://doi.org/10.1609/aimag.v27i4.1904.\n\n\nMitchell, C. 2020. “Market Price: Definition, Meaning, How to\nDetermine, and Example.” 2020. https://www.investopedia.com/terms/m/market-price.asp.\n\n\nMonaghan, B. 2019. “Correlation Vs. Beta: What Is the Difference\nand Why Does It Matter?” 2019. https://www.mackenzieinvestments.com/content/dam/final/corporate/mackenzie/docs/investment-teams/multi-asset-team/en/Correlation%20vs.%20Beta_%20What%20is%20The%20Difference%20and%20Why%20Does%20It%20Matter_%20_%20Mackenzie%20Investments.pdf.\n\n\nNandakumar, S. 2020. “How Can r-Squared Be Negative When the\nCorrelation Between Prediction and Truth Is Positive?” 2020. https://stackoverflow.com/a/63311778/12660035.\n\n\nOlah, Christopher. 2015. “Understanding LSTM Networks.”\nColah’s blog. 2015. https://colah.github.io/posts/2015-08-Understanding-LSTMs/.\n\n\nOmG. 2021. “Difference Between ReLU, ELU and Leaky ReLU. Their\nPros and Cons Majorly.” 2021. https://datascience.stackexchange.com/a/102485.\n\n\nPinset, W. 2021. “Understanding Stock Prices and Values.”\n2021. https://www.investopedia.com/articles/stocks/08/stock-prices-fool.asp.\n\n\nPowell, Michael JD. 1969. “A Method for Nonlinear Constraints in\nMinimization Problems.” Optimization, 283–98.\n\n\nRallabandi, S. 2023. “Activation Functions ReLU Vs. Leaky\nReLU.” 2023. https://medium.com/mlearning-ai/activation-functions-relu-vs-leaky-relu-b8272dc0b1be.\n\n\nRockafellar, R Tyrrell, and Stanislav Uryasev. 2002. “Conditional\nValue-at-Risk for General Loss Distributions.” Journal of\nBanking & Finance 26 (7): 1443–71.\n\n\nRosen, JB. 1961. “The Gradient Projection Method for Nonlinear\nProgramming. Part II. Nonlinear Constraints.” Journal of the\nSociety for Industrial and Applied Mathematics 9 (4): 514–32.\n\n\nRosen, Jo Bo. 1960. “The Gradient Projection Method for Nonlinear\nProgramming. Part i. Linear Constraints.” Journal of the\nSociety for Industrial and Applied Mathematics 8 (1): 181–217.\n\n\nRoss, S. 2022. “How Do i Calculate Correlation Between Market\nIndicators and Specific Stocks?” 2022. https://www.investopedia.com/ask/answers/032315/how-do-i-calculate-correlation-between-market-indicators-and-specific-stocks.asp.\n\n\nRuiz, M. C. 2011. “Tema 5: Procesos Estocásticos.” http://www.dmae.upct.es/~mcruiz/Telem06/Teoria/apuntes_procesos.pdf;\nDepartamento de Matemática y Estadística. Universidad Politécnica de\nCartagena. 2011.\n\n\nRyan, Jeffrey A., and Joshua M. Ulrich. 2023. Quantmod: Quantitative\nFinancial Modelling Framework. https://CRAN.R-project.org/package=quantmod.\n\n\nSamuelson, Paul A. 1970. “The Fundamental Approximation Theorem of\nPortfolio Analysis in Terms of Means, Variances and Higher\nMoments.” The Review of Economic Studies 37 (4): 537–42.\n\n\nSezer, Omer Berat, Mehmet Ugur Gudelek, and Ahmet Murat Ozbayoglu. 2020.\n“Financial Time Series Forecasting with Deep Learning : A\nSystematic Literature Review: 2005–2019.” Applied Soft\nComputing 90: 106181. https://doi.org/https://doi.org/10.1016/j.asoc.2020.106181.\n\n\nShenoy, Catherine, and Prakash P Shenoy. 2000. “Bayesian Network\nModels of Portfolio Risk and Return.” In. The MIT Press.\n\n\nSiddiqui, J. Rafid. 2023. “Why Convolve? Understanding Convolution\nand Feature Extraction in Deep Networks.” Medium, Towards Data\nScience. 2023. https://towardsdatascience.com/why-convolve-understanding-convolution-and-feature-extraction-in-deep-networks-ee45d1fdd17c.\n\n\nSutton, Richard S, and Andrew G Barto. 2018. Reinforcement Learning:\nAn Introduction. MIT press.\n\n\nTealab, Ahmed. 2018. “Time Series Forecasting Using Artificial\nNeural Networks Methodologies: A Systematic Review.” Future\nComputing and Informatics Journal 3 (2): 334–40. https://doi.org/https://doi.org/10.1016/j.fcij.2018.10.003.\n\n\nTeam, CFI. 2023. “What Is Stock Price?” 2023. https://corporatefinanceinstitute.com/resources/capital-markets/stock-price/.\n\n\nTeam, The Investopedia. 2022. “Intrinsic Value Defined and How\nIt’s Determined in Investing and Business.” 2022. https://www.investopedia.com/terms/i/intrinsicvalue.asp.\n\n\nVillagarcía, T. 2006. “Series Temporales.” https://halweb.uc3m.es/fjnm/estind/doc_grupo1/archivos/Apuntes%20de%20series.pdf.\n2006.\n\n\nVillavicencio, J. 2010. “Introducción a Las Series de\nTiempo.” http://www.estadisticas.gobierno.pr/iepr/LinkClick.aspx;\nInstituto de estadística de Puerto Rico. 2010.\n\n\nWalker, Ryan. 2014. “Solving Quadratic Progams with r’s Quadprog\nPackage.” rwalk. 2014. https://rwalk.xyz/solving-quadratic-progams-with-rs-quadprog-package/.\n\n\nWong, W. K., and Z. X. Guo. 2010. “A hybrid\nintelligent model for medium-term sales forecasting in fashion retail\nsupply chains using extreme learning machine and harmony search\nalgorithm.” International Journal of Production\nEconomics 128 (2): 614–24. https://ideas.repec.org/a/eee/proeco/v128y2010i2p614-624.html."
  },
  {
    "objectID": "Annex1.html",
    "href": "Annex1.html",
    "title": "Anexo. 1 Figuras",
    "section": "",
    "text": "Figura 1: Relación entre IA-ML-DL\n\n\n\n\nTirado de: Deep learning with R de Chollet and Allaire (2018).\n\n\n\nFigura 2: Programación clásica y machine learning\n\n\n\n\nTirado de: Deep learning with R de Chollet and Allaire (2018).\n\n\n\nFigura 3: Estrutura básica dunha rede neuronal artificial\n\n\n\n\nTirado de: Tema 14: redes neuronales de Larrañaga (2007).\n\n\n\n\n\nFigura 4: Como afecta o tamaño do filtro ao vector de saída\n\n\n\n\n\n\nElaboración propia: Elaborado dende Jing (2020). Mostra como cambia o tamaño do vector de saída segundo o tamaño do filtro que se utilice.\n\n\n\n\n\nFigura 5: Como afecta a zancada ao vector de saída\n\n\n\n\n\n\nElaboración propia: Elaborado dende Jing (2020). Mostra como o parámetro de zancada afecta o tamaño do vector de saída.\n\n\n\n\n\nFigura 6: Como afecta a dilatación ao vector de saída\n\n\n\n\n\n\nElaboración propia: Elaborado dende Jing (2020). Mostra como afecta o parámetro de dilatación ao tamaño do vector de saída.\n\n\n\n\n\nFigura 7: Como afecta o recheo ao vector de saída\n\n\n\n\n\n\nElaboración propia: Elaborado dende Jing (2020). Mostra como o parámetro de recheo afecta o tamaño do vector de saída.\n\n\n\nFigura 8: Implantación do bucle dunha rede neuronal recorrente estándar\n\n\n\n\nTirado de: Understanding LSTM networks, Olah (2015).\n\n\n\nFigura 9: Información relevante cercana\n\n\n\n\nTirado de: Understanding LSTM networks, Olah (2015).\n\n\n\nFigura 10: Información relevante lejana\n\n\n\n\nTirado de: Understanding LSTM networks, Olah (2015).\n\n\n\nFigura 11: Diferenza entre módulos de repetición\n\n\n\n\nTirado de: Understanding LSTM networks, Olah (2015).\n\n\n\nFigura 12: Funcionalidade LSTM: representación do paso 1\n\n\n\n\nTirado de: Understanding LSTM networks, Olah (2015).\n\n\n\nFigura 13: Funcionalidade LSTM: representación do paso 2\n\n\n\n\nTirado de: Understanding LSTM networks, Olah (2015).\n\n\n\nFigura 14: Funcionalidade LSTM: representación do paso 3\n\n\n\n\nTirado de: Understanding LSTM networks, Olah (2015).\n\n\n\nFigura 15: Funcionalidade LSTM: representación do paso 4\n\n\n\n\nTirado de: Understanding LSTM networks, Olah (2015).\n\n\n\n\n\nFigura 16: Visualización vectorial de entrada e saída\n\n\n\n\n\n\nElaboración propia: Feita a partir dunha imaxe en Chollet and Allaire (2018). Mostra como son os vectores de entrada e saída tridimensionais dos datos dunha empresa, se se usan tres observacións para crear o vector de entrada.\n\n\n\nFigura 17: Diferentes estruturas dependendo dos diferentes tamaños dos vectores de entrada\n\n\n\n\nElaboración propia: Elaborouse a partir dos diferentes modelos construídos utilizando os paquetes keras e tensorflow en R, e representáronse gráficamente mediante o paquete Iannone (2023).\n\n\n\nFigura 18: Dominio de ReLU e Leaky ReLU\n\n\n\n\nElaboración propia: Elaborada a partir das imaxes que se observan en Rallabandi (2023).\n\n\n\nFigura 19: Diagrama de fluxo da metodoloxía Walk Forward Validation\n\n\n\n\nElaboración propia\n\n\n\n\n\nChollet, F., and J. J. Allaire. 2018. Deep Learning with r. Manning Publications. https://books.google.es/books?id=xnIRtAEACAAJ.\n\n\nIannone, Richard. 2023. DiagrammeR: Graph/Network Visualization. https://CRAN.R-project.org/package=DiagrammeR.\n\n\nJing, Hong. 2020. “How Convolutional Layers Work in Deep Learning Neural Networks?” Jingles, Github Blog. 2020. https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/.\n\n\nLarrañaga, Iñaki & Moujahid, Pedro & Inza. 2007. “Tema 14. Redes Neuronales.” Departamento de Ciencias de la Computaci´on e Inteligencia Artificial, Universidad del Pa´ıs Vasco–Euskal Herriko Unibertsitatea. 2007. http://www.sc.ehu.es/ccwbayes/docencia/mmcc/docs/t14-neuronales.pdf.\n\n\nOlah, Christopher. 2015. “Understanding LSTM Networks.” Colah’s blog. 2015. https://colah.github.io/posts/2015-08-Understanding-LSTMs/.\n\n\nRallabandi, S. 2023. “Activation Functions ReLU Vs. Leaky ReLU.” 2023. https://medium.com/mlearning-ai/activation-functions-relu-vs-leaky-relu-b8272dc0b1be."
  },
  {
    "objectID": "Annex2.html",
    "href": "Annex2.html",
    "title": "Anexo. 2 Gráficos",
    "section": "",
    "text": "Figura 1: Tendencia alcista e heteroscedástica\n\n\n\n\n\n\nElaboración propia: Mediante o uso de RStudio coa base de datos histórica do IBEX, obtida de https://finance.yahoo.com/, no período comprendido entre o 01-1995 e o 01-1997.\n\n\n\n\n\nFigura 2: Tendencia bajista e heteroscedástica\n\n\n\n\n\n\nElaboración propia: Mediante o uso de RStudio coa base de datos histórica do IBEX, obtida de https://finance.yahoo.com/, no período comprendido entre o 01-2000 e o 01-2003.\n\n\n\n\n\nFigura 3: Sen tendencia, homoscedástica e estacionaria\n\n\n\n\n\n\nElaboración propia: Mediante o uso de RStudio coa base de datos histórica do IBEX obtida de https://finance.yahoo.com/, no período comprendido entre o 01-2000 e o 01-2003, utilizando os rendementos calculados a partir do prezo de peche.\n\n\n\n\n\nFigura 4: Descomposición: estacionalidade e erro\n\n\n\n\n\n\nElaboración propia: Mediante o uso de RStudio coa base de datos histórica do IBEX obtida en https://finance.yahoo.com/, descompondo a serie temporal composta polas observacións que abarcan o período 01-2000 ao 01-2023 .\n\n\n\n\n\nFigura 5: Correlograma\n\n\n\n\n\n\nElaboración propia: Mediante RStudio.\n\n\n\n\n\nFigura 6: Tendencia constante nos prezos de peche axustados da empresa “Nueva Expresión Textil S.A”\n\n\n\n\n\n\nElaboración propia: A partir dos datos obtidos de  (n.d.) correspondentes á empresa “Nueva Expreción Textil S.A” no período comprendido entre o 31 de xaneiro de 2000 e o 28 de febreiro de 2023.\n\n\n\n\n\nFigura 7: Cambio brusco de prezos que reflicte un cálculo erróneo dos prezos de peche axustados, “BANKINTER,S.A.”\n\n\n\n\n\n\nElaboración propia: A partir dos datos obtidos de  (n.d.) correspondentes á empresa “Nueva Expreción Textil S.A” no período comprendido entre o 31 de xaneiro de 2000 e o 28 de febreiro de 2023.\n\n\n\n\n\nFigura 8: Evolución dos indicadores – Entradas cunha observación\n\n\n\n\n\n\nElaboración propia: Mediante o uso de R e Rstudio.\n\n\n\n\n\nFigura 9: Evolución dos indicadores – Entradas con dúas observacións\n\n\n\n\n\n\nElaboración propia: Mediante o uso de R e Rstudio.\n\n\n\n\n\nFigura 10: Evolución dos indicadores – Entradas con tres observacións\n\n\n\n\n\n\nElaboración propia: Mediante o uso de R e Rstudio.\n\n\n\n\n\nFigura 11: Evolución das carteiras e do IBEX – Entradas cunha observación\n\n\n\n\n\n\nElaboración propia: Mediante o uso de R e Rstudio.\n\n\n\n\n\nFigura 12: Evolución das carteiras e do IBEX – Entradas con dúas observacións\n\n\n\n\n\n\nElaboración propia: Mediante o uso de R e Rstudio.\n\n\n\n\n\nFigura 13: Evolución das carteiras e do IBEX – Entradas con tres observacións\n\n\n\n\n\n\nElaboración propia: Mediante o uso de R e Rstudio.\n\n\n\n\n\nn.d. Yahoo Finance. https://finance.yahoo.com/."
  },
  {
    "objectID": "Annex3.html",
    "href": "Annex3.html",
    "title": "Anexo. 3 Taboleiros",
    "section": "",
    "text": "Táboa 1: Estrutura de datos de prezos\n\n\nDate\nOpen\nHigh\nLow\nClose\nVolume\nAdjusted\n\n\n\n\n2001-05-24\n3.600\n3.620\n3.510\n3.608\n216270100\n-0.1317839\n\n\n2001-05-25\n3.600\n3.676\n3.580\n3.602\n50448300\n-0.1315648\n\n\n2001-05-28\n3.560\n3.604\n3.544\n3.580\n26118945\n-0.1307612\n\n\n2001-05-29\n3.562\n3.626\n3.562\n3.614\n26910070\n-0.1320031\n\n\n2001-05-30\n3.606\n3.648\n3.602\n3.620\n48229995\n-0.1322222\n\n\n2001-05-31\n3.620\n3.676\n3.610\n3.670\n24806710\n-0.1340484\n\n\n\n\n\nElaboración propia: Mediante o uso de RStudio coa base de datos histórica de “INDITEX”, obtida de https://finance.yahoo.com/, no período comprendido entre o 24-05-2001 ao 31-05-2001.\n\n\n\n\nTáboa 2: Listaxe de sociedades cotizadas\n\n\n\n\n\n\n\n\n\n\nNOMBRE\nTICKERS\nSECTOR-SUBSECTOR\nMERCADO\nINDICE\nSeleccionadas\n\n\n\n\nACCIONA,S.A.\nANA.MC\nMat.Basicos, Industria y Construcción - Construcción\nMC\nIBEX 35®, IGBM\nX\n\n\nACERINOX, S.A.\nACX.MC\nMat.Basicos, Industria y Construcción - Mineral, Metales y Transformación\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nACS,ACTIVIDADES DE CONST.Y SERVICIOS S.A\nACS.MC\nMat.Basicos, Industria y Construcción - Construcción\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nADOLFO DOMINGUEZ, S.A.\nADZ.MC\nBienes de Consumo - Textil, Vestido y Calzado\nMC\nIGBM\nX\n\n\nAEDAS HOMES, S.A.\nAEDAS.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nIGBM\nX\n\n\nAENA, S.M.E., S.A.\nAENA.MC\nServicios de Consumo - Transporte y Distribución\nMC\nIBEX 35®, IGBM\nX\n\n\nAIRBUS SE\nAIR.MC\nMat.Basicos, Industria y Construcción - Aerospacial\nMC\nIGBM\nX\n\n\nAIRTIFICIAL INTELLIGENCE STRUCTURES S.A.\nAI.MC\nMat.Basicos, Industria y Construcción - Ingeniería y Otros\nMC\nIGBM\n\n\n\nALANTRA PARTNERS, S.A.\nALNT.MC\nServicios Financieros - Cartera y Holding\nMC\nIGBM\n\n\n\nALMIRALL, S.A.\nALM.MC\nBienes de Consumo - Productos farmaceúticos y Biotecnología\nMC\nIGBM\nX\n\n\nAMADEUS IT GROUP, S.A.\nAMS.MC\nTecnología y Telecomunicaciones - Electrónica y Software\nMC\nIBEX 35®, IGBM\nX\n\n\nAMPER, S.A.\nAMP.MC\nTecnología y Telecomunicaciones - Electrónica y Software\nMC\nIGBM\nX\n\n\nAMREST HOLDINGS, S.E.\nEAT.MC\nServicios de Consumo - Ocio, Turismo y Hostelería\nMC\nIGBM\nX\n\n\nAPERAM, SOCIETE ANONYME\nAPAM.MC\nMat.Basicos, Industria y Construcción - Mineral, Metales y Transformación\nMC\nNA\nX\n\n\nAPPLUS SERVICES, S.A.\nAPPS.MC\nMat.Basicos, Industria y Construcción - Ingeniería y Otros\nMC\nIGBM\nX\n\n\nARCELORMITTAL, S.A.\nMTS.MC\nMat.Basicos, Industria y Construcción - Mineral, Metales y Transformación\nMC\nIBEX 35®, IGBM\nX\n\n\nÁRIMA REAL ESTATE SOCIMI, S.A.\nARM.MC\nServicios Inmobiliarios - SOCIMI\nMC\nIGBM\nX\n\n\nATRESMEDIA CORP. DE MEDIOS DE COM. S.A.\nA3M.MC\nServicios de Consumo - Medios de Comunicación y Publicidad\nMC\nIGBM\nX\n\n\nATRYS HEALTH, S.A.\nATRY.MC\nBienes de Consumo - Productos farmaceúticos y Biotecnología\nMC\nIGBM\nX\n\n\nAUDAX RENOVABLES, S.A.\nADX.MC\nPetróleo y Energía - Energías Renovables\nMC\nIGBM\n\n\n\nAZKOYEN S.A.\nAZK.MC\nMat.Basicos, Industria y Construcción - Fabric. y Montaje Bienes de Equipo\nMC\nIGBM\nX\n\n\nBANCO BILBAO VIZCAYA ARGENTARIA, S.A.\nBBVA.MC\nServicios Financieros - Bancos y Cajas de Ahorro\nMC\nIBEX 35®, IGBM\nX\n\n\nBANCO DE SABADELL, S.A.\nSAB.MC\nServicios Financieros - Bancos y Cajas de Ahorro\nMC\nIBEX 35®, IGBM\nX\n\n\nBANCO SANTANDER, S.A.\nSAN.MC\nServicios Financieros - Bancos y Cajas de Ahorro\nMC\nIBEX 35®, IGBM\nX\n\n\nBANKINTER,S.A.\nBKT.MC\nServicios Financieros - Bancos y Cajas de Ahorro\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nBERKELEY ENERGIA LIMITED\nBKY.MC\nMat.Basicos, Industria y Construcción - Mineral, Metales y Transformación\nMC\nIGBM\nX\n\n\nBODEGAS RIOJANAS, S.A.\nRIO.MC\nBienes de Consumo - Alimentación y Bebidas\nMC\nIGBM\nX\n\n\nBORGES AGRICULTURAL & INDUST. NUTS, S.A.\nBAIN.MC\nBienes de Consumo - Alimentación y Bebidas\nMC\nNA\n\n\n\nCAIXABANK, S.A.\nCABK.MC\nServicios Financieros - Bancos y Cajas de Ahorro\nMC\nIBEX 35®, IGBM\nX\n\n\nCAJA DE AHORROS DEL MEDITERRANEO\nCAM.MC\nServicios Financieros - Bancos y Cajas de Ahorro\nMC\nNA\n\n\n\nCASH, S.A.\nCASH.MC\nServicios de Consumo - Otros Servicios\nMC\nIGBM, IBEXTD®\nX\n\n\nCELLNEX TELECOM, S.A.\nCLNX.MC\nTecnología y Telecomunicaciones - Telecomunicaciones y Otros\nMC\nIBEX 35®, IGBM\nX\n\n\nCIA. DE DIST. INTEG. LOGISTA HOLDINGS\nLOG.MC\nServicios de Consumo - Transporte y Distribución\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nCIA. ESPAÑOLA VIVIENDAS EN ALQUILER,S.A\nCEV.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nNA\n\n\n\nCIA.LEVANTINA, EDIFICACION DE O.PUBLICAS\nCLEO.MC\nMat.Basicos, Industria y Construcción - Construcción\nMC\nNA\n\n\n\nCIE AUTOMOTIVE, S.A.\nCIE.MC\nMat.Basicos, Industria y Construcción - Mineral, Metales y Transformación\nMC\nIGBM\nX\n\n\nCLINICA BAVIERA, S.A.\nCBAV.MC\nServicios de Consumo - Otros Servicios\nMC\nIGBM\nX\n\n\nCOCA-COLA EUROPACIFIC PARTNERS PLC\nCCEP.MC\nBienes de Consumo - Alimentación y Bebidas\nMC\nIGBM\nX\n\n\nCONSTRUCC. Y AUX. DE FERROCARRILES, S.A.\nCAF.MC\nMat.Basicos, Industria y Construcción - Fabric. y Montaje Bienes de Equipo\nMC\nIGBM\nX\n\n\nCORP. ACCIONA ENERGÍAS RENOVABLES, S.A.\nANE.MC\nPetróleo y Energía - Energías Renovables\nMC\nIBEX 35®, IGBM\nX\n\n\nCORPORACION FINANCIERA ALBA, S.A.\nALB.MC\nServicios Financieros - Cartera y Holding\nMC\nIGBM\nX\n\n\nDEOLEO, S.A.\nOLE.MC\nBienes de Consumo - Alimentación y Bebidas\nMC\nIGBM\nX\n\n\nDESA\nDESA.MC\nMat.Basicos, Industria y Construcción - Mineral, Metales y Transformación\nMC\nNA\n\n\n\nDIA-DISTRIBUIDORA INT. DE ALIMENT. S.A.\nDIA.MC\nServicios de Consumo - Comercio\nMC\nIGBM\nX\n\n\nDURO FELGUERA, S.A.\nMDF.MC\nMat.Basicos, Industria y Construcción - Ingeniería y Otros\nMC\nIGBM\nX\n\n\nEBRO FOODS, S.A.\nEBRO.MC\nBienes de Consumo - Alimentación y Bebidas\nMC\nIGBM, IBEXTD®\nX\n\n\nEDREAMS ODIGEO, S.A.\nEDR.MC\nServicios de Consumo - Ocio, Turismo y Hostelería\nMC\nIGBM\nX\n\n\nELECNOR S. A.\nENO.MC\nMat.Basicos, Industria y Construcción - Fabric. y Montaje Bienes de Equipo\nMC\nIGBM, IBEXTD®\nX\n\n\nENAGAS, S.A.\nENG.MC\nPetróleo y Energía - Electricidad y Gas\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nENCE ENERGIA Y CELULOSA, S.A.\nENC.MC\nBienes de Consumo - Papel y Artes Gráficas\nMC\nIGBM\nX\n\n\nENDESA, SOCIEDAD ANONIMA\nELE.MC\nPetróleo y Energía - Electricidad y Gas\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nERCROS S.A.\nECR.MC\nMat.Basicos, Industria y Construcción - Industria Química\nMC\nIGBM\nX\n\n\nFAES FARMA, S.A.\nFAE.MC\nBienes de Consumo - Productos farmaceúticos y Biotecnología\nMC\nIGBM, IBEXTD®\nX\n\n\nFERROVIAL, S.A.\nFER.MC\nMat.Basicos, Industria y Construcción - Construcción\nMC\nIBEX 35®, IGBM\nX\n\n\nFLUIDRA, S.A.\nFDR.MC\nMat.Basicos, Industria y Construcción - Ingeniería y Otros\nMC\nIBEX 35®, IGBM\nX\n\n\nFOMENTO DE CONSTR. Y CONTRATAS S.A.\nFCC.MC\nMat.Basicos, Industria y Construcción - Construcción\nMC\nIGBM, IBEXTD®\nX\n\n\nGENERAL DE ALQUILER DE MAQUINARIA, S.A.\nGAM.MC\nMat.Basicos, Industria y Construcción - Ingeniería y Otros\nMC\nIGBM\n\n\n\nGESTAMP AUTOMOCION, S.A.\nGEST.MC\nMat.Basicos, Industria y Construcción - Fabric. y Montaje Bienes de Equipo\nMC\nIGBM\nX\n\n\nGLOBAL DOMINION ACCESS, S.A.\nDOM.MC\nTecnología y Telecomunicaciones - Telecomunicaciones y Otros\nMC\nIGBM\nX\n\n\nGRENERGY RENOVABLES, S.A.\nGRE.MC\nPetróleo y Energía - Energías Renovables\nMC\nIGBM\nX\n\n\nGRIFOLS, S.A.\nGRF.MC\nBienes de Consumo - Productos farmaceúticos y Biotecnología\nMC\nIBEX 35®, IGBM\nX\n\n\nGRUPO CATALANA OCCIDENTE, S.A.\nGCO.MC\nServicios Financieros - Seguros\nMC\nIGBM\nX\n\n\nGRUPO ECOENER, S.A.\nENER.MC\nPetróleo y Energía - Energías Renovables\nMC\nIGBM\nX\n\n\nGRUPO EMPRESARIAL SAN JOSE, S.A.\nGSJ.MC\nMat.Basicos, Industria y Construcción - Construcción\nMC\nIGBM\nX\n\n\nGRUPO EZENTIS, S.A.\nEZE.MC\nTecnología y Telecomunicaciones - Telecomunicaciones y Otros\nMC\nNA\nX\n\n\nIBERDROLA, S.A.\nIBE.MC\nPetróleo y Energía - Electricidad y Gas\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nIBERPAPEL GESTION, S.A.\nIBG.MC\nBienes de Consumo - Papel y Artes Gráficas\nMC\nIGBM\nX\n\n\nINDRA SISTEMAS, S.A., SERIE A\nIDR.MC\nTecnología y Telecomunicaciones - Electrónica y Software\nMC\nIBEX 35®, IGBM\nX\n\n\nINDUSTRIA DE DISEÑO TEXTIL, SA “INDITEX”\nITX.MC\nBienes de Consumo - Textil, Vestido y Calzado\nMC\nIBEX 35®, IGBM\nX\n\n\nINMOBILIARIA COLONIAL SOCIMI, S.A.\nCOL.MC\nServicios Inmobiliarios - SOCIMI\nMC\nIBEX 35®, IGBM\nX\n\n\nINMOBILIARIA DEL SUR, S.A.\nISUR.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nIGBM\nX\n\n\nINNOVATIVE SOLUTIONS ECOSYSTEM, S.A.\nISE.MC\nServicios de Consumo - Comercio\nMC\nNA\n\n\n\nINTERNATIONAL CONSOLIDAT. AIRLINES GROUP\nIAG.MC\nServicios de Consumo - Transporte y Distribución\nMC\nIBEX 35®, IGBM\nX\n\n\nLABORATORIO REIG JOFRE, S.A.\nRJF.MC\nBienes de Consumo - Productos farmaceúticos y Biotecnología\nMC\nIGBM\nX\n\n\nLABORATORIOS FARMACEUTICOS ROVI, S.A.\nROVI.MC\nBienes de Consumo - Productos farmaceúticos y Biotecnología\nMC\nIBEX 35®, IGBM\nX\n\n\nLAR ESPAÑA REAL ESTATE, SOCIMI, S.A.\nLRE.MC\nServicios Inmobiliarios - SOCIMI\nMC\nIGBM, IBEXTD®\nX\n\n\nLIBERTAS 7, S.A.\nLIB.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nNA\n\n\n\nLINEA DIRECTA ASEGURADORA, S.A.\nLDA.MC\nServicios Financieros - Seguros\nMC\nIGBM\nX\n\n\nLINGOTES ESPECIALES, S.A.\nLGT.MC\nMat.Basicos, Industria y Construcción - Mineral, Metales y Transformación\nMC\nNA\nX\n\n\nMAPFRE, S.A.\nMAP.MC\nServicios Financieros - Seguros\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nMELIA HOTELS INTERNATIONAL, S.A.\nMEL.MC\nServicios de Consumo - Ocio, Turismo y Hostelería\nMC\nIBEX 35®, IGBM\nX\n\n\nMERLIN PROPERTIES, SOCIMI, S.A.\nMRL.MC\nServicios Inmobiliarios - SOCIMI\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nMETROVACESA, S.A.\nMVC.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nIGBM\nX\n\n\nMIQUEL Y COSTAS & MIQUEL, S.A.\nMCM.MC\nBienes de Consumo - Papel y Artes Gráficas\nMC\nIGBM, IBEXTD®\nX\n\n\nMONTEBALITO, S.A.\nMTB.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nNA\nX\n\n\nNATURGY ENERGY GROUP, S.A.\nNTGY.MC\nPetróleo y Energía - Electricidad y Gas\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nNATURHOUSE HEALTH, S.A.\nNTH.MC\nBienes de Consumo - Alimentación y Bebidas\nMC\nIGBM\nX\n\n\nNEINOR HOMES, S.A.\nHOME.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nIGBM\nX\n\n\nNH HOTEL GROUP, S.A.\nNHH.MC\nServicios de Consumo - Ocio, Turismo y Hostelería\nMC\nIGBM\nX\n\n\nNICOLAS CORREA S.A.\nNEA.MC\nMat.Basicos, Industria y Construcción - Fabric. y Montaje Bienes de Equipo\nMC\nIGBM, IBEXTD®\nX\n\n\nNUEVA EXPRESION TEXTIL, S.A.\nNXT.MC\nBienes de Consumo - Textil, Vestido y Calzado\nMC\nIGBM\n\n\n\nNYESA VALORES CORPORACION, S.A.\nNYE.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nIGBM\n\n\n\nOBRASCON HUARTE LAIN, S.A.\nOHLA.MC\nMat.Basicos, Industria y Construcción - Construcción\nMC\nIGBM\nX\n\n\nOPDENERGY HOLDING, S.A.\nOPDE.MC\nPetróleo y Energía - Energías Renovables\nMC\nIGBM\nX\n\n\nORYZON GENOMICS, S.A.\nORY.MC\nBienes de Consumo - Productos farmaceúticos y Biotecnología\nMC\nIGBM\nX\n\n\nPESCANOVA, S.A.\nPVA.MC\nBienes de Consumo - Alimentación y Bebidas\nMC\nIGBM\n\n\n\nPHARMA MAR, S.A.\nPHM.MC\nBienes de Consumo - Productos farmaceúticos y Biotecnología\nMC\nIGBM\nX\n\n\nPRIM, S.A.\nPRM.MC\nBienes de Consumo - Productos farmaceúticos y Biotecnología\nMC\nIGBM\nX\n\n\nPROMOTORA DE INFORMACIONES,S.A.\nPRS.MC\nServicios de Consumo - Medios de Comunicación y Publicidad\nMC\nIGBM\nX\n\n\nPROSEGUR , CIA. DE SEGURIDAD, S.A.\nPSG.MC\nServicios de Consumo - Otros Servicios\nMC\nIGBM, IBEXTD®\nX\n\n\nREALIA BUSINESS, S.A.\nRLIA.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nIGBM\nX\n\n\nRED ELECTRICA CORPORACION, S.A.\nRED.MC\nPetróleo y Energía - Electricidad y Gas\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nRENTA 4 BANCO, S.A.\nR4.MC\nServicios Financieros - Servicios de Inversión\nMC\nIGBM\nX\n\n\nRENTA CORPORACION REAL ESTATE, S.A.\nREN.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nIGBM\n\n\n\nREPSOL, S.A.\nREP.MC\nPetróleo y Energía - Petróleo\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nSACYR, S.A.\nSCYR.MC\nMat.Basicos, Industria y Construcción - Construcción\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nSOLARIA ENERGIA Y MEDIO AMBIENTE, S.A.\nSLR.MC\nPetróleo y Energía - Energías Renovables\nMC\nIBEX 35®, IGBM\nX\n\n\nSOLTEC POWER HOLDINGS, S.A.\nSOL.MC\nPetróleo y Energía - Energías Renovables\nMC\nIGBM\nX\n\n\nSQUIRREL MEDIA, S.A\nSQRL.MC\nServicios de Consumo - Medios de Comunicación y Publicidad\nMC\nNA\n\n\n\nTALGO, S.A.\nTLGO.MC\nMat.Basicos, Industria y Construcción - Fabric. y Montaje Bienes de Equipo\nMC\nIGBM\nX\n\n\nTECNICAS REUNIDAS, S.A.\nTRE.MC\nMat.Basicos, Industria y Construcción - Ingeniería y Otros\nMC\nIGBM\nX\n\n\nTELEFONICA, S.A.\nTEF.MC\nTecnología y Telecomunicaciones - Telecomunicaciones y Otros\nMC\nIBEX 35®, IGBM, IBEXTD®\nX\n\n\nTUBACEX, S.A.\nTUB.MC\nMat.Basicos, Industria y Construcción - Mineral, Metales y Transformación\nMC\nIGBM\nX\n\n\nTUBOS REUNIDOS,S.A.\nTRG.MC\nMat.Basicos, Industria y Construcción - Mineral, Metales y Transformación\nMC\nIGBM\nX\n\n\nUNICAJA BANCO, S.A.\nUNI.MC\nServicios Financieros - Bancos y Cajas de Ahorro\nMC\nIBEX 35®, IGBM\nX\n\n\nURBAS GRUPO FINANCIERO, S.A.\nUBS.MC\nServicios Inmobiliarios - Inmobiliarias y Otros\nMC\nIGBM\n\n\n\nVIDRALA S.A.\nVID.MC\nBienes de Consumo - Otros Bienes de Consumo\nMC\nIGBM\nX\n\n\nVISCOFAN, S.A.\nVIS.MC\nBienes de Consumo - Alimentación y Bebidas\nMC\nIGBM, IBEXTD®\nX\n\n\nVOCENTO, S.A.\nVOC.MC\nServicios de Consumo - Medios de Comunicación y Publicidad\nMC\nIGBM\nX\n\n\n\n\n\n::: figure-caption Obtido de: A información exposta no sitio oficial das Bolsas e Mercados Españoles, “Empresas Cotizadas” (n.d.). Nota: MC en MARKET significa Mercado Continuo, IBEXTD en INDEX significa IBEX TOP Dividendo. :::\n\n\nTáboa 3: Cantidades de mostras utilizadas para adestrar os modelos\n\n\nEntradas\nMuestras.totales\n\n\n\n\n1\n17347\n\n\n2\n17244\n\n\n3\n17141\n\n\n\n\n\nObtido de: A información exposta no sitio oficial das Bolsas e Mercados de Valores Españoles, “Empresas Cotizadas” (n.d.).\n\n\n\n\n\nTáboa 4: Mellores e mellores empresas segundo os resultados obtidos dos cálculos dos indicadores\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n\nTICKER\nR2\nMSE\nTICKER\nR2\nMSE\nTICKER\nR2\nMSE\n\n\n\n\nOPDE.MC\n0.4976431\n0.0140459\nOPDE.MC\n0.3889262\n0.0119095\nOPDE.MC\n0.4861395\n0.0121918\n\n\nOLE.MC\n0.1408607\n0.2092006\nSOL.MC\n0.3037137\n0.0225800\nANE.MC\n0.3485550\n0.0063473\n\n\nANE.MC\n0.1073977\n0.0066219\nANE.MC\n0.1965812\n0.0064902\nSOL.MC\n0.3160949\n0.0207540\n\n\nDOM.MC\n0.1032658\n0.0055531\nBKY.MC\n0.1687609\n0.1873538\nBKY.MC\n0.1983894\n0.2024927\n\n\nMVC.MC\n0.1005222\n0.0095915\nTLGO.MC\n0.1390272\n0.0087595\nLOG.MC\n0.1928642\n0.0045066\n\n\nBKY.MC\n0.0612159\n0.2068808\nOLE.MC\n0.1077772\n0.2036521\nLDA.MC\n0.1502733\n0.0035126\n\n\nTLGO.MC\n0.0586490\n0.0091608\nAEDAS.MC\n0.1069500\n0.0069291\nTLGO.MC\n0.1165425\n0.0081263\n\n\nMRL.MC\n0.0558508\n0.0062275\nMVC.MC\n0.0990202\n0.0097977\nOLE.MC\n0.0676713\n0.2072154\n\n\nAEDAS.MC\n0.0504877\n0.0072116\nENER.MC\n0.0977418\n0.0098403\nCBAV.MC\n0.0590027\n0.0116354\n\n\nNTH.MC\n0.0496536\n0.0108446\nCCEP.MC\n0.0865251\n0.0041225\nENER.MC\n0.0523626\n0.0111998\n\n\nEBRO.MC\n-0.1131305\n0.0026464\nAENA.MC\n-0.0116025\n0.0059543\nBBVA.MC\n-0.1015487\n0.0106436\n\n\nVID.MC\n-0.1182183\n0.0054714\nPRS.MC\n-0.0147394\n0.0274017\nSAN.MC\n-0.1064919\n0.0101428\n\n\nAMS.MC\n-0.1195827\n0.0061822\nDIA.MC\n-0.0251285\n0.0218383\nEBRO.MC\n-0.1097231\n0.0026198\n\n\nATRY.MC\n-0.1372633\n0.0122878\nRIO.MC\n-0.0251470\n0.0029560\nRED.MC\n-0.1307882\n0.0038899\n\n\nENER.MC\n-0.1393435\n0.0124522\nVIS.MC\n-0.0288599\n0.0034482\nMVC.MC\n-0.1332527\n0.0125188\n\n\nPRM.MC\n-0.1685250\n0.0073096\nTEF.MC\n-0.0294417\n0.0054187\nRIO.MC\n-0.1363685\n0.0032897\n\n\nAPPS.MC\n-0.2295015\n0.0080938\nITX.MC\n-0.0311148\n0.0077844\nALB.MC\n-0.1487811\n0.0052084\n\n\nR4.MC\n-0.2788249\n0.0022699\nGRE.MC\n-0.0456889\n0.0285741\nIBE.MC\n-0.1519585\n0.0056253\n\n\nVIS.MC\n-0.2859081\n0.0042912\nATRY.MC\n-0.1516661\n0.0125130\nHOME.MC\n-0.1528376\n0.0073972\n\n\nLDA.MC\n-0.3181947\n0.0054316\nLDA.MC\n-0.1579126\n0.0042955\nVIS.MC\n-0.1825075\n0.0039782\n\n\n\n\n\n\n\n\n\nElaboración propia.\n\n\n\n\n\n“Empresas Cotizadas.” n.d. BME Exchange. Accessed May 21, 2023. https://www.bolsasymercados.es/bme-exchange/es/Mercados-y-Cotizaciones/Acciones/Mercado-Continuo/Empresas-Cotizadas."
  },
  {
    "objectID": "Annex4.html#datos",
    "href": "Annex4.html#datos",
    "title": "Anexo. 4 Códigos",
    "section": "Datos",
    "text": "Datos\n\nRecollida de datos\nO primeiro que se fixo foi cargar a táboa de empresas.\n\nlibrary(readxl)\nempresas &lt;- read_excel(\"data/000_empresas.xlsx\")\n\nDespois extraíanse as carrachas das empresas.\n\nlibrary(dplyr)\nticks &lt;- empresas |&gt; \n  select(TICKERS) |&gt; \n  pull()\n\nUnha vez almacenados os ticks das empresas na variable ticks, os datos correspondentes a ditas empresas foron descargados de Yahoo Finance mediante o paquete quantmod de Ryan and Ulrich (2023).\n\nlibrary(quantmod)\nnombres_colum &lt;- c(\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\"Adjusted\")\nqmd_data &lt;- list()\nfor (i in 1:length(ticks)) {\n  tick &lt;- ticks[i]\n  value &lt;- getSymbols(\n    tick,\n    from = \"2000-01-02\",\n    to = \"2023-03-01\",\n    auto.assign = F,\n    periodicity = \"monthly\") |&gt;\n    as.data.frame()\n  dates &lt;- row.names(value)\n  row.names(value) &lt;- NULL\n  value &lt;- cbind(dates,value)\n  names(value) &lt;- nombres_colum\n  qmd_data[[tick]] &lt;-  value\n}\n\nCo obxectivo de realizar unha análise exploratoria dos datos, optouse por realizar unha avaliación visual dos datos históricos do prezo axustado polo que se executou:\n\nlapply(qmd_data, function(x){\n  x |&gt;\n    ggplot(aes(x=as.Date(Date), y=Adjusted))+\n             geom_line(color=\"#065AD8\")\n})\n\nTras a análise visual realizada co fragmento de código anterior detectouse a existencia de prezos constantes, así como cálculos erróneos no prezo axustado correspondente aos primeiros anos dalgunha serie. Para eliminar estas irregularidades, só se seleccionaron aquelas observacións posteriores a xaneiro de 2005.\n\nreturns_emps &lt;- qmd_data |&gt;\n  lapply(function(x){\n    emps &lt;- x |&gt;\n      filter(Date &gt;= \"2005-01-31\")\n  })\n\nPara determinar se os datos que foran importados tiñan valores que faltaban, executouse o seguinte código:\n\nna_values &lt;- returns_emps |&gt;\n  sapply(function(x){\n    na &lt;- length(which(is.na(x)))\n  })\nemp_con_na &lt;- which(na_values &gt; 0)\n\nPara solucionar o problema de rexistro incorrecto dos datos, optouse por eliminar aqueles que non presentasen variacións de prezo en máis de 10 observacións. Para o cal, os retornos calculáronse primeiro executando o seguinte código, mediante o cal tamén se eliminaron as series con valores ausentes.\n\nreturns_emps2 &lt;- returns_emps[-emp_con_na] |&gt;\n  lapply(function(x){\n    returns &lt;- x |&gt;\n      select(Date, Adjusted) |&gt;\n      mutate(Return_Ad = Delt(Adjusted)[,1]) |&gt;\n      na.omit() |&gt;\n      select(Date, Return_Ad)\n  })\n\nUnha vez computados os retornos, elimináronse aquelas series que presentaban 0 retornos en máis de 10 observacións, para o que se executou o seguinte código.\n\nzero_values &lt;- returns_emps2 |&gt;\n  sapply(function(x){\n    zeros &lt;- length(which(x[,2]==0))\n  })\nreturns_emps3 &lt;- returns_emps2[zero_values&lt;10]\n\n\n\nIndicadores\nA continuación móstrase o código utilizado durante o proceso descrito no subtítulo de indicadores do capítulo 2.\nEn primeiro lugar, descargáronse os datos do IBEX, calculáronse os rendementos do prezo axustado dos mesmos e seleccionáronse os valores posteriores a xaneiro de 2005.\n\n#Importando IBEX\nIBEXsel &lt;- getSymbols(\n  \"^IBEX\",\n  from = \"1990-01-01\",\n  to = \"2023-03-01\",\n  auto.assign = F,\n  periodicity = \"monthly\") |&gt;\n  as.data.frame()\ndates &lt;- row.names(IBEXsel)\nrow.names(IBEXsel) &lt;- NULL\nIBEXsel &lt;- cbind(dates,IBEXsel)\nnames(IBEXsel) &lt;- nombres_colum\n# Cálculo da rendibilidade e selección de observacións despois\n# Xaneiro 2005.\nIBEXsel &lt;- IBEXsel |&gt;\n  mutate(Return_I = Delt(Adjusted)[,1]) |&gt;\n  na.omit() |&gt;\n  filter(Date &gt;= \"2005-01-31\") |&gt;\n  select(Date, Return_I)\n\nA continuación, engadíronse os valores das rendibilidades do IBEX ás táboas de rendibilidade das accións das empresas seleccionadas, e calculáronse e engadíronse a cada unha das táboas as variables que se enumeran a continuación:\n\nVolatilidade da empresa\nVolatilidade do índice\nCorrelación entre a rendibilidade da empresa e o índice\nA Beta entre a empresa e o índice\n\n\nreturns_indc &lt;- returns_emps3 |&gt;\n  lapply(function(x, ind = IBEXsel){\n    emp &lt;- x |&gt;\n      left_join(ind) |&gt;\n      mutate(\n        VE = sqrt(cumsum((Return_Ad - cummean(Return_Ad))^2)/1:length(Return_Ad)),\n        VI = sqrt(cumsum((Return_I - cummean(Return_I))^2)/1:length(Return_I)),\n        Cor = cumsum((Return_Ad-cummean(Return_Ad))*(Return_I-cummean(Return_I)))/(sqrt(cumsum((Return_Ad-cummean(Return_Ad))^2))*sqrt(cumsum((Return_I-cummean(Return_I))^2)))\n      )|&gt;\n      na.omit() |&gt;\n      mutate(\n        Beta = (Cor*VE)/VI\n      )\n  })\n\n\n\nVectores\nA continuación móstrase o código utilizado durante o proceso descrito no subtítulo de vectores do título de modelado do capítulo 2.\nO primeiro paso realizado para a execución do proceso explicado no subepígrafe en cuestión foi a creación dunha función que permitise obter as mostras consecutivas para cada serie utilizada. A función que se presenta a continuación, como xa se dixo, permite obter as mostras consecutivas dunha serie, para as que se utilizan os parámetros mencionados no subtítulo, número de observacións de entrada e número de observacións de saída, así como un parámetro condicional co que se indícase se o vector que se vai crear é de entrada ou de saída.\n\nvector2dmaker &lt;- function(vec, ent, sal, eos=T){\n  if(eos==T){\n    emp &lt;- 1\n    term &lt;- (length(vec) - (ent+sal-1))\n    ob &lt;- ent\n  }else{\n    emp &lt;- ent + 1\n    term &lt;- (length(vec)-sal+1)\n    ob &lt;- sal\n  }\n  \n  vec2d &lt;- sapply(emp:term,\n               function(x) vec[x:(x + ob-1)]) |&gt;\n    matrix(nrow = ob) |&gt;\n    t()\n  \n  return(vec2d)\n}\n\nA continuación móstrase o código utilizado para crear os vectores de entrada correspondentes a cada unha das series. Para o cal se crearon primeiro dúas funcións, unha para as entradas e outra para as saídas.\n\n# Función que se utilizará para crear as entradas tridimensionais\ninput3dmaker &lt;- function(x,inp,out){\n  empre &lt;- x\n  series &lt;- 2:dim(x)[2]\n  for (i in series) {\n    if(i==series[1]){\n      vec3d &lt;- vector2dmaker(empre[[i]],ent=inp,sal=out)\n    }else{\n      vec3d &lt;- abind(vec3d,vector2dmaker(empre[[i]],ent=inp,sal=out), along = 3)\n    }\n  }\n  return(vec3d)\n}\n\n# Función que se utilizará para crear as saídas tridimensionais\noutput3dmaker &lt;- function(x,inp,out){\n  empre &lt;- x[[\"Return_Ad\"]]\n  vec3d &lt;- vector2dmaker(empre,ent=inp,sal=out,F)\n  dim(vec3d) &lt;- c(dim(vec3d),1)\n  return(vec3d)\n}\n\nDespois creáronse as listas de vectores tridimensionais de entradas e saídas por empresa, executando outras dúas veces o seguinte código co obxectivo de crear as listas vecs3d2e e vecs3d3e que se corresponden con aqueles casos nos que foron 2 e 3 entradas. seleccionados.\n\n# O horizonte temporal está definido\nht &lt;- 1\n\n# Defínense as observacións de entrada\noe &lt;- 1\n\n# Os vectores de entrada 3D créanse para o tamaño de entrada 1\nvecs3d1e &lt;- list()\nfor(i in 1:length(returns_indc)){\n  emp &lt;- returns_indc[[i]]\n  inps &lt;- input3dmaker(emp, oe, ht)\n  outs &lt;- output3dmaker(emp, oe, ht)\n  dates &lt;- emp[(oe + ht):dim(emp)[1],1]\n  id &lt;- rep(names(returns_indc)[i],length(dates))\n  tibblex &lt;- tibble(\n    Date = dates,\n    ID = id,\n    inputs = inps,\n    outputs = outs\n  )\n  vecs3d1e[[names(returns_indc)[i]]] &lt;- tibblex\n}"
  },
  {
    "objectID": "Annex4.html#modelado-e-formación",
    "href": "Annex4.html#modelado-e-formación",
    "title": "Anexo. 4 Códigos",
    "section": "Modelado e formación",
    "text": "Modelado e formación\nA continuación preséntase o código utilizado durante o proceso descrito nas diferentes subseccións da sección Modelado e formación.\n\nModelado\nPara a creación dos modelos, o primeiro paso a executar é obter a información dos vectores para os que se vai construír o modelo, o que se fixo executando o seguinte código:\n\ndata &lt;- bind_rows(vecs3d1e)\ndata &lt;- data  |&gt;\n  arrange(Date)\ninputsinfo &lt;- data|&gt;\n  select(inputs) |&gt;\n  pull() |&gt;\n  dim()\noutputsinfo &lt;- data|&gt;\n  select(outputs) |&gt;\n  pull() |&gt;\n  dim()\n\n# Definir parámetros\nn_ob_pas &lt;- inputsinfo[2]\nn_variables &lt;- inputsinfo[3]\nn_ob_fut &lt;- outputsinfo[2]\n\nDespois constituíuse a estrutura dos modelos cos aspectos descritos en Sección 1.\n\n# Capa de entrada\ninp &lt;- layer_input(\n  shape = c(NULL,n_ob_pas,n_variables))\n\n# Capas ocultas\n# - CNN\ncnn &lt;- inp |&gt;\n  layer_conv_1d(\n    filters = 64,\n    kernel_size = 1,\n    activation = layer_activation_leaky_relu())\n# - LSTM\nlstm &lt;- cnn |&gt;\n  layer_lstm(64)\n\n# Capa de Salida\nout &lt;- lstm |&gt; \n  layer_dense(\n    n_ob_fut*1)\n\n# Unir as capas para constituír o modelo\nmodel &lt;- keras_model(inp, out)\n# Establecemento de parámetros de aprendizaxe\nmodel |&gt; \n  compile(loss = \"mse\", optimizer = optimizer_sgd(0.0005))\n\nNota: Podes atopar modelos non adestrados no cartafol data do repositorio onde se atopa este traballo. Os modelos gardáronse usando a extensión hdf5 e baixo os nomes model1e, model2e e model3e.\n\n\nFormación\nO primeiro paso é definir a función a utilizar para adestrar os modelos. Esta función creouse co obxectivo de utilizar o método de adestramento descrito en ?sec-training. Como resultado, esta función devolverá unha lista que conterá as predicións obtidas e o modelo despois de ter sido adestrado e tomará como entradas principais o tibble denominado datos constituído no primeiro paso que se expón en Sección 2.1 e o modelo tamén. doutros argumentos que permitan o uso da función con algunhas entradas principais que non se utilizan no presente traballo.\n\nwfv_train &lt;- function(x, modelo, seq_var_name, inp_var_name = \"inputs\", out_var_name = \"outputs\", progress_bar=T){\n  \n  predictions &lt;- c()\n  seq_val &lt;- unique(x[[seq_var_name]])\n  \n  if(progress_bar){\n    pb &lt;- txtProgressBar(min = 0, max = length(seq_val), initial = 0, style = 3)\n  }\n  \n  \n  # Iteración que se executará para cada valor único na variable que define a secuencia de datos. Por este motivo é de vital importancia que os datos en tibble x estean ordenados pola variable de secuencia cuxo nome se pasa a seq_var_name\n  \n  for (i in 1:length(seq_val)) {\n    val_seq &lt;- seq_val[i]\n    # Extraer entradas e saídas correspondentes ao período na variable secuencia actual\n    inputs &lt;- x |&gt;\n      filter(!!sym(seq_var_name) == val_seq) |&gt;\n      select(!!sym(inp_var_name)) |&gt;\n      pull()\n    outputs &lt;- x |&gt;\n      filter(!!sym(seq_var_name) == val_seq) |&gt;\n      select(!!sym(out_var_name)) |&gt;\n      pull()\n    outputs &lt;- outputs[,,1]\n    \n    # Use entradas para obter previsións para todos os períodos da variable secuencia excepto o primeiro\n    if(i &gt; 1){\n      pred &lt;- modelo |&gt;\n        predict(inputs, verbose = 3)\n      predictions &lt;- rbind(predictions, pred)\n    }\n    \n    # Adestrar o modelo\n    modelo |&gt;\n      fit(\n        inputs,\n        outputs,\n        epochs = 1,\n        batch_size = 10,\n        shuffle = F,\n        verbose = 0)\n    \n    if(progress_bar){\n      setTxtProgressBar(pb,i)\n      }\n    \n  }\n  \n  if(progress_bar){\n    close(pb)\n  }\n  \n  results &lt;- list()\n  results[['predicciones']] &lt;- predictions\n  results[['modelo']] &lt;- modelo\n  return(results)\n}\n\nUnha vez creada a función, obtivéronse as predicións mediante o seguinte código:\n\nresultados &lt;- wfv_train(data,model,'Date')\npredicciones1e &lt;- resultados$predicciones\n\nNota: Podes atopar modelos adestrados no cartafol data do repositorio onde se atopa este traballo. Os modelos gardáronse usando a extensión hdf5 e baixo os nomes model1etd, model2etd e model3etd.\nSegundo se explica en Sección 1, ademais das predicións obtidas polos modelos, calculáronse predicións obtidas a partir do uso da media aritmética, para comparar coas obtidas cos modelos. Para calcular estas predicións, creouse a seguinte función:\n\nwfv_means &lt;- function(x, seq_var_name, inp_var_name = \"inputs\", out_var_name = \"outputs\", id_var_name, progress_bar=T){\n  \n  means &lt;- c()\n  seq_val &lt;- unique(x[[seq_var_name]])\n  \n  if(progress_bar){\n    pb &lt;- txtProgressBar(min = 0, max = length(seq_val), initial = 0, style = 3)\n  }\n  \n  for (i in 1:length(seq_val)) {\n    val_seq &lt;- seq_val[i]\n    inputs &lt;- x |&gt;\n      filter(!!sym(seq_var_name) == val_seq) |&gt;\n      select(!!sym(inp_var_name)) |&gt;\n      pull()\n    inputspred &lt;- x |&gt;\n      filter(!!sym(seq_var_name) == val_seq) |&gt;\n      select(!!sym(inp_var_name)) |&gt;\n      pull()\n    outputs &lt;- x |&gt;\n      filter(!!sym(seq_var_name) == val_seq) |&gt;\n      select(!!sym(out_var_name)) |&gt;\n      pull()\n    outputs &lt;- outputs[,,1]\n    \n    ids &lt;- x |&gt;\n      filter(!!sym(seq_var_name) == val_seq) |&gt;\n      select(!!sym(id_var_name)) |&gt;\n      pull()\n    \n    if(i==1){\n      dfmeans &lt;- inputs[,,1] |&gt;\n        as.data.frame() |&gt;\n        cbind(ID = ids)\n    }else{\n      dfmeansupd &lt;- inputs[,dim(inputs)[2],1] |&gt;\n        as.data.frame() |&gt;\n        cbind(ID = ids)\n      names(dfmeansupd)[1] &lt;- paste0(\"V\",(dim(dfmeans)[2]))\n      idsdf &lt;- unique(c(ids, dfmeans[[id_var_name]]))\n      idsdf &lt;- data.frame(ID = idsdf)\n      dfmeansupd &lt;- dplyr::left_join(idsdf, dfmeansupd, by = \"ID\")\n      ifelse(\n        dim(dfmeansupd)[1] &gt; dim(dfmeans)[1],\n        dfmeans &lt;- dplyr::left_join(dfmeansupd, dfmeans, by = \"ID\"),\n        dfmeans &lt;- dplyr::left_join(dfmeans, dfmeansupd, by = \"ID\")\n        )\n    }\n    \n    if(i &gt; 1){\n      MEANS &lt;-  dfmeans |&gt;\n        rowwise() |&gt;\n        mutate(\n          means = mean(c_across(-!!sym(id_var_name)), na.rm = T)) |&gt;\n        slice(match(ids,!!sym(id_var_name))) |&gt;\n        pull(means) |&gt;\n        as.matrix()\n      means &lt;- rbind(means, MEANS)\n    }\n    \n    if(progress_bar){\n      setTxtProgressBar(pb,i)\n    }\n    \n  }\n  \n  if(progress_bar){\n    close(pb)\n  }\n  \n  return(means)\n}\n\nUnha vez creada a función, obtivéronse as predicións mediante o seguinte código:\n\nmeanse1 &lt;- wfv_train(data,'Date',id_var_name = \"ID\")\n\nNota: Ademais do exposto anteriormente, no ficheiro .Rprofile do repositorio no que se atopa este traballo creáronse dúas funcións getconfig e plot_modelk que permiten representar gráficamente a estrutura dos modelos mediante o paquete Iannone (2023), como visto nas ?fig-structures. O código a usar sería:\n\n# As funcións créanse para representar gráficamente as estruturas utilizadas neste traballo.\nmodel |&gt;\n  getconfig() |&gt;\n  plot_modelk() |&gt;\n  grViz()\n\nRepetiuse o procedemento exposto nas seccións ?sec-A-models e ?sec-A-training para construír os 10 modelos feitos a partir de cada grupo de vectores tridimensionais, substituíndo a chamada a vecs3d1e por no primeiro código exposto. .vecs3d2e e vecs3d3e, dependendo do grupo de vectores tridimensionais utilizados."
  },
  {
    "objectID": "Annex4.html#resultado",
    "href": "Annex4.html#resultado",
    "title": "Anexo. 4 Códigos",
    "section": "Resultado",
    "text": "Resultado\nA continuación preséntase o código utilizado durante o proceso descrito nas diferentes subseccións da sección de Resultados.\n\nPredicións\nA análise exposta nas prediccións ?sec-realizouse a partir de gráficos (ver Figura 8, Figura 9 e Figura 10), nos que se recollen os valores dos indicadores MSE e \\(R^2\\) para cada unha das estruturas ensaiadas.\nO primeiro paso para obter estas gráficas foi o cálculo dos indicadores, para cada período de tempo, para cada unha das predicións obtidas a partir dos distintos modelos construídos con cada estrutura. Isto faise usando o seguinte código.\n\n# Extraer os resultados reais\nsalidas &lt;- data |&gt;\n  filter(\n    Date &gt; data$Date[1]\n  ) |&gt;\n  select(outputs) |&gt;\n  pull()\nsalidas &lt;- salidas[,,1]\n\n# Calcular os indicadores MSE e R2\nindicadores &lt;- data |&gt;\n  filter(Date &gt; data$Date[1]) |&gt;\n  cbind(predicciones = predicciones1e[,1]) |&gt;\n  cbind(means = meanse1) |&gt;\n  mutate(salidas = salidas) |&gt;\n  select(Date, predicciones, means, salidas) |&gt;\n  group_by(Date) |&gt;\n  summarise(\n    r2 = 1 - (sum((salidas - predicciones)^2)/sum((salidas - means)^2)),\n    mse = mse(predicciones, salidas),\n  )\n\nOs diferentes indicadores calculados para cada un dos 10 modelos adestrados con cada unha das estruturas foron almacenados nunha lista denominada list_indicadores. Isto faise usando o seguinte código:\n\nlist_indicadores[[\"indicadores1\"]] &lt;-  indicadores\n\nFeito isto, obtense unha lista que contén 10 marcos de datos (indicadores1,…,indicadores10), que á súa vez conteñen os valores dos de MSe e \\(R^2\\) das predicións obtidas. por modelos de ARN para cada unha das empresas agrupadas por data. Entón, a gráfica foi construída usando o seguinte código.\n\n# Agrupar a información das distintas construcións nun único marco de datos\nindi_graf_data &lt;- do.call(cbind,list_indicadores)\n\n# Obter os resultados medios, para cada período de tempo, utilizando as distintas construcións\nindi_graf_data |&gt;\n  rowwise() |&gt;\n  mutate(\n    Date = `indicadores1.Date`,\n    meanmse = mean(c_across(contains(\"mse\"))),\n    meanr2 = mean(c_across(contains(\"r2\")))\n    ) |&gt;\n  select(\n    Date, meanmse,meanr2\n  )|&gt;\n  # Gráfico\n  mutate(\n    Date = as.Date(Date)) |&gt;\n  ggplot(aes(x = Date, group = 1)) +\n  geom_line(aes(y = meanmse, color = \"MSE\")) +\n  geom_line(aes(y = meanr2, color = \"R2\")) +\n  scale_color_manual(values = c(\"blue\", \"green\")) +\n  theme(axis.text.x = element_text(angle = 90)) +\n  labs(x = \"Fecha\", y = \"Valores\", color = \"Indicadores\")\n\nAdemais das gráficas, na análise dos resultados tamén se utilizou o Táboa 4, nos que se sitúan as empresas que obtiveron os mellores e peores indicadores para cada estrutura Para a obtención destes datos utilizouse o seguinte código:\n\nindicadores_X_emp &lt;- data |&gt;\n  filter(Date &gt; data$Date[1]) |&gt;\n  cbind(predicciones = predicciones1e[,1]) |&gt;\n  cbind(means = meanse1) |&gt;\n  mutate(salidas = salidas) |&gt;\n  select(Date, predicciones, means, salidas, ID) |&gt;\n  group_by(ID) |&gt;\n  summarise(\n    r2 = 1 - (sum((salidas - predicciones)^2)/sum((salidas - means)^2)),\n    mse = mse(predicciones, salidas)\n  ) |&gt;\n  select(ID, r2, mse)\n\nDo mesmo xeito que os indicadores calculados por data, para gardar os indicadores calculados por empresa, creouse unha lista chamada list_indic_emp. Despois de ter almacenados os 10 marcos de datos indicadores por empresa na lista, extraéronse as empresas con mellores e peores resultados mediante o seguinte código:\n\n# Agrupar a información das distintas construcións nun único marco de datos\nind_emp_t &lt;- do.call(rbind, list_indic_emp)\n\n# Calcula a media R2 e MSE por empresa\nind_emp_t &lt;- ind_emp_t |&gt;\n  group_by(ID) |&gt;\n  summarize(\n    r2 = mean(r2),\n    mse= mean(mse)) |&gt;\n  ungroup() |&gt;\n  arrange(desc(r2))\n\n# Obtén as 10 empresas cos mellores e peores indicadores\nmejores10 &lt;- head(ind_emp_t,10)\npeores10 &lt;- tail(ind_emp_t,10)\n\nE usando as variables anteriores e as funcións rbind() e cbind, creouse a Táboa 4.\n\n\nComposición de carteiras\nNeste apartado explícase como se realizou a análise da comparación dos resultados obtidos polas diferentes carteiras (ver Figura 11, Figura 12 e Figura 13). Para iso, primeiro cómpre obter a composición das carteiras, por datas, a partir das predicións obtidas mediante a utilización das medias aritméticas e dos modelos de ARN.\nPara calcular a composición das carteiras utilizouse o paquete R Berwin A. Turlach R port by Andreas Weingessel &lt;Andreas.Weingessel@ci.tuwien.ac.at&gt; Fortran contributions from Cleve Moler dpodi/LINPACK) (2019). A continuación móstrase o código utilizado para atopar a composición das carteiras a partir das predicións da media:\n\n# Creouse un marco de datos no que se almacenaba toda a información:\n#   - Valores IBEX, como índice de referencia\n#   - Valores das predicións, tanto os obtidos polo modelo de ARN como polas medias aritméticas\n\nDATA &lt;- data |&gt;\n  left_join(IBEXsel, by =\"Date\") |&gt;\n  mutate(IBEX = Return_I) |&gt;\n  arrange(Date) |&gt;\n  filter(\n    Date &gt; data$Date[1]\n  ) |&gt;\n  mutate(predicciones = predicciones1e[,1]) |&gt;\n  mutate(\n    Real = salidas,\n    RNA = predicciones,\n    Means = meanse1\n  ) |&gt;\n  select(Date, Real, IBEX, RNA, Means, ID)\n\n# A partir do marco de datos creáronse DATA:\n#    - Un marco de datos cuxas columnas son os datos reais de cada unha das empresas para cada un dos períodos de tempo para os que se obtiveron predicións.\n#    - Un marco de datos cuxas columnas son os datos obtidos mediante a utilización das medias aritméticas de cada unha das empresas para cada un dos períodos de tempo para os que se obtiveron predicións.\n\npvtReal &lt;- DATA |&gt;\n  select(Date, Real, ID) |&gt;\n  pivot_wider(\n    names_from = ID,\n    values_from = Real\n  )\n\npvtMeans &lt;- DATA |&gt;\n  select(Date, Means, ID) |&gt;\n  pivot_wider(\n    names_from = ID,\n    values_from = Means\n  )\n\n# Creouse o marco de datos no que se almacenaba a composición das carteiras para cada un dos períodos para os que se obtivo a predición\nweightsm &lt;- data.frame()\n\n# Iteración pola que se atopa a composición das carteiras\n\npb &lt;- txtProgressBar(min = 0, max = length(unique(data$Date)[-1]), initial = 0, style = 3)\n\nfor (i in 1:length(unique(data$Date)[-1])) {\n  if(i&gt;1){\n    \n    # Créase o marco de datos que inclúe os datos a utilizar para atopar a composición da carteira, esta é creada polos datos reais ata a data e a previsión para o próximo período\n    \n    datamQP &lt;- pvtReal |&gt;\n      filter(Date &lt; unique(data$Date)[-1][i]) |&gt;\n      rbind(pvtMeans |&gt;\n              filter(Date == unique(data$Date)[-1][i])\n      )\n    \n    # Elimina aquelas empresas que non teñan datos reais ou previstos\n    \n    nare &lt;- which(is.na(datamQP[dim(datamQP)[1],]))\n    naremo &lt;- which(is.na(datamQP[(dim(datamQP)[1]-1),]))\n    nare &lt;- c(nare,naremo)\n    nare &lt;- unique(nare)\n    if(length(nare) != 0){\n      carteram &lt;- datamQP[, - nare]\n    }else{\n      carteram &lt;- datamQP\n    }\n    \n    # Extraer previsións\n    returnm &lt;- carteram[dim(carteram)[1], -1] |&gt;\n      as.matrix() |&gt;\n      t()\n    \n    # Calcula a matriz de covarianza\n    \n    covmm &lt;- cov(carteram[, -1], use = \"complete.obs\")\n    npcovmm &lt;- nearPD(covmm)$mat |&gt; \n      as.matrix()\n    \n    # Extrae o número de empresas\n    n &lt;- ncol(npcovmm)\n    \n    # Busca a composición da carteira\n    qp_outm &lt;- solve.QP(\n      Dmat = 2*npcovmm,\n      dvec = rep(0,n),\n      Amat = cbind(-1, diag(n)),\n      bvec = c(-1, rep(0,n)),\n      meq = 1)\n    qp_outm &lt;- qp_outm$solution\n    qp_outm &lt;- floor(qp_outm*100)/100\n    for(j in 1:length(qp_outm)){\n      if(qp_outm[j] &lt; 0.001){\n        qp_outm[j] &lt;- 0\n      }else{}\n    }\n    \n    # Gardar a composición da carteira\n    names(qp_outm) &lt;- names(carteram[, -1])\n    weightsm &lt;- bind_rows(weightsm, qp_outm)\n  }\n  \n  setTxtProgressBar(pb,i)\n}\n\nclose(pb)\n\n# Substitúe os pesos reais e as observacións polos valores que faltan por cero\n\npvtReal[is.na(pvtReal)] &lt;- 0\nweightsm[is.na(weightsm)] &lt;- 0\n\nDespois, para atopar a rendibilidade da carteira, multiplicáronse as composicións polos rendementos reais, supouse que se investiu unha no primeiro período e realizouse unha suma acumulada ao longo dos valores para obter o comportamento da rendibilidade ao longo do período do tempo.\n\n# Atopar os rendementos das carteiras formadas a partir das predicións da media aritmética\n\nreturn_CM &lt;-  weightsm * pvtReal[-1,-1]\nreturn_CM &lt;- rowSums(return_CM)\nreturn_CM &lt;- c(1,return_CM)\nreturn_CM &lt;- data.frame(\n  Date = pvtReal[,1],\n  Mean = return_CM\n)\n\nRealizáronse os mesmos pasos que se realizaron para atopar o comportamento da rendibilidade das carteiras a partir das medias aritméticas para atopar o comportamento a partir das predicións obtidas polo modelo de ARN tal e como se ve no código a continuación.\n\n# A partir do marco de datos DATA creouse un marco de datos cuxas columnas son os datos obtidos mediante o uso do modelo de ARN de cada unha das empresas para cada un dos períodos de tempo para os que se obtiveron predicións.\n\npvtRNA &lt;- DATA |&gt;\n  select(Date, RNA, ID) |&gt;\n  pivot_wider(\n    names_from = ID,\n    values_from = RNA\n  )\n\n# Creouse o marco de datos no que se almacenaba a composición das carteiras para cada un dos períodos para os que se obtivo a predición.\n\nweightse &lt;- data.frame()\n\n# Iteración pola que se atopa a composición das carteiras\n\npb &lt;- txtProgressBar(min = 0, max = length(unique(data$Date)[-1]), initial = 0, style = 3)\n\nfor (i in 1:length(unique(data$Date)[-1])) {\n  if(i&gt;1){\n    \n    # Créase o marco de datos que inclúe os datos a utilizar para atopar a composición da carteira, esta é creada polos datos reais ata a data e a previsión para o próximo período.\n    \n    dataeQP &lt;- pvtReal |&gt;\n      filter(Date &lt; unique(data$Date)[-1][i]) |&gt;\n      rbind(pvtRNA |&gt;\n              filter(Date == unique(data$Date)[-1][-1][i])\n            )\n    # Elimina aquelas empresas que non teñan datos reais ou previstos\n    \n    nare &lt;- which(is.na(dataeQP[dim(dataeQP)[1],]))\n    naremo &lt;- which(is.na(dataeQP[(dim(dataeQP)[1]-1),]))\n    nare &lt;- c(nare,naremo)\n    nare &lt;- unique(nare)\n    if(length(nare) != 0){\n      carterae &lt;- dataeQP[, - nare]\n    }else{\n      carterae &lt;- dataeQP\n    }\n    \n    # Extraer previsións\n    \n    returne &lt;- carterae[dim(carterae)[1], -1] |&gt;\n      as.matrix() |&gt;\n      t()\n    \n    # Calcula a matriz de covarianza\n    \n    covme &lt;- cov(carterae[, -1], use = \"complete.obs\")\n    npcovme &lt;- nearPD(covme)$mat |&gt; \n      as.matrix()\n    \n    # Extrae o número de empresas\n    \n    n &lt;- ncol(npcovme)\n    \n    # Busca a composición da carteira\n    \n    qp_oute &lt;- solve.QP(\n      Dmat = 2*npcovme,\n      dvec = rep(0,n),\n      Amat = cbind(-1, diag(n)),\n      bvec = c(-1, rep(0,n)),\n      meq = 1)\n    qp_oute &lt;- qp_oute$solution\n    qp_oute &lt;- floor(qp_oute*100)/100\n    for(j in 1:length(qp_oute)){\n      if(qp_outm[j] &lt; 0.001){\n        qp_outm[j] &lt;- 0\n      }else{}\n    }\n    \n    # Gardar a composición da carteira\n    \n    names(qp_oute) &lt;- names(carterae[, -1])\n    weightse &lt;- bind_rows(weightse, qp_oute)\n  }\n  \n  setTxtProgressBar(pb,i)\n}\n\nclose(pb)\n\n# Substitúe os pesos cos valores que faltan por cero\n\nweightse[is.na(weightse)] &lt;- 0\n\nDespois, para atopar a rendibilidade da carteira, multiplicáronse as composicións polos rendementos reais, supouse que se investiu unha no primeiro período e realizouse unha suma acumulada ao longo dos valores para obter o comportamento da rendibilidade ao longo do período. período.tempo.\n\n# Atopar os rendementos das carteiras formadas a partir das predicións do modelo de ARN\n\nreturn_CRNA &lt;-  weightse * pvtReal[-1,-1]\nreturn_CRNA &lt;- rowSums(return_CRNA)\nreturn_CRNA &lt;- c(1,return_CRNA)\nreturn_CRNA &lt;- data.frame(\n  Date = pvtReal[,1],\n  RNA = return_CRNA\n)\n\nDespois, ao igual que cos indicadores, creouse unha lista list_ret_RNA na que se almacenaban os marcos de datos dos distintos modelos construídos con cada unha das estruturas. Despois executouse o seguinte código para obter o gráfico.\n\n# Coñecer o comportamento das rendibilidades do IBEX para o período\n\nIBEXvals &lt;- IBEXsel |&gt;\n    filter(Date &gt; unique(data$Date)[2]) |&gt;\n    select(2) |&gt;\n    pull()\nIBEXvals &lt;- c(1, IBEXvals)\n\ndata_rent_RNA &lt;- do.call(cbind,list_ret_RNA)\ndata_rent_RNA &lt;- data_rent_RNA |&gt;\n  mutate(\n    Date = RNA1.Date,\n    IBEX = IBEXvals,\n    Means = return_CM$Mean) |&gt;\n  mutate_at(vars(contains(\".RNA\")), ~ cumsum(.)) |&gt;\n  mutate(\n    IBEX = cumsum(IBEX),\n    Means = cumsum(Means)) |&gt;\n  group_by(Date) |&gt;\n  summarize(\n    meanRNA = mean(c_across(contains(\".RNA\"))),\n    max_y = max(c_across(contains(\".RNA\"))),\n    min_y = min(c_across(contains(\".RNA\"))),\n    min_5 = unname(quantile(c_across(contains(\".RNA\")),0.05)),\n    max_95 = unname(quantile(c_across(contains(\".RNA\")),0.95)),\n    IBEX = IBEX,\n    Means = Means)\ndata_rent_RNA |&gt;\n  mutate(\n    Date = as.Date(Date)) |&gt;\nggplot(aes(x = Date)) +\n  geom_ribbon(aes(ymin = min_y, ymax = min_5), fill = \"blue\", alpha = 0.3) +\n  geom_ribbon(aes(ymin = max_y, ymax = max_95), fill = \"blue\", alpha = 0.3) +\n  geom_ribbon(aes(ymin = min_5, ymax = max_95), fill = \"blue\", alpha = 0.6) +\n  geom_line(\n    aes(y = meanRNA, color = \"Media RNA1\"),\n    linetype = \"dashed\") +\n  geom_line(aes(y = max_y), color = \"blue\") +\n  geom_line(aes(y = min_y), color = \"blue\") +\n  geom_line(aes(y = max_95), color = \"blue\") +\n  geom_line(aes(y = min_5, color = \"RNA1\")) +\n  geom_line(aes(y = IBEX, color = \"IBEX\")) +\n  geom_line(aes(y = Means, color = \"Medias\")) +\n  scale_color_manual(\n    values = c(\n      \"Media RNA1\"=\"blue\",\n      \"RNA1\" = \"blue\",\n      \"IBEX\" = \"red\",\n      \"Medias\" = \"green\")) +\n  guides(\n    color = guide_legend(\n      override.aes = list(\n        linetype = c(\"solid\",\"dashed\",\"solid\",\"solid\"))))+\n  labs(x = \"Fecha\",\n       y = \"Valores\",\n       color = \"Leyenda\")+\n  theme_minimal()\n\n\n\n\n\nBerwin A. Turlach R port by Andreas Weingessel &lt;Andreas.Weingessel@ci.tuwien.ac.at&gt; Fortran contributions from Cleve Moler dpodi/LINPACK), S original by. 2019. Quadprog: Functions to Solve Quadratic Programming Problems. https://CRAN.R-project.org/package=quadprog.\n\n\nIannone, Richard. 2023. DiagrammeR: Graph/Network Visualization. https://CRAN.R-project.org/package=DiagrammeR.\n\n\nRyan, Jeffrey A., and Joshua M. Ulrich. 2023. Quantmod: Quantitative Financial Modelling Framework. https://CRAN.R-project.org/package=quantmod."
  }
]