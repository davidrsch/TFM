{
  "hash": "59aa7983ef74c2a8e9784c06706e8a9b",
  "result": {
    "markdown": "# Anexo. 4 Códigos {.unnumbered}\n\nA continuación, se presenta el código utilizado para la realización del procedimiento descrito en el desarrollo del trabajo.\n\n## Datos\n\n### Obtención de Datos {#sec-A-obtdat}\n\nLo primero que se realizó fue cargar la tabla de las empresas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nempresas <- read_excel(\"data/000_empresas.xlsx\")\n```\n:::\n\n\nLuego se extrageron los ticks de las empresas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nticks <- empresas |> \n  select(TICKERS) |> \n  pull()\n```\n:::\n\n\nUna vez almacenados los ticks de las empresas en la variable `ticks` se procedio a descargar los datos correspondientes a dichas empresas desde Yahoo Finance usando el paquete quantmod de @quantmod23.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(quantmod)\nnombres_colum <- c(\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\"Adjusted\")\nqmd_data <- list()\nfor (i in 1:length(ticks)) {\n  tick <- ticks[i]\n  value <- getSymbols(\n    tick,\n    from = \"2000-01-02\",\n    to = \"2023-03-01\",\n    auto.assign = F,\n    periodicity = \"monthly\") |>\n    as.data.frame()\n  dates <- row.names(value)\n  row.names(value) <- NULL\n  value <- cbind(dates,value)\n  names(value) <- nombres_colum\n  qmd_data[[tick]] <-  value\n}\n```\n:::\n\n\nCon el objetivo de realizar un análisis exploratorio de los datos, se decidió realizar una evaluación visual de los datos históricos del precio ajustado para lo que se ejecutó:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlapply(qmd_data, function(x){\n  x |>\n    ggplot(aes(x=as.Date(Date), y=Adjusted))+\n             geom_line(color=\"#065AD8\")\n})\n```\n:::\n\n\nTras el análisis visual ejecutado con el fragmento de código anterior se persivió la existencia de precios constantes, así como calculos erroneos en el precio ajustado correspondiente a los primeros años de algunas series. Con el objetivo de eliminar estas irregularidades se seleccionaron solo aquellas observaciones posteriores a enero del 2005.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreturns_emps <- qmd_data |>\n  lapply(function(x){\n    emps <- x |>\n      filter(Date >= \"2005-01-31\")\n  })\n```\n:::\n\n\nCon el objetivo de determinar si los datos que habían sido importados contaban con valores faltantes se ejecutó el siguiente código:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nna_values <- returns_emps |>\n  sapply(function(x){\n    na <- length(which(is.na(x)))\n  })\nemp_con_na <- which(na_values > 0)\n```\n:::\n\n\nCon el objetivo de solucionar el problema con respecto al incorrecto registro de los datos se decidio eliminar aquellas que no presentaran variaciones en los precios en más de 10 observaciones. Para lo que primero se computaron las rentabilidades ejecutando el siguiente código, mediante el cual además se eliminaron las series con valores faltantes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreturns_emps2 <- returns_emps[-emp_con_na] |>\n  lapply(function(x){\n    returns <- x |>\n      select(Date, Adjusted) |>\n      mutate(Return_Ad = Delt(Adjusted)[,1]) |>\n      na.omit() |>\n      select(Date, Return_Ad)\n  })\n```\n:::\n\n\nUna vez computadas las rentabilidades se eliminaron aquellas series que presentaban en más de 10 observaciones rentabilidad 0, para lo que se ejecutó el siguiente código.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nzero_values <- returns_emps2 |>\n  sapply(function(x){\n    zeros <- length(which(x[,2]==0))\n  })\nreturns_emps3 <- returns_emps2[zero_values<10]\n```\n:::\n\n\n### Indicadores {#sec-A-indi}\n\nA continuación, se expone el código utilizado durante el proceso expuesto en el sub-epígrafe indicadores del capítulo 2.\n\nPrimero se descargaron los datos del IBEX, se computaron las rentabilidades del precio ajustado del mismo y se seleccionaron los valores posteriores a enero del 2005.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Importando IBEX\nIBEXsel <- getSymbols(\n  \"^IBEX\",\n  from = \"1990-01-01\",\n  to = \"2023-03-01\",\n  auto.assign = F,\n  periodicity = \"monthly\") |>\n  as.data.frame()\ndates <- row.names(IBEXsel)\nrow.names(IBEXsel) <- NULL\nIBEXsel <- cbind(dates,IBEXsel)\nnames(IBEXsel) <- nombres_colum\n# Calculando rentabilidad y seleccionando observaciones posteriores a\n# enero del 2005.\nIBEXsel <- IBEXsel |>\n  mutate(Return_I = Delt(Adjusted)[,1]) |>\n  na.omit() |>\n  filter(Date >= \"2005-01-31\") |>\n  select(Date, Return_I)\n```\n:::\n\n\nLuego se agregaron los valores de las rentabilidades del IBEX a las tablas de las rentabilidades de las acciones de las empresas seleccionadas, y se computaron y agregaron las variables listadas a continuación a cada una de las tablas:\n\n-   Volatilidad de la empresa\n-   Volatilidad del índice\n-   Correlación entre las rentabilidades de la empresa y el indice\n-   La Beta entre la empresa y el indice\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreturns_indc <- returns_emps3 |>\n  lapply(function(x, ind = IBEXsel){\n    emp <- x |>\n      left_join(ind) |>\n      mutate(\n        VE = sqrt(cumsum((Return_Ad - cummean(Return_Ad))^2)/1:length(Return_Ad)),\n        VI = sqrt(cumsum((Return_I - cummean(Return_I))^2)/1:length(Return_I)),\n        Cor = cumsum((Return_Ad-cummean(Return_Ad))*(Return_I-cummean(Return_I)))/(sqrt(cumsum((Return_Ad-cummean(Return_Ad))^2))*sqrt(cumsum((Return_I-cummean(Return_I))^2)))\n      )|>\n      na.omit() |>\n      mutate(\n        Beta = (Cor*VE)/VI\n      )\n  })\n```\n:::\n\n\n### Vectores {#sec-A-vec}\n\nA continuación se expone el código utilizado durante el proceso expuesto en el sub-epígrafe vectores del epígrafe modelado del Capítulo 2.\n\nEl primer paso llevado a cabo para la ejecución del proceso explicado en el sub-epígrafe en cuestión fue crear una función que permitió obtener las muestras consecutivas para cada serie utilizada. La función expuesta a continuación, como ya se mencionó, permite obtener las muestras consecutivas de una serie, para lo que se utilizan los parametros mencionados en el sub-epígrafe, número de observaciones de entradas y número de observaciones de salida, así como un parametro condicional con el que se indica si el vector a crear es de entrada o de salida.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvector2dmaker <- function(vec, ent, sal, eos=T){\n  if(eos==T){\n    emp <- 1\n    term <- (length(vec) - (ent+sal-1))\n    ob <- ent\n  }else{\n    emp <- ent + 1\n    term <- (length(vec)-sal+1)\n    ob <- sal\n  }\n  \n  vec2d <- sapply(emp:term,\n               function(x) vec[x:(x + ob-1)]) |>\n    matrix(nrow = ob) |>\n    t()\n  \n  return(vec2d)\n}\n```\n:::\n\n\nA continuación se muestra el código utilizado para la creación de los vectores de entrada de correspondiente a cada una de las series. Para lo que primero se crearon dos funciones una para las entradas y otra para las salidas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Función que se utlizará para crear las entradas tridimensionales\ninput3dmaker <- function(x,inp,out){\n  empre <- x\n  series <- 2:dim(x)[2]\n  for (i in series) {\n    if(i==series[1]){\n      vec3d <- vector2dmaker(empre[[i]],ent=inp,sal=out)\n    }else{\n      vec3d <- abind(vec3d,vector2dmaker(empre[[i]],ent=inp,sal=out), along = 3)\n    }\n  }\n  return(vec3d)\n}\n\n# Función que se utlizará para crear las salidas tridimensionales\noutput3dmaker <- function(x,inp,out){\n  empre <- x[[\"Return_Ad\"]]\n  vec3d <- vector2dmaker(empre,ent=inp,sal=out,F)\n  dim(vec3d) <- c(dim(vec3d),1)\n  return(vec3d)\n}\n```\n:::\n\n\nLuego se crearon las listas de vectores tridimensionales de entradas y salidas por empresa, ejecutandosé el siguiente código otras dos veces con el objetivo de crear las listas `vecs3d2e` y `vecs3d3e` que corresponden a aquellos casos en los que se seleccionaron 2 y 3 entradas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Se define el horizonte temporal\nht <- 1\n\n#Se define el observaciones de entrada\noe <- 1\n\n#Se crean los vectores de entrada 3d para tamaño de entrada 1\nvecs3d1e <- list()\nfor(i in 1:length(returns_indc)){\n  emp <- returns_indc[[i]]\n  inps <- input3dmaker(emp, oe, ht)\n  outs <- output3dmaker(emp, oe, ht)\n  dates <- emp[(oe + ht):dim(emp)[1],1]\n  id <- rep(names(returns_indc)[i],length(dates))\n  tibblex <- tibble(\n    Date = dates,\n    ID = id,\n    inputs = inps,\n    outputs = outs\n  )\n  vecs3d1e[[names(returns_indc)[i]]] <- tibblex\n}\n```\n:::\n\n\n## Modelado y entrenamiento\n\nA continuación, se presenta el código utilizado durante el proceso descrito en los distintos sub-epígrafes del epígrafe Modelado y entrenamiento.\n\n### Modelado {#sec-A-modelos}\n\nPara la creación de los modelos el primer paso a ejecutar es obtener la información de los vectores para los que se va a construir el modelo, lo que se hizo ejecutando el siguiente código:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- bind_rows(vecs3d1e)\ndata <- data  |>\n  arrange(Date)\ninputsinfo <- data|>\n  select(inputs) |>\n  pull() |>\n  dim()\noutputsinfo <- data|>\n  select(outputs) |>\n  pull() |>\n  dim()\n\n# Definir parámetros\nn_ob_pas <- inputsinfo[2]\nn_variables <- inputsinfo[3]\nn_ob_fut <- outputsinfo[2]\n```\n:::\n\n\nLuego se constituyo la estructura de los modelos con los aspectos descritos en @sec-modelado.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Capa de entrada\ninp <- layer_input(\n  shape = c(NULL,n_ob_pas,n_variables))\n\n# Capas ocultas\n# - CNN\ncnn <- inp |>\n  layer_conv_1d(\n    filters = 64,\n    kernel_size = 1,\n    activation = layer_activation_leaky_relu())\n# - LSTM\nlstm <- cnn |>\n  layer_lstm(64)\n\n# Capa de Salida\nout <- lstm |> \n  layer_dense(\n    n_ob_fut*1)\n\n# Juntar las capas para constituir el modelo \nmodel <- keras_model(inp, out)\n# Estableciendo parámetros de aprendizaje\nmodel |> \n  compile(loss = \"mse\", optimizer = optimizer_sgd(0.0005))\n```\n:::\n\n\n*Nota:* Puede encontrar modelos sin entrenar en la carpeta `data` del repositorio en el que se encuentra el presente trabajo. Los modelos fueron guardados usando la extensión `hdf5` y bajo los nombres `model1e`, `model2e` y `model3e`.\n\n### Entrenamiento {#sec-A-entrenamiento}\n\nEl primer paso es definir la función a utilizar para el entrenamiento de los modelos. Esta función fue construida con el objetivo de emplear el método de entrenamiento descrito en @sec-entrenamiento. Como resultado esta función devolvera una lista que contendra las predicciones obtenidas y el modelo después de haber sido entrenado y tomará como entradas principales el tibble llamado `data` constituido en el primer paso que se expone en @sec-A-modelos y el modelo además de otros argumentos que permite la utilización de la función con unos inputs principales que no sean los utilizados en el presente trabajo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwfv_train <- function(x, modelo, seq_var_name, inp_var_name = \"inputs\", out_var_name = \"outputs\", progress_bar=T){\n  \n  predictions <- c()\n  seq_val <- unique(x[[seq_var_name]])\n  \n  if(progress_bar){\n    pb <- txtProgressBar(min = 0, max = length(seq_val), initial = 0, style = 3)\n  }\n  \n  \n  # Iteración que se ejecutará para cada valor unico en la variable que define la secuencia de los datos. Por ello es de vital importancia que los datos en el tibble x se encuentren ordenados por la variable de secuencia cuyo nombre se pasa a seq_var_name\n  \n  for (i in 1:length(seq_val)) {\n    val_seq <- seq_val[i]\n    #Extraer entradas y salidas correspondiente al periodo en la variable de secuencia actual\n    inputs <- x |>\n      filter(!!sym(seq_var_name) == val_seq) |>\n      select(!!sym(inp_var_name)) |>\n      pull()\n    outputs <- x |>\n      filter(!!sym(seq_var_name) == val_seq) |>\n      select(!!sym(out_var_name)) |>\n      pull()\n    outputs <- outputs[,,1]\n    \n    #Usar entradas para obtener predicciones para los periodos en la variable secuencia a excepción del primero\n    if(i > 1){\n      pred <- modelo |>\n        predict(inputs, verbose = 3)\n      predictions <- rbind(predictions, pred)\n    }\n    \n    # Entrenar el modelo\n    modelo |>\n      fit(\n        inputs,\n        outputs,\n        epochs = 1,\n        batch_size = 10,\n        shuffle = F,\n        verbose = 0)\n    \n    if(progress_bar){\n      setTxtProgressBar(pb,i)\n      }\n    \n  }\n  \n  if(progress_bar){\n    close(pb)\n  }\n  \n  results <- list()\n  results[['predicciones']] <- predictions\n  results[['modelo']] <- modelo\n  return(results)\n}\n```\n:::\n\n\nUna vez creada la función se obtuvieron las predicciones utilizando el siguiente código:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresultados <- wfv_train(data,model,'Date')\npredicciones1e <- resultados$predicciones\n```\n:::\n\n\n*Nota:* Puede encontrar modelos entrenados en la carpeta `data` del repositorio en el que se encuentra el presente trabajo. Los modelos fueron guardados usando la extensión `hdf5` y bajo los nombres `model1etd`, `model2etd` y `model3etd`.\n\nComo se explica en @sec-predicciones además de las predicciones obtenidas por los modelos se computaron predicciones obtenidas a partir del uso de la media aritmetica, para comparar con las obtenidas con los modelos. Para el computo de estas predicciones se creo la siguiente función:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwfv_means <- function(x, seq_var_name, inp_var_name = \"inputs\", out_var_name = \"outputs\", id_var_name, progress_bar=T){\n  \n  means <- c()\n  seq_val <- unique(x[[seq_var_name]])\n  \n  if(progress_bar){\n    pb <- txtProgressBar(min = 0, max = length(seq_val), initial = 0, style = 3)\n  }\n  \n  for (i in 1:length(seq_val)) {\n    val_seq <- seq_val[i]\n    inputs <- x |>\n      filter(!!sym(seq_var_name) == val_seq) |>\n      select(!!sym(inp_var_name)) |>\n      pull()\n    inputspred <- x |>\n      filter(!!sym(seq_var_name) == val_seq) |>\n      select(!!sym(inp_var_name)) |>\n      pull()\n    outputs <- x |>\n      filter(!!sym(seq_var_name) == val_seq) |>\n      select(!!sym(out_var_name)) |>\n      pull()\n    outputs <- outputs[,,1]\n    \n    ids <- x |>\n      filter(!!sym(seq_var_name) == val_seq) |>\n      select(!!sym(id_var_name)) |>\n      pull()\n    \n    if(i==1){\n      dfmeans <- inputs[,,1] |>\n        as.data.frame() |>\n        cbind(ID = ids)\n    }else{\n      dfmeansupd <- inputs[,dim(inputs)[2],1] |>\n        as.data.frame() |>\n        cbind(ID = ids)\n      names(dfmeansupd)[1] <- paste0(\"V\",(dim(dfmeans)[2]))\n      idsdf <- unique(c(ids, dfmeans[[id_var_name]]))\n      idsdf <- data.frame(ID = idsdf)\n      dfmeansupd <- dplyr::left_join(idsdf, dfmeansupd, by = \"ID\")\n      ifelse(\n        dim(dfmeansupd)[1] > dim(dfmeans)[1],\n        dfmeans <- dplyr::left_join(dfmeansupd, dfmeans, by = \"ID\"),\n        dfmeans <- dplyr::left_join(dfmeans, dfmeansupd, by = \"ID\")\n        )\n    }\n    \n    if(i > 1){\n      MEANS <-  dfmeans |>\n        rowwise() |>\n        mutate(\n          means = mean(c_across(-!!sym(id_var_name)), na.rm = T)) |>\n        slice(match(ids,!!sym(id_var_name))) |>\n        pull(means) |>\n        as.matrix()\n      means <- rbind(means, MEANS)\n    }\n    \n    if(progress_bar){\n      setTxtProgressBar(pb,i)\n    }\n    \n  }\n  \n  if(progress_bar){\n    close(pb)\n  }\n  \n  return(means)\n}\n```\n:::\n\n\nUna vez creada la función se obtuvieron las predicciones utilizando el siguiente código:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeanse1 <- wfv_train(data,'Date',id_var_name = \"ID\")\n```\n:::\n\n\n*Nota:* En adición a lo expuesto con anterioridad se crearon dos funciones `getconfig` y `plot_modelk`, en el archivo .Rprofile del repositorio en el que se encuentra este trabajo, que permiten graficar la estructura de los modelos mediante el uso del paquete @Diagrammer, como se ve en la @fig-estructuras. El código a utilizar sería:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Las funciones están creadas para graficar las estructuras utilizadas en el presente trabajo.\nmodel |>\n  getconfig() |>\n  plot_modelk() |>\n  grViz()\n```\n:::\n\n\nEl procedimiento expuesto en las secciones @sec-A-modelos y @sec-A-entrenamiento fue repetido para construir los 10 modelos realizados a partir de cada grupo de vectores tridimensionales, sustituyendo en el primer código expuesto la llamada a `vecs3d1e` por `vecs3d2e` y `vecs3d3e`,según el grupo de vectores tridimensionanales utilizado.\n\n## Resultado\n\nA continuación, se presenta el código utilizado durante el proceso descrito en los distintos sub-epígrafes del epígrafe Resultado.\n\n### Predicciones{#sec-A-predicciones}\n\nEl análisis expuesto en la @sec-predicciones fue realizado a partir de gráficas (vea @fig-ind_evo_oo, @fig-ind_evo_twoo y @fig-ind_evo_threeo), en las que se recogen los valores de los indicadores MSE y $R^2$ para cada una de las estructuras probadas.\n\nEl primer paso para la obtención de estas gráficas fue el de computar los indicadores, para cada periodo de tiempo, para cada una de las predicciones obtenidas a partir de los distintos modelos construidos con cada estructura. Esto se realizo mediante el siguiente código.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Extraer salidas reales\nsalidas <- data |>\n  filter(\n    Date > data$Date[1]\n  ) |>\n  select(outputs) |>\n  pull()\nsalidas <- salidas[,,1]\n\n#Computar indicadores MSE y R2\nindicadores <- data |>\n  filter(Date > data$Date[1]) |>\n  cbind(predicciones = predicciones1e[,1]) |>\n  cbind(means = meanse1) |>\n  mutate(salidas = salidas) |>\n  select(Date, predicciones, means, salidas) |>\n  group_by(Date) |>\n  summarise(\n    r2 = 1 - (sum((salidas - predicciones)^2)/sum((salidas - means)^2)),\n    mse = mse(predicciones, salidas),\n  )\n```\n:::\n\n\nLos diferentes indicadores computados para cada uno de las 10 modelos entrenados con cada una de las estructuras fueron guardados en una lista llamada `list_indicadores`. Esto se realizo utilizando el siguiente código:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist_indicadores[[\"indicadores1\"]] <-  indicadores\n```\n:::\n\n\nUna vez realizado esto se obtiene una lista que contiene 10 data frames (`indicadores1`,...,`indicadores10`), los cuales a su vez contienen los valores de los de MSe y $R^2$ de las predicciones obtenidas por los modelos de RNA para cada una de las empresas agrupados por fecha. Por lo que luego se construyo la gráfica mediante el uso del siguiente código.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Agrupar la información de las distintas construcciones en un solo data frame\nindi_graf_data <- do.call(cbind,list_indicadores)\n\n# Obtener los resultados medios, para cada periodo de tiempo, usando las distintas construcciones\nindi_graf_data |>\n  rowwise() |>\n  mutate(\n    Date = `indicadores1.Date`,\n    meanmse = mean(c_across(contains(\"mse\"))),\n    meanr2 = mean(c_across(contains(\"r2\")))\n    ) |>\n  select(\n    Date, meanmse,meanr2\n  )|>\n  # Graficar\n  mutate(\n    Date = as.Date(Date)) |>\n  ggplot(aes(x = Date, group = 1)) +\n  geom_line(aes(y = meanmse, color = \"MSE\")) +\n  geom_line(aes(y = meanr2, color = \"R2\")) +\n  scale_color_manual(values = c(\"blue\", \"green\")) +\n  theme(axis.text.x = element_text(angle = 90)) +\n  labs(x = \"Fecha\", y = \"Valores\", color = \"Indicadores\")\n```\n:::\n\n\nAdemás de las gráficas se utilzo también en el análisis de los resultados la @tbl-indicadores, en la que se ecuentran las empresas que obtuvieron mejores y peores indicadores para cada estructura, para la obtención de estos datos se uso el siguiente código:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindicadores_X_emp <- data |>\n  filter(Date > data$Date[1]) |>\n  cbind(predicciones = predicciones1e[,1]) |>\n  cbind(means = meanse1) |>\n  mutate(salidas = salidas) |>\n  select(Date, predicciones, means, salidas, ID) |>\n  group_by(ID) |>\n  summarise(\n    r2 = 1 - (sum((salidas - predicciones)^2)/sum((salidas - means)^2)),\n    mse = mse(predicciones, salidas)\n  ) |>\n  select(ID, r2, mse)\n```\n:::\n\n\nAl igual que los indicadores computados por fecha para guardar los indicadores computados por empresa se creo una lista denominada `list_indic_emp`. Luego de haber almacenado los 10 data frames de indicadores por empresa en la lista se extrajeron las empresas con los mejores y peores resultados mediante el siguiente código:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Agrupar la información de las distintas construcciones en un solo data frame\nind_emp_t <- do.call(rbind, list_indic_emp)\n\n# Computar los R2 y MSE medios por empresa\nind_emp_t <- ind_emp_t |>\n  group_by(ID) |>\n  summarize(\n    r2 = mean(r2),\n    mse= mean(mse)) |>\n  ungroup() |>\n  arrange(desc(r2))\n\n# Obtener las 10 empresas con mejores y peores indicadores\nmejores10 <- head(ind_emp_t,10)\npeores10 <- tail(ind_emp_t,10)\n```\n:::\n\n\nY mediante la utilización de las variables anteriores y el uso de las funciones `rbind()` y `cbind` fue como se creo la @tbl-indicadores.\n\n### Composición de carteras {#sec-A-cc}\n\nEn esta sección se explica como se realizo el análisis del compratamiento de los resultados obtenidos por las distintas carteras (ver @fig-pf_evo_oo, @fig-pf_evo_twoo y @fig-pf_evo_threeo). Para ello es necesario primero obtener la composición de las carteras, por fecha, a partir de las predicciones obtenidas mediante el uso de las medias aritmeticas y los modelos de RNA.\n\nPara el calculo de la composición de las carteras se uso el paquete de R @quadprog, a continuación se muestra el código utilizado para hallar la composición de carteras a partir de las predicciones de la media:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Se creo un data frame en el que se guardo toda la información:\n#   - Valores del IBEX, como indice de referencia\n#   - Valores de las predicciones, tanto las obtenidas por el modelo de RNA como por las medias aritmeticas\n\nDATA <- data |>\n  left_join(IBEXsel, by =\"Date\") |>\n  mutate(IBEX = Return_I) |>\n  arrange(Date) |>\n  filter(\n    Date > data$Date[1]\n  ) |>\n  mutate(predicciones = predicciones1e[,1]) |>\n  mutate(\n    Real = salidas,\n    RNA = predicciones,\n    Means = meanse1\n  ) |>\n  select(Date, Real, IBEX, RNA, Means, ID)\n\n# A partir del data frame DATA se crearon:\n#    - Un data frame cuyas columnas son los datos reales de cada una de las empresas para cada uno de los periodos de tiempo para los que se obtuvieron predicciones.\n#    - Un data frame cuyas columnas son los datos obtenidos mediante el uso de las medias aritmeticas de cada una de las empresas para cada uno de los periodos de tiempo para los que se obtuvieron predicciones.\n\npvtReal <- DATA |>\n  select(Date, Real, ID) |>\n  pivot_wider(\n    names_from = ID,\n    values_from = Real\n  )\n\npvtMeans <- DATA |>\n  select(Date, Means, ID) |>\n  pivot_wider(\n    names_from = ID,\n    values_from = Means\n  )\n\n# Se creo el data frame en el que se guardara la composición de las carteras para cada uno de los periodos para los que se obtuvo predicción\nweightsm <- data.frame()\n\n# Iteración mediante la cual se halla la composición de las carteras\n\npb <- txtProgressBar(min = 0, max = length(unique(data$Date)[-1]), initial = 0, style = 3)\n\nfor (i in 1:length(unique(data$Date)[-1])) {\n  if(i>1){\n    \n    # Se crea el data frame que comprende los datos a utilizar para hallar la composición de la cartera, este esta creado por los datos reales hasta la fecha y la previsión del siguiente periodo\n    datamQP <- pvtReal |>\n      filter(Date < unique(data$Date)[-1][i]) |>\n      rbind(pvtMeans |>\n              filter(Date == unique(data$Date)[-1][i])\n      )\n    \n    # Elimina aquellas empresas que no tengan ni datos reales o de previsión\n    nare <- which(is.na(datamQP[dim(datamQP)[1],]))\n    naremo <- which(is.na(datamQP[(dim(datamQP)[1]-1),]))\n    nare <- c(nare,naremo)\n    nare <- unique(nare)\n    if(length(nare) != 0){\n      carteram <- datamQP[, - nare]\n    }else{\n      carteram <- datamQP\n    }\n    \n    # Extre las previsiones\n    returnm <- carteram[dim(carteram)[1], -1] |>\n      as.matrix() |>\n      t()\n    \n    # Calcula la matriz de covarianza\n    covmm <- cov(carteram[, -1], use = \"complete.obs\")\n    npcovmm <- nearPD(covmm)$mat |> \n      as.matrix()\n    # Extrae el número de empresas\n    n <- ncol(npcovmm)\n    \n    # Halla la composición de la cartera\n    qp_outm <- solve.QP(\n      Dmat = 2*npcovmm,\n      dvec = rep(0,n),\n      Amat = cbind(-1, diag(n)),\n      bvec = c(-1, rep(0,n)),\n      meq = 1)\n    qp_outm <- qp_outm$solution\n    qp_outm <- floor(qp_outm*100)/100\n    for(j in 1:length(qp_outm)){\n      if(qp_outm[j] < 0.001){\n        qp_outm[j] <- 0\n      }else{}\n    }\n    \n    # Guarda la composición de la cartera\n    names(qp_outm) <- names(carteram[, -1])\n    weightsm <- bind_rows(weightsm, qp_outm)\n  }\n  \n  setTxtProgressBar(pb,i)\n}\n\nclose(pb)\n\n# Sustituir los pesos y observaciones reales con valores faltantes con cero\npvtReal[is.na(pvtReal)] <- 0\nweightsm[is.na(weightsm)] <- 0\n```\n:::\n\n\nLuego para hallar la rentabilidad de la cartera se multiplicaron las composiciones por las rentabilidades reales, se asumio que se invertia uno en el primer periodo y se realizó una sumatoria acumulativa a los largo de los valores para obtener el comportamiento de la rentabilidad a lo largo del tiempo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Hallando las rentabilidades de las carteras conformadas a partir de las predicciones de la media aritmetica\n\nreturn_CM <-  weightsm * pvtReal[-1,-1]\nreturn_CM <- rowSums(return_CM)\nreturn_CM <- c(1,return_CM)\nreturn_CM <- data.frame(\n  Date = pvtReal[,1],\n  Mean = return_CM\n)\n```\n:::\n\n\nLos mismos pasos que se realizaron para hallar el comportamiento de la rentabilidad de las carteras a partir de las medias aritmeticas se realizaron para hallar el comportamiento a partir de las predicciones obtenidas por el modelo de RNA como se ve en el código a continuación.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A partir del data frame DATA se creo un data frame cuyas columnas son los datos obtenidos mediante el uso del model de RNA de cada una de las empresas para cada uno de los periodos de tiempo para los que se obtuvieron predicciones.\n\npvtRNA <- DATA |>\n  select(Date, RNA, ID) |>\n  pivot_wider(\n    names_from = ID,\n    values_from = RNA\n  )\n\n# Se creo el data frame en el que se guardara la composición de las carteras para cada uno de los periodos para los que se obtuvo predicción\nweightse <- data.frame()\n\n# Iteración mediante la cual se halla la composición de las carteras\n\npb <- txtProgressBar(min = 0, max = length(unique(data$Date)[-1]), initial = 0, style = 3)\n\nfor (i in 1:length(unique(data$Date)[-1])) {\n  if(i>1){\n    # Se crea el data frame que comprende los datos a utilizar para hallar la composición de la cartera, este esta creado por los datos reales hasta la fecha y la previsión del siguiente periodo\n    dataeQP <- pvtReal |>\n      filter(Date < unique(data$Date)[-1][i]) |>\n      rbind(pvtRNA |>\n              filter(Date == unique(data$Date)[-1][-1][i])\n            )\n    # Elimina aquellas empresas que no tengan ni datos reales o de previsión\n    nare <- which(is.na(dataeQP[dim(dataeQP)[1],]))\n    naremo <- which(is.na(dataeQP[(dim(dataeQP)[1]-1),]))\n    nare <- c(nare,naremo)\n    nare <- unique(nare)\n    if(length(nare) != 0){\n      carterae <- dataeQP[, - nare]\n    }else{\n      carterae <- dataeQP\n    }\n    \n    # Extre las previsiones\n    returne <- carterae[dim(carterae)[1], -1] |>\n      as.matrix() |>\n      t()\n    \n    # Calcula la matriz de covarianza\n    covme <- cov(carterae[, -1], use = \"complete.obs\")\n    npcovme <- nearPD(covme)$mat |> \n      as.matrix()\n    # Extrae el número de empresas\n    n <- ncol(npcovme)\n    \n    # Halla la composición de la cartera\n    qp_oute <- solve.QP(\n      Dmat = 2*npcovme,\n      dvec = rep(0,n),\n      Amat = cbind(-1, diag(n)),\n      bvec = c(-1, rep(0,n)),\n      meq = 1)\n    qp_oute <- qp_oute$solution\n    qp_oute <- floor(qp_oute*100)/100\n    for(j in 1:length(qp_oute)){\n      if(qp_outm[j] < 0.001){\n        qp_outm[j] <- 0\n      }else{}\n    }\n    \n    # Guarda la composición de la cartera\n    names(qp_oute) <- names(carterae[, -1])\n    weightse <- bind_rows(weightse, qp_oute)\n  }\n  \n  setTxtProgressBar(pb,i)\n}\n\nclose(pb)\n\n# Sustituir los pesos con valores faltantes con cero\nweightse[is.na(weightse)] <- 0\n```\n:::\n\n\nLuego para hallar la rentabilidad de la cartera se multiplicaron las composiciones por las rentabilidades reales, se asumio que se invertia uno en el primer periodo y se realizó una sumatoria acumulativa a los largo de los valores para obtener el comportamiento de la rentabilidad a lo largo del tiempo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Hallando las rentabilidades de las carteras conformadas a partir de las predicciones del modelo RNA\n\nreturn_CRNA <-  weightse * pvtReal[-1,-1]\nreturn_CRNA <- rowSums(return_CRNA)\nreturn_CRNA <- c(1,return_CRNA)\nreturn_CRNA <- data.frame(\n  Date = pvtReal[,1],\n  RNA = return_CRNA\n)\n```\n:::\n\n\nLuego, al igual que con los indicadores se creo un lista `list_ret_RNA` en la que se guardaron los data frames de los distintos modelos construidos con cada una de las estructuras. Después se ejecutó el siguiente código para obtener la gráfica.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Hallando el comportamiento de las rentabilidades del IBEX para el periodo\n\nIBEXvals <- IBEXsel |>\n    filter(Date > unique(data$Date)[2]) |>\n    select(2) |>\n    pull()\nIBEXvals <- c(1, IBEXvals)\n\ndata_rent_RNA <- do.call(cbind,list_ret_RNA)\ndata_rent_RNA <- data_rent_RNA |>\n  mutate(\n    Date = RNA1.Date,\n    IBEX = IBEXvals,\n    Means = return_CM$Mean) |>\n  mutate_at(vars(contains(\".RNA\")), ~ cumsum(.)) |>\n  mutate(\n    IBEX = cumsum(IBEX),\n    Means = cumsum(Means)) |>\n  group_by(Date) |>\n  summarize(\n    meanRNA = mean(c_across(contains(\".RNA\"))),\n    max_y = max(c_across(contains(\".RNA\"))),\n    min_y = min(c_across(contains(\".RNA\"))),\n    min_5 = unname(quantile(c_across(contains(\".RNA\")),0.05)),\n    max_95 = unname(quantile(c_across(contains(\".RNA\")),0.95)),\n    IBEX = IBEX,\n    Means = Means)\ndata_rent_RNA |>\n  mutate(\n    Date = as.Date(Date)) |>\nggplot(aes(x = Date)) +\n  geom_ribbon(aes(ymin = min_y, ymax = min_5), fill = \"blue\", alpha = 0.3) +\n  geom_ribbon(aes(ymin = max_y, ymax = max_95), fill = \"blue\", alpha = 0.3) +\n  geom_ribbon(aes(ymin = min_5, ymax = max_95), fill = \"blue\", alpha = 0.6) +\n  geom_line(\n    aes(y = meanRNA, color = \"Media RNA1\"),\n    linetype = \"dashed\") +\n  geom_line(aes(y = max_y), color = \"blue\") +\n  geom_line(aes(y = min_y), color = \"blue\") +\n  geom_line(aes(y = max_95), color = \"blue\") +\n  geom_line(aes(y = min_5, color = \"RNA1\")) +\n  geom_line(aes(y = IBEX, color = \"IBEX\")) +\n  geom_line(aes(y = Means, color = \"Medias\")) +\n  scale_color_manual(\n    values = c(\n      \"Media RNA1\"=\"blue\",\n      \"RNA1\" = \"blue\",\n      \"IBEX\" = \"red\",\n      \"Medias\" = \"green\")) +\n  guides(\n    color = guide_legend(\n      override.aes = list(\n        linetype = c(\"solid\",\"dashed\",\"solid\",\"solid\"))))+\n  labs(x = \"Fecha\",\n       y = \"Valores\",\n       color = \"Leyenda\")+\n  theme_minimal()\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}