{"title":"2.5 Modelado e formación","markdown":{"headingText":"2.5 Modelado e formación","headingAttr":{"id":"","classes":["unnumbered"],"keyvalue":[]},"containsRefs":false,"markdown":"\nEste apartado divídese en dous subapartados nos que se describen brevemente os modelos que foron construídos e o procedemento utilizado para adestralos. No primeiro dos subepígrafes explícanse as estruturas dos modelos empregados, mentres que no segundo subtítulo explícanse as particularidades da metodoloxía de formación empregada.\n\n## 2.5.1 Modelado {#sec-modelado}\n\nEn @sec-A-models pódese atopar unha explicación máis detallada do código utilizado durante o procedemento descrito nesta subsección.\n\nComo se explicou anteriormente, os principais elementos dos modelos de redes neuronais artificiais utilizados son unha capa CNN e unha capa LSTM. Ademais disto, utilizouse unha capa de entrada e outra de saída, que se encargan de subministrar aos modelos a información dos vectores constituídos previamente. En @sec-A-models pódese atopar unha explicación máis detallada sobre o código utilizado para realizar o procedemento descrito neste subtítulo.\n\nDado que se definiron tres tamaños de observacións diferentes a ter en conta para facer unha predición, foi necesario construír tres estruturas modelo diferentes que se adaptasen ás dimensións dos diferentes vectores de entrada, as diferentes estruturas pódense observar nas @fig-structures. .\n\nA primeira diferenza notable entre as estruturas son as saídas das capas de entrada, esta diferenza débese aos tamaños da mostra se optou por utilizar 1, 2 ou 3 observacións para construír o modelo. Como se pode ver, o tamaño da saída da capa de entrada modifica, polo tanto, o tamaño das entradas e saídas da capa CNN.\n\nComo se mencionou anteriormente, as variacións na segunda dimensión nas saídas da capa CNN poden explicarse polos diferentes tamaños dos vectores de entrada. Pero como se pode ver, o tamaño da terceira dimensión da saída desta capa é o mesmo en todas as estruturas, 64, o que indica o número de filtros elixidos para utilizar, un dos principais parámetros a ter en conta á hora de configurar estes. capas. Isto último significa que as observacións correspondentes ás 6 variables utilizadas foron divididas en 64 variables que permiten ao modelo unha mellor comprensión da relación entre as variables.\n\nOutro aspecto que se modificou na capa CNN das estruturas foi a función de activación que por defecto se chama ReLU (polas súas siglas en inglés, Rectified Linear Unit) cambiouse a Leaky ReLU porque como se explica en @OmG21 , ReLU é unha activación non lineal. función que xera cero para entradas negativas, o que pode provocar que algunhas neuronas deixen de aprender se moitas das súas entradas son negativas, xa que os seus gradientes serán cero.\n\nTendo en conta o exposto anteriormente e que algunhas das variables utilizadas nos valores de entrada presentan un elevado número de observacións negativas, como é o caso dos rendementos ou a correlación dalgunhas das series en determinados períodos de tempo, a utilización do A función de activación de ReLU non parecía unha boa opción. Polo tanto, decidiuse utilizar Leaky Relu como función de activación, que como se explica en @OmG21, trátase dunha variante que permite un pequeno gradiente constante, distinto de cero, para entradas negativas. Isto significa que esta función de activación permite que algunhas neuronas sigan aprendendo a partir de entradas negativas.\n\nNos dominios @fig-obsérvase o dominio da función ReLU e Leaky ReLU, o que lle permitirá comprender mellor o que se expuxo anteriormente.\n\nA capa CNN en todas as estruturas está ligada a unha capa LSTM, que en todos os casos tiña 64 neuronas. A saída desta capa ligouse á capa de saída que devolve un único valor.\n\nPara concluír coa construción dos modelos, determinouse utilizar o erro cadrado medio (en diante MSE, polas súas siglas en inglés, Mean Squared Error) como función empregada para avaliar unha solución candidata, os resultados do modelo e o SGD. optimizador (polos seus acrónimos en inglés, Stochastic Gradient Descent) cun alfa de 0,0005.\n\n## 2.5.2 Formación {#sec-entrenamiento}\n\nEn @sec-A-training pódese atopar unha explicación máis detallada do código utilizado durante o procedemento descrito nesta subsección.\n\nO adestramento de algoritmos de Machine Learning na previsión de series temporais ten as súas peculiaridades en como se adestran os modelos co obxectivo de resolver outro tipo de problemas. Polo tanto, neste subapartado cóbrase brevemente a metodoloxía de formación empregada, que é a denominada validación de andaina ou validación avanzada.\n\nComo xa se mencionou, a validación feedforward é un método usado para avaliar modelos de aprendizaxe automática en datos de series temporais. Isto débese a que, como explica @Brownlee19, ofrece a avaliación máis realista dos modelos de aprendizaxe automática sobre datos de series temporais. Os métodos tradicionais de avaliación de modelos procedentes da aprendizaxe automática, como a validación cruzada k-fold ou a división en datos de adestramento e validación, non funcionan para os datos de series temporais porque ignoran os compoñentes de tempo inherentes ao problema. A validación avanzada ten en conta estes compoñentes temporais e ofrece unha avaliación máis realista de como funcionará o modelo cando se use operativamente.\n\nAo avaliar un modelo, interésanos saber como funciona o modelo en datos que non se utilizaron para adestralo. Na aprendizaxe automática, isto denomínase datos non vistos ou fóra da mostra. Normalmente, para a resolución doutros problemas, os datos divídense en diferentes subconxuntos: adestramento, proba e validación, cuxo obxectivo é adestrar e validar o modelo. Coa metodoloxía de validación walk forward, os datos divídense por períodos de tempo e o modelo adestrase e validase consecutivamente, o que permite avaliar como o modelo entende a dependencia temporal dos datos.\n\nAo dividir os datos por períodos de tempo, permítenos avaliar o funcionamento real do modelo se fora aplicado desde o primeiro período, así como analizar o seu comportamento ao longo de todos os períodos, observando se o seu rendemento mellora ou non.\n\nPolo exposto neste subapartado, enténdese que os modelos foron adestrados utilizando os conxuntos de mostras correspondentes, pasando todas as mostras dispoñibles nun período de tempo determinado antes de continuar co período seguinte. Obtendo como consecuencia do anterior unha predición correspondente a cada período de tempo contemplado, a excepción dos dous primeiros que se utilizarían para adestrar o modelo por primeira vez, tal e como se ve no seguinte esquema do @fig-wfv.\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"paged","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","include-after-body":["my_scripts.html"],"css":["../my_style.css"],"output-file":"MandT.html"},"language":{"toc-title-document":"Táboa de contidos","toc-title-website":"Nesta páxina","related-formats-title":"Outros formatos","related-notebooks-title":"Cadernos","source-notebooks-prefix":"Fonte","section-title-abstract":"Abstracto","section-title-appendices":"Anexos","section-title-footnotes":"Notas ao pé","section-title-references":"Referencias","section-title-reuse":"Reutilizar","section-title-copyright":"Dereitos de autor","section-title-citation":"Cita","appendix-attribution-cite-as":"Para a atribución, cite esta obra como:","appendix-attribution-bibtex":"Cita BibTeX:","title-block-author-single":"Autor","title-block-author-plural":"Autores","title-block-affiliation-single":"Afiliación","title-block-affiliation-plural":"Afiliacións","title-block-published":"Publicado","title-block-modified":"Modificado","callout-tip-title":"Consello","callout-note-title":"Nota","callout-warning-title":"Aviso","callout-important-title":"Importante","callout-caution-title":"Precaución","code-summary":"Código","code-tools-menu-caption":"Código","code-tools-show-all-code":"Mostrar todo o código","code-tools-hide-all-code":"Ocultar todo o código","code-tools-view-source":"Ver fonte","code-tools-source-code":"Código fonte","code-line":"Liña","code-lines":"Liñas","copy-button-tooltip":"Copiar ao portapapeis","copy-button-tooltip-success":"Copiouse!","repo-action-links-edit":"Editar esta páxina","repo-action-links-source":"Ver fonte","repo-action-links-issue":"Informar dun problema","back-to-top":"Volver ao inicio","search-no-results-text":"Sen resultados","search-matching-documents-text":"documentos coincidentes","search-copy-link-title":"Copiar ligazón para buscar","search-hide-matches-text":"Ocultar coincidencias adicionais","search-more-match-text":"máis coincidencias neste documento","search-more-matches-text":"máis coincidencias neste documento","search-clear-button-title":"Borrar","search-detached-cancel-button-title":"Cancelar","search-submit-button-title":"Enviar","search":"Search","toggle-section":"Alternar sección","toggle-sidebar":"Cambiar navegación da barra lateral","toggle-dark-mode":"Activar o modo escuro","toggle-reader-mode":"Cambia o modo lector","toggle-navigation":"Alternar navegación","crossref-fig-title":"Figura","crossref-tbl-title":"Táboa","crossref-lst-title":"Listado","crossref-thm-title":"Teorema","crossref-lem-title":"Lema","crossref-cor-title":"Corolario","crossref-prp-title":"Proposición","crossref-cnj-title":"Conxectura","crossref-def-title":"Definición","crossref-exm-title":"Exemplo","crossref-exr-title":"Exercicio","crossref-ch-prefix":"Capítulo","crossref-apx-prefix":"Apéndice","crossref-sec-prefix":"Sección","crossref-eq-prefix":"Ecuación","crossref-lof-title":"Lista de figuras","crossref-lot-title":"Lista de táboas","crossref-lol-title":"Lista de listados","environment-proof-title":"Proba","environment-remark-title":"Comentario","environment-solution-title":"Solución","listing-page-order-by":"Ordenar por","listing-page-order-by-default":"Predeterminado","listing-page-order-by-date-asc":"A máis antiga","listing-page-order-by-date-desc":"O máis novo","listing-page-order-by-number-desc":"De alto a menor","listing-page-order-by-number-asc":"De baixo a maior","listing-page-field-date":"Data","listing-page-field-title":"Título","listing-page-field-description":"Descrición","listing-page-field-author":"Autor","listing-page-field-filename":"Nome de arquivo","listing-page-field-filemodified":"Modificado","listing-page-field-subtitle":"Subtítulo","listing-page-field-readingtime":"Tempo de lectura","listing-page-field-categories":"Categorías","listing-page-minutes-compact":"{0} min","listing-page-category-all":"Todos","listing-page-no-matches":"Non hai elementos coincidentes"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","bibliography":["../references.bib"],"editor":"visual","theme":"cosmo","title-block-banner":"#D60D8C","fig-cap-location":"top"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}