# 2.5 Modelado y entrenamiento {.unnumbered}

Este epígrafe se encuentra dividido en dos sub-epígrafes en los cuales se describe de forma breve los modelos que se construyeron y el procedimiento utilizado para entrenarlos. Explicándose en el primero de los sub-epígrafes las estructuras de los modelos utilizados, mientras que en el segundo sub-epígrafe se explican las particularidades de la metodología de entrenamiento utilizada.

## 2.5.1 Modelado {#sec-modelado}

Una explicación más en detalle sobre el código utilizado durante el procedimiento expuesto en este sub-epígrafe se encuentra en @sec-A-modelos.

Como se explicó con anterioridad los principales elementos de los modelos de redes neuronales artificiales utilizados son una capa CNN y una capa LSTM. Además de esto se utilizó una capa de entrada y una capa de salida, que son las encargadas de suministrar a los modelos la información de los vectores constituidos con anterioridad. Una explicación más detallada, en lo respecto a el código utilizado para la realización del procedimiento expuesto en el presente sub-epígrafe se encuentra en @sec-A-modelos.

Dado que se definieron tres tamaños distintos de observaciones para tener en cuenta para realizar una predicción fue necesario construir tres estructuras de modelos distintas que se adaptasen a las dimensiones de los distintos vectores de entrada, las distintas estructuras se pueden observar en la @fig-estructuras.

La primera diferencia notable entre las estructuras son las salidas de las capas de entrada, esta diferencia se debe a los tamaños de las muestras si se ha escogido usar 1,2 o 3 observaciones para construir el modelo. Como se observa el tamaño de la salida de la capa de entrada modifica por consiguiente el tamaño de las entradas y las salidas de la capa CNN.

Como se mencionó con anterioridad las variaciones en la segunda dimensión en las salidas de la capa CNN se pueden explicar por los distintos tamaños de los vectores de entrada. Pero como se observa el tamaño de la tercera dimensión de la salida de esta capa es igual en todas las estructuras, 64, lo que señala el número de filtros escogidos a utilizar, uno de los principales parámetros para tener en cuenta durante la configuración de estas capas. Esto último significa que las observaciones correspondientes a las 6 variables utilizadas fueron divididas en 64 variables que permiten al modelo una mejor comprensión de la relación entre las variables.

Otro aspecto que se modificó en la capa CNN de las estructuras fue la función de activación que de manera predetermina es la denominada ReLU (por sus siglas en inglés, Rectified Linear Unit) se cambió a Leaky ReLU debido a que como se explica en @OmG21, ReLU es una función de activación no lineal que genera cero para entradas negativas, lo que puede hacer que algunas neuronas dejen de aprender si muchas de sus entradas son negativas, ya que sus gradientes serán cero.

Dado lo explicado con anterioridad y que algunas de las variables que se usan en los valores de entradas poseen un alto número de observaciones negativas, como es el caso de las rentabilidades o la correlación de algunas de las series en ciertos periodos de tiempo el uso de la función de activación ReLU no parecía una buena opción. Por lo que se decidió utilizar como función de activación Leaky Relu que como se explica en @OmG21, esta es una variante que permite un pequeño gradiente constante, distinto de cero, para entradas negativas. Esto significa que esta función de activación permite que algunas neuronas sigan aprendiendo de las entradas negativas.

En la @fig-dominios se observa el dominio de la función ReLU y Leaky ReLU lo que le permitirá una mejor comprensión de lo expuesto con anterioridad.

La capa CNN en todas las estructuras se encuentran enlazada a una capa LSTM, la cual en todos los casos contó con 64 neuronas. La salida de esta capa se encontraba enlazada con la capa de salida la cuál devuelve un solo valor.

Para concluir con la construcción de los modelos se determinó usar el error cuadrático medio (en lo adelante MSE, por sus siglas en inglés, Mean Squared Error) como la función utilizada para evaluar una solución candidata los resultados del modelo y el optimizador SGD (por sus siglas en inglés, Stochastic Gradient Descent) con un Alpha de 0.0005.

## 2.5.2 Entrenamiento {#sec-entrenamiento}

Una explicación más en detalle sobre el código utilizado durante el procedimiento expuesto en este sub-epígrafe se encuentra en @sec-A-entrenamiento.

El entrenamiento de algoritmos de Machine Learning en la previsión de series de tiempo tienes sus peculiaridades a como se entrenan modelos con el objetivo de solucionar otro tipo de problemas. Por lo que en este sub-epígrafe se cubre de manera breve la metodología de entrenamiento utilizada, que es la denominada walk forward validation o validación de avance.

Como ya se mencionó la validación de avance es un método utilizado para evaluar modelos de aprendizaje automático en datos de series temporales. Esto se debe a que como se explica en @Brownlee19 proporciona la evaluación más realista de modelos de aprendizaje automático en datos de series temporales. Los métodos tradicionales de evaluación de modelos a partir del aprendizaje automático, como la validación cruzada de k-fold o la división en datos de entrenamiento y validación no funcionan en el caso de datos de series temporales porque ignoran los componentes temporales inherentes al problema. La validación Walk-forward tiene en cuenta estos componentes temporales y proporciona una evaluación más realista de cómo funcionará el modelo cuando se use operativamente.

Al evaluar un modelo, nos interesa su rendimiento del modelo en datos que no se usaron para entrenarlo. En el aprendizaje automático, se llaman datos no vistos o fuera de la muestra. Comúnmente para la resolución de otros problemas se dividen los datos en distintos subconjuntos: entrenamiento, prueba y validación, los que tiene como objetivo entrenar y validar el modelo. Con la metodología walk forward validation los datos se dividen por periodos de tiempo y se entrena y valida al modelo de forma consecutiva lo que permite evaluar como el modelo entiende la dependencia temporal de los datos.

Al dividir los datos por periodos de tiempo nos permite evaluar el funcionamiento real del modelo si se hubiese aplicado desde el primer periodo, así como analizar su comportamiento a lo largo de todos los periodos, observándose si su desempeño mejora o no.

De lo expuesto en el presente sub-epígrafe se entiende que los modelos fueron entrenados usando los conjuntos de muestras correspondientes, pasándose todas las muestras disponibles en un determinado periodo de tiempo antes de continuar con el siguiente periodo. Obteniéndose como resultado de lo anterior una predicción correspondiente a cada periodo de tiempo contemplado, a excepción de los dos primeros que se usarían para entrenar el modelo por primera vez, como se ve en el siguiente diagrama de la @fig-wfv.
